{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把框选出的单词单独保存出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_black_background(image_path):\n",
    "    \"\"\"Crop out the black background area from a single image and return the cropped image.\"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a binary mask where black regions are 255 and non-black regions are 0\n",
    "    _, binary_mask = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the bounding box of the largest contour (the black region)\n",
    "    if contours:\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        \n",
    "        # Crop the image using the bounding box\n",
    "        cropped_image = image[y:y+h, x:x+w]\n",
    "        \n",
    "        return cropped_image\n",
    "    else:\n",
    "        return image  # If no contours found, return the original image\n",
    "\n",
    "def process_images_in_folder(folder_path):\n",
    "    \"\"\"Process all images in a folder, crop out the black background, and overwrite the original images.\"\"\"\n",
    "    # List all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            # Construct full file path\n",
    "            img_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Process image\n",
    "            cropped_image = crop_black_background(img_path)\n",
    "            \n",
    "            # Save the processed image by overwriting the original image\n",
    "            cropped_image_pil = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
    "            cropped_image_pil.save(img_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL'  # Path to the folder containing images\n",
    "\n",
    "# Process all images in the folder\n",
    "process_images_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/IAM'  # Path to the folder containing images\n",
    "\n",
    "# Process all images in the folder\n",
    "process_images_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把黑像素点变成白像素点，白像素点变成黑像素点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image from BGR to RGB (OpenCV loads images in BGR format)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create masks for black and white colors\n",
    "    mask_black = np.all(image_rgb == [0, 0, 0], axis=-1)\n",
    "    mask_white = np.all(image_rgb == [255, 255, 255], axis=-1)\n",
    "    \n",
    "    # Invert black to white and white to black\n",
    "    inverted_image = np.where(mask_black[:, :, np.newaxis], [255, 255, 255], image_rgb)\n",
    "    final_image = np.where(mask_white[:, :, np.newaxis], [0, 0, 0], inverted_image)\n",
    "    \n",
    "    # Ensure the image data type is uint8\n",
    "    final_image = final_image.astype(np.uint8)\n",
    "    \n",
    "    # Save the processed image\n",
    "    cv2.imwrite(image_path, cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            process_image(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 26\u001b[0m, in \u001b[0;36mprocess_folder\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     25\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert image from BGR to RGB (OpenCV loads images in BGR format)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create masks for black and white colors\u001b[39;00m\n\u001b[1;32m      9\u001b[0m mask_black \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mall(image_rgb \u001b[38;5;241m==\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL'\n",
    "process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/IAM'\n",
    "process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把图片截出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_red_boxes(image):\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for the red color in the HSV space\n",
    "    lower_red1 = np.array([0, 70, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 70, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Create masks for the red color\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours, mask\n",
    "\n",
    "def resize_image(image, size=(128, 128)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "def crop_words(input_folder, crop_folder):\n",
    "    if not os.path.exists(crop_folder):\n",
    "        os.makedirs(crop_folder)\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(input_folder, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        contours, _ = extract_red_boxes(image)\n",
    "        \n",
    "        # Create a subfolder for each image\n",
    "        img_subfolder = os.path.join(crop_folder, os.path.splitext(img_file)[0])\n",
    "        if not os.path.exists(img_subfolder):\n",
    "            os.makedirs(img_subfolder)\n",
    "        \n",
    "        for i, cnt in enumerate(contours):\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            word_crop = image[y:y+h, x:x+w]\n",
    "            \n",
    "            # Save cropped image with a unique name within the subfolder\n",
    "            crop_path = os.path.join(img_subfolder, f\"word_{i}.png\")\n",
    "            cv2.imwrite(crop_path, word_crop)\n",
    "\n",
    "def resize_and_clean_words(crop_folder):\n",
    "    if not os.path.exists(crop_folder):\n",
    "        raise ValueError(f\"The folder '{crop_folder}' does not exist.\")\n",
    "\n",
    "    for root, dirs, files in os.walk(crop_folder):\n",
    "        for img_file in files:\n",
    "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(root, img_file)\n",
    "                image = cv2.imread(img_path)\n",
    "                \n",
    "                # Resize the image\n",
    "                resized_image = resize_image(image)\n",
    "                \n",
    "                # Save the resized image (overwrite the original cropped image)\n",
    "                cv2.imwrite(img_path, resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CVL\n",
    "input_folder = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL\"\n",
    "crop_folder = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL_rec\"\n",
    "\n",
    "# Step 1: Crop words and save them to crop_folder\n",
    "crop_words(input_folder, crop_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resize cropped images and remove red boxes\n",
    "resize_and_clean_words(crop_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IAM\n",
    "input_folder = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/IAM\"\n",
    "crop_folder = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/IAM_rec\"\n",
    "\n",
    "# Step 1: Crop words and save them to crop_folder\n",
    "crop_words(input_folder, crop_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resize cropped images and remove red boxes\n",
    "resize_and_clean_words(crop_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把红框去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_red_boxes(image):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for the red color in the HSV space\n",
    "    lower_red1 = np.array([0, 70, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 70, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Create masks for the red color\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Create an image where red pixels are set to white\n",
    "    white_background = np.ones_like(image) * 255\n",
    "    no_red_image = np.where(red_mask[:, :, None] == 0, image, white_background)\n",
    "\n",
    "    return no_red_image\n",
    "\n",
    "def convert_white_inside_black_outline(image):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for the black color in the HSV space\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([180, 255, 50])  # Black has very low value in V channel\n",
    "\n",
    "    # Create a mask for black color\n",
    "    black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "    # Find contours in the black mask\n",
    "    contours, _ = cv2.findContours(black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Convert image to RGB for easier manipulation\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        roi = image_rgb[y:y+h, x:x+w]\n",
    "        \n",
    "        # Create a mask for white pixels inside the bounding box\n",
    "        white_mask = np.all(roi == [255, 255, 255], axis=-1)\n",
    "        \n",
    "        # Convert white pixels to black\n",
    "        roi[white_mask] = [0, 0, 0]\n",
    "        \n",
    "        # Replace the ROI in the original image\n",
    "        image_rgb[y:y+h, x:x+w] = roi\n",
    "\n",
    "    # Convert back to BGR for saving\n",
    "    processed_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "    return processed_image\n",
    "\n",
    "def process_subfolders(root_folder):\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for img_file in files:\n",
    "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(subdir, img_file)\n",
    "                image = cv2.imread(img_path)\n",
    "                \n",
    "                # Remove red boxes\n",
    "                image_no_red = remove_red_boxes(image)\n",
    "                \n",
    "                # Convert white inside black outline\n",
    "                processed_image = convert_white_inside_black_outline(image_no_red)\n",
    "                \n",
    "                # Save the processed image (overwrite the original image)\n",
    "                cv2.imwrite(img_path, processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m root_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL_rec\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_subfolders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 64\u001b[0m, in \u001b[0;36mprocess_subfolders\u001b[0;34m(root_folder)\u001b[0m\n\u001b[1;32m     61\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Remove red boxes\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m image_no_red \u001b[38;5;241m=\u001b[39m \u001b[43mremove_red_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Convert white inside black outline\u001b[39;00m\n\u001b[1;32m     67\u001b[0m processed_image \u001b[38;5;241m=\u001b[39m convert_white_inside_black_outline(image_no_red)\n",
      "Cell \u001b[0;32mIn[30], line 18\u001b[0m, in \u001b[0;36mremove_red_boxes\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create an image where red pixels are set to white\u001b[39;00m\n\u001b[1;32m     17\u001b[0m white_background \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(image) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m---> 18\u001b[0m no_red_image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mred_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_background\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m no_red_image\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root_folder = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/CVL_rec'\n",
    "process_subfolders(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/output/IAM_rec'\n",
    "process_subfolders(root_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
