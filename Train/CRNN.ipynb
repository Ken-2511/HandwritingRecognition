{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个记事本是用来搭建CRNN网络的，用来做recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from utils import *\n",
    "from helper import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试用的代码，不用看（打印出神经网络的结构）\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# # model_cnn = nn.Sequential(*list(model.children())[:-1])\n",
    "# for chi in model.children():\n",
    "#     print(chi)\n",
    "#     print('-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用resnet18除去最后的fc作为cnn的部分，lstm作为rnn的部分。<br>\n",
    "输入1x128x128图片<br>\n",
    "经过cnn部分，先是卷到了512x4x4，然后经过平均池化层变成512x1x1<br>\n",
    "然后展平，经过线性变换放入lstm的hidden和cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个是从另一个记事本中复制过来的，懒得改了\n",
    "\n",
    "def get_model_name(epoch, name):\n",
    "    return f\"{name}_{epoch}.pth\"\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    这是一个基于CNN和LSTM的CRNN模型，用于生成文本\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=128, hidden_dim=1024, io_dim=1024, num_layers=4, bidirectional=True, device='cuda:0', num_beams=20):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            num_classes: ...\n",
    "            hidden_dim: int, the dimension of the hidden state of the LSTM\n",
    "            io_dim: int, the dimension of the input and output of the LSTM\n",
    "            num_layers: int, the number of layers of the LSTM\n",
    "            bidirectional: bool, whether to use bidirectional LSTM\n",
    "            device: str, the device\n",
    "            num_beams: int, the number of beams used in beam search\n",
    "        \"\"\"\n",
    "        super(CRNN, self).__init__()\n",
    "        self.direction_factor = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.num_beams = num_beams\n",
    "        # num-classes对应ascii码表的128种字符\n",
    "        self.num_classes = num_classes\n",
    "        # hidden_dim是LSTM的隐藏层（hidden state）和细胞状态（cell state）的维度\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # io_dim是LSTM的输入和输出的维度\n",
    "        self.io_dim = io_dim\n",
    "        self.device = device\n",
    "        # max num of characters of the generated text\n",
    "        self.max_len = 64\n",
    "        # 1x1卷积层，用于将灰度图转换为3通道图像以适应ResNet的输入\n",
    "        self.conv1 = nn.Conv2d(1, 3, 1)\n",
    "        # 使用ResNet50作为CNN的基础模型，去掉最后一层全连接层\n",
    "        self.cnn = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])  # output dim is 2048\n",
    "        # LSTM层，输入维度为io_dim，隐藏层维度为hidden_dim\n",
    "        self.rnn = nn.LSTM(io_dim, hidden_dim, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        # 将CNN的输出转换为LSTM的隐藏状态和细胞状态\n",
    "        self.h0_fc = nn.Linear(2048, hidden_dim * num_layers * self.direction_factor)\n",
    "        self.c0_fc = nn.Linear(2048, hidden_dim * num_layers * self.direction_factor)\n",
    "        # 将LSTM的输出转换为最终的输出，即字符概率分布\n",
    "        self.out_fc = nn.Linear(hidden_dim * self.direction_factor, num_classes)\n",
    "        # 将字符的索引转换为字符的embedding\n",
    "        self.embedding = nn.Embedding(num_classes, io_dim)\n",
    "        # dropout防止过拟合\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "        self.to(device)\n",
    "    \n",
    "    def init_state(self, img):\n",
    "        # 通过CNN卷出 lstm 的 hidden state 和 cell state\n",
    "        x = self.conv1(img)         # batch_size, 3, 64, 64\n",
    "        x = self.cnn(x)             # batch_size, 512, 1, 1\n",
    "        x = x.view(x.size(0), -1)   # batch_size, 512\n",
    "        x = x.unsqueeze(0)          # 1, batch_size, 512\n",
    "        h0 = self.h0_fc(x)          # 1, batch_size, hidden_dim\n",
    "        c0 = self.c0_fc(x)          # 1, batch_size, hidden_dim\n",
    "        h0 = h0.view(-1, self.hidden_dim, self.num_layers * self.direction_factor).permute(2, 0, 1).contiguous()  # num_layers * direction_factor, batch_size, hidden_dim\n",
    "        c0 = c0.view(-1, self.hidden_dim, self.num_layers * self.direction_factor).permute(2, 0, 1).contiguous()  # num_layers * direction_factor, batch_size, hidden_dim\n",
    "        return h0, c0\n",
    "    \n",
    "    def next_char(self, x, h_c_n):\n",
    "        # print(\"next char x shape: \", x.shape)\n",
    "        h_n, c_n = h_c_n\n",
    "        # x: the embedding of the last character\n",
    "        # h_n: the hidden state of the last character\n",
    "        # c_n: the cell state of the last character\n",
    "        x, (h_n, c_n) = self.rnn(x, (h_n, c_n))\n",
    "        # print(\"next char rnn output x shape: \", x.shape)\n",
    "        x = self.out_fc(x)\n",
    "        # x = self.dropout(x)\n",
    "        # print(\"next char output x shape: \", x.shape)\n",
    "        return x, (h_n, c_n)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        batch_size = img.size(0)\n",
    "        h0, c0 = self.init_state(img)\n",
    "        x = 2  # the index of the start token\n",
    "        x = torch.tensor([x] * batch_size, dtype=torch.long).view(batch_size, 1).to(self.device)\n",
    "        x = self.embedding(x)\n",
    "        h_c_n = (h0, c0)\n",
    "        output = torch.zeros(batch_size, self.max_len, self.num_classes).to(self.device)\n",
    "        output[:, 0, 2] = 1\n",
    "        for i in range(1, self.max_len):\n",
    "            x, h_c_n = self.next_char(x, h_c_n)\n",
    "            output[:, i, :] = x.view(batch_size, self.num_classes)\n",
    "            x = x.argmax(dim=-1)\n",
    "            x = self.embedding(x)\n",
    "        return output\n",
    "    \n",
    "    def forward_beam(self, img):\n",
    "        # 使用束搜索，生成最可能的文本\n",
    "        num_beams = self.num_beams\n",
    "        batch_size = img.size(0)\n",
    "        h0, c0 = self.init_state(img)\n",
    "        x = 2  # the index of the start token\n",
    "        x = torch.tensor([x] * batch_size, dtype=torch.long).view(batch_size, 1).to(self.device)\n",
    "        x = self.embedding(x)\n",
    "        h_c_n = (h0, c0)\n",
    "        output = torch.zeros(batch_size, num_beams, self.max_len, self.num_classes, dtype=torch.long).to(self.device)\n",
    "        output[:, :, 0, 2] = 1\n",
    "        probabilities = torch.ones(batch_size, num_beams).to(self.device)\n",
    "        # 最一开始的时候只有一个beam，所以要先预测一次，得到初始的概率分布，并将其分散到num_beams个beam上\n",
    "        x, h_c_n = self.next_char(x, h_c_n)\n",
    "        x = torch.softmax(x, dim=-1).view(batch_size, -1)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(num_beams):\n",
    "                index = x[i].argmax().item()\n",
    "                output[i, j, 1, index] = 1\n",
    "                probabilities[i, j] = x[i, index]\n",
    "                x[i, index] = 0\n",
    "        x = output[:, :, 1, :].argmax(dim=-1)\n",
    "        x = self.embedding(x)\n",
    "        # 将隐状态在beam维度上复制num_beams份\n",
    "        # 当前shape：num_layers * direction_factor, batch_size, hidden_dim\n",
    "        # 目标shape：num_layers * direction_factor, batch_size * num_beams, hidden_dim\n",
    "        h_n, c_n = h_c_n\n",
    "        h_n = h_n.unsqueeze(2)\n",
    "        h_n = torch.repeat_interleave(h_n, num_beams, 2)  # num_layers * direction_factor, batch_size, num_beams, hidden_dim\n",
    "        h_n = h_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "        c_n = c_n.unsqueeze(2)\n",
    "        c_n = torch.repeat_interleave(c_n, num_beams, 2)\n",
    "        c_n = c_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "        h_c_n = (h_n, c_n)\n",
    "        # 现在，\n",
    "        # x:                batch_size, num_beams, io_dim\n",
    "        # probabilities:    batch_size, num_beams\n",
    "        # output:           batch_size, num_beams, max_len, num_classes\n",
    "        # 接下来，每次预测一个字符，然后从中选出最可能的num_beams个预测\n",
    "        # for i in range(2, self.max_len):\n",
    "        for i in range(2, self.max_len):\n",
    "            # 先将batch维度和beam维度合并，以便于LSTM的输入\n",
    "            x = x.view(batch_size * num_beams, 1, -1)\n",
    "            h_n = h_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "            c_n = c_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "            h_c_n = (h_n, c_n)\n",
    "            x, h_c_n = self.next_char(x, h_c_n)\n",
    "            x = torch.softmax(x, dim=-1)\n",
    "            # 筛选出含有3（结束标志）的beams并将概率设为1，因为这个beam已经结束了\n",
    "            temp = torch.argmax(output, dim=-1)  # batch_size, num_beams, max_len\n",
    "            temp = torch.eq(temp, 3).any(dim=-1)  # batch_size, num_beams\n",
    "            mask_ones = torch.zeros(batch_size, num_beams, self.num_classes, dtype=torch.bool).to(self.device)\n",
    "            mask_ones[temp] = 1\n",
    "            mask_ones[:, :, 1:] = 0\n",
    "            x = x.view(batch_size, num_beams, self.num_classes)\n",
    "            x[temp] = 0\n",
    "            x[mask_ones] = 1\n",
    "            # print(\"index:\", i)\n",
    "            # print(\"beams:\")\n",
    "            # for j in range(batch_size):\n",
    "            #     for k in range(num_beams):\n",
    "            #         for l in range(i):\n",
    "            #             print(output[j, k, l].argmax(dim=-1).item(), end=' ')\n",
    "            #         print(x[j, k].argmax(dim=-1).item())\n",
    "            # print(\"mask:\", mask_ones)\n",
    "            x = x * probabilities.view(batch_size, num_beams, 1)\n",
    "            x = x.view(batch_size, num_beams * self.num_classes)\n",
    "            # 找出最可能的num_beams个预测，并使用花式索引\n",
    "            chosens = torch.argsort(x, dim=-1, descending=True)[:, :num_beams]\n",
    "            chosens_indices = (torch.arange(batch_size).repeat_interleave(num_beams), chosens.contiguous().view(-1))\n",
    "            # 更新probabilities\n",
    "            probabilities = x[chosens_indices].view(batch_size, num_beams)\n",
    "            # 更新输入\n",
    "            x = x.view(batch_size, num_beams, self.num_classes)\n",
    "            chosens_indices = (chosens_indices[0], chosens_indices[1] // self.num_classes, chosens_indices[1] % self.num_classes)\n",
    "            x = chosens_indices[2].view(batch_size, num_beams, 1)\n",
    "            x = self.embedding(x)\n",
    "            # 更新输出\n",
    "            output = output[chosens_indices[0], chosens_indices[1]].view(batch_size, num_beams, self.max_len, self.num_classes)\n",
    "            # print(output[:, :, :i+1, 65:123])\n",
    "            out_idx_0 = torch.arange(batch_size).repeat_interleave(num_beams)\n",
    "            out_idx_1 = torch.arange(num_beams).repeat(batch_size)\n",
    "            out_idx_3 = chosens_indices[2]\n",
    "            output[out_idx_0, out_idx_1, i, out_idx_3] = 1\n",
    "            # 更新隐状态\n",
    "            h_n, c_n = h_c_n\n",
    "            # print(f\"probabilities: {probabilities}\", end=' ')\n",
    "            # print(f\"chosen 1 {chosens_indices[1]}, chosen 2 {chosens_indices[2]}\")\n",
    "            # print(output[:, :, :i+1, 65:123])\n",
    "            \n",
    "        return output, probabilities\n",
    "    \n",
    "    def beam_output_to_words(self, output):\n",
    "        # 将模型输出的字符概率分布转换为文本\n",
    "        batch_size = output.size(0)\n",
    "        output = output.argmax(dim=-1)\n",
    "        output = output.cpu().numpy()\n",
    "        word_beams = []\n",
    "        for i in range(batch_size):\n",
    "            words = []\n",
    "            for j in range(self.num_beams):\n",
    "                word = ''\n",
    "                for k in range(1, self.max_len):\n",
    "                    if output[i, j, k] == 3:\n",
    "                        break\n",
    "                    word += chr(output[i, j, k])\n",
    "                words.append(word)\n",
    "            word_beams.append(words)\n",
    "        return word_beams\n",
    "    \n",
    "    def output_to_words(self, output):\n",
    "        # 将模型输出的字符概率分布转换为文本\n",
    "        batch_size = output.size(0)\n",
    "        output = output.argmax(dim=-1)\n",
    "        output = output.cpu().numpy()\n",
    "        words = []\n",
    "        for i in range(batch_size):\n",
    "            word = ''\n",
    "            for j in range(1, self.max_len):\n",
    "                if output[i, j] == 3:\n",
    "                    break\n",
    "                word += chr(output[i, j])\n",
    "            words.append(word)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset_IAM = RecDataset(\"IAM\", \"train\")\n",
    "dataset_CVL = RecDataset(\"CVL\", \"train\")\n",
    "dataset_Aug = RecDatasetAug(\"eng_news_2023_10K-sentences.txt\")\n",
    "dataset = dataset_Aug\n",
    "dataset = torch.utils.data.ConcatDataset([dataset_IAM, dataset_CVL])\n",
    "train_loader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 128, 128])\n",
      "torch.Size([10, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "# 测试CRNN进行预测时的形状是否符合要求\n",
    "\n",
    "crnn = CRNN()\n",
    "for step, (img, label) in enumerate(train_loader):\n",
    "    img, label = img.to(crnn.device), label.to(crnn.device)\n",
    "    print(img.shape)\n",
    "    output = crnn(img)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 128, 128])\n",
      "torch.Size([8, 10, 1024]) torch.Size([8, 10, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 测试CRNN进行训练时的形状是否符合要求\n",
    "\n",
    "crnn = CRNN()\n",
    "for step, (img, label) in enumerate(train_loader):\n",
    "    img, label = img.to(crnn.device), label.to(crnn.device)\n",
    "    print(img.shape)\n",
    "    h_n, c_n = crnn.init_state(img)\n",
    "    print(h_n.shape, c_n.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(epoch, name):\n",
    "    return f\"{name}_{epoch}.pth\"\n",
    "\n",
    "\n",
    "def get_val_loss(model, dataloader, device):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (img, target) in enumerate(dataloader):\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            h_n, c_n = model.init_state(img)\n",
    "            h_n, c_n = h_n.to(device), c_n.to(device)\n",
    "            output = torch.zeros(target.shape[0], model.max_len, model.num_classes).to(device)\n",
    "            x = target[:, 0]\n",
    "            output[:, 0] = x\n",
    "            x = model.embedding(x.long().unsqueeze(1))\n",
    "            for i in range(model.max_len-1):\n",
    "                x = model.embedding(target[:, i].argmax(-1).unsqueeze(1))\n",
    "                x, (h_n, c_n) = model.next_char(x, (h_n, c_n))\n",
    "                output[:, i+1] = x.squeeze(1)\n",
    "            loss += criterion(output.view(-1, model.num_classes), target.argmax(-1).view(-1))\n",
    "    return loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21834/1026976738.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path + model_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from Aug_25.pth\n",
      "Epoch 26, Val Loss 0.7828720211982727                                                                                               \n",
      "Model saved as Aug_26.pth\n",
      "Epoch 27, Val Loss 0.783542811870575                                                                                                \n",
      "Model saved as Aug_27.pth\n",
      "Epoch 28, Val Loss 0.7840873003005981                                                                                               \n",
      "Model saved as Aug_28.pth\n",
      "Epoch 29, Val Loss 0.7840085029602051                                                                                               \n",
      "Model saved as Aug_29.pth\n",
      "Epoch 30, Val Loss 0.7837098240852356                                                                                               \n",
      "Model saved as Aug_30.pth\n",
      "Epoch 31, Iter 212, Loss 0.6965"
     ]
    }
   ],
   "source": [
    "# 下面是训练的代码，使用教师强制训练\n",
    "def train_crnn(model, lr, epochs, start_epoch, name, device='cuda:0'):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        model: CRNN, the model to be trained\n",
    "        lr: float, the learning rate\n",
    "        epochs: int, the number of epochs to train\n",
    "        device: str, the device to use\n",
    "        start_epoch: int, the epoch to start training\n",
    "        name: str, the name of the model or the task\n",
    "    \"\"\"\n",
    "\n",
    "    # 如果start_epoch不为0，说明是从某个epoch开始训练的，需要加载模型\n",
    "    if start_epoch:\n",
    "        model_name = get_model_name(start_epoch, name)\n",
    "        model_path = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/CRNN/\"\n",
    "        model.load_state_dict(torch.load(model_path + model_name))\n",
    "        start_epoch += 1\n",
    "        print(f\"Model loaded from {model_name}\")\n",
    "\n",
    "    writer = tb.SummaryWriter('/root/tf-logs')  # tensorboard writer，可以在浏览器中查看训练过程\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    model.to(device)\n",
    "    t0 = time.time()\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        for step, (img, target) in enumerate(train_loader):\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            # 准备初始状态\n",
    "            h_n, c_n = model.init_state(img)\n",
    "            h_n, c_n = h_n.to(device), c_n.to(device)\n",
    "            output = torch.zeros(target.shape[0], model.max_len, model.num_classes).to(device)\n",
    "            x = target[:, 0]\n",
    "            output[:, 0] = x\n",
    "            x = model.embedding(x.long().unsqueeze(1))\n",
    "            for i in range(model.max_len-1):\n",
    "                x = model.embedding(target[:, i].argmax(-1).unsqueeze(1))\n",
    "                x, (h_n, c_n) = model.next_char(x, (h_n, c_n))\n",
    "                output[:, i+1] = x.squeeze(1)\n",
    "            loss = criterion(output.view(-1, model.num_classes), target.argmax(-1).view(-1))\n",
    "            loss.backward()\n",
    "            # 将cnn的梯度调小，防止过拟合\n",
    "            for param in model.cnn.parameters():\n",
    "                param.grad *= 0.1\n",
    "            optimizer.step()\n",
    "            if time.time() - t0 > 1:\n",
    "                # 每秒打印一次训练信息\n",
    "                t0 = time.time()\n",
    "                print(f\"\\rEpoch {epoch}, Iter {step}, Loss {loss.item():.4f}\", end=\"\")\n",
    "                writer.add_scalar(f'{name}/Train_Loss', loss.item(), epoch * len(train_loader) + step)\n",
    "        \n",
    "        # 计算验证集上的loss\n",
    "        val_loss = get_val_loss(model, val_loader, device)\n",
    "        print(\" \" * 100, end=\"\")\n",
    "        print(f\"\\rEpoch {epoch}, Val Loss {val_loss.item()}\", end=\"\")\n",
    "        writer.add_scalar(f'{name}/Val_Loss', val_loss.item(), epoch)\n",
    "\n",
    "        model_name = get_model_name(epoch, name)\n",
    "        model_path = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/CRNN/\"\n",
    "        torch.save(model.state_dict(), model_path + model_name)\n",
    "        print(f\"\\nModel saved as {model_name}\")\n",
    "\n",
    "\n",
    "# 数据增广 & 加载数据集\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(size=(128, 128), scale=(0.9, 1.2), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "val_trans = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set_IAM = RecDataset(\"IAM\", \"train\", trans)\n",
    "train_set_CVL = RecDataset(\"CVL\", \"train\", trans)\n",
    "train_set = torch.utils.data.ConcatDataset([train_set_IAM, train_set_CVL])\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=16)\n",
    "\n",
    "val_set_IAM = RecDataset(\"IAM\", \"val\", val_trans)\n",
    "val_set_CVL = RecDataset(\"CVL\", \"val\", val_trans)\n",
    "val_set = torch.utils.data.ConcatDataset([val_set_IAM, val_set_CVL])\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=False, num_workers=16)\n",
    "\n",
    "# 创建模型\n",
    "model = CRNN()\n",
    "\n",
    "# 开始训练\n",
    "train_crnn(model, lr=0.001, epochs=500, start_epoch=25, name=\"Aug\")\n",
    "\n",
    "# 记录：\n",
    "# CRNN:\n",
    "# 一开始lr=0.01\n",
    "# 从epoch=8开始，lr=0.001\n",
    "# 从epoch=15开始，添加dropout=0.8\n",
    "# Aug:\n",
    "# 从epoch=16开始，不再使用盖茨比数据集，改用一种从网上下载的无名语料库，并且并上IAM和CVL数据集。训练时间可能会更长，但是效果应该会更好\n",
    "# https://wortschatz.uni-leipzig.de/en/download/English\n",
    "# 顺带说一句，这个无名语料库的大小是1212kb，盖茨比的大小是293kb\n",
    "# 从epoch=25开始，lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
