{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个notebook用来可视化CRNN模型的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    这是一个基于CNN和LSTM的CRNN模型，用于生成文本\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=128, hidden_dim=1024, io_dim=1024, num_layers=4, bidirectional=True, device='cuda:0'):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            num_classes: ...\n",
    "            hidden_dim: int, the dimension of the hidden state of the LSTM\n",
    "            io_dim: int, the dimension of the input and output of the LSTM\n",
    "            num_layers: int, the number of layers of the LSTM\n",
    "            bidirectional: bool, whether to use bidirectional LSTM\n",
    "            device: str, the device\n",
    "        \"\"\"\n",
    "        super(CRNN, self).__init__()\n",
    "        self.direction_factor = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        # num-classes对应ascii码表的128种字符\n",
    "        self.num_classes = num_classes\n",
    "        # hidden_dim是LSTM的隐藏层（hidden state）和细胞状态（cell state）的维度\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # io_dim是LSTM的输入和输出的维度\n",
    "        self.io_dim = io_dim\n",
    "        self.device = device\n",
    "        # max num of characters of the generated text\n",
    "        self.max_len = 64\n",
    "        # 1x1卷积层，用于将灰度图转换为3通道图像以适应ResNet的输入\n",
    "        self.conv1 = nn.Conv2d(1, 3, 1)\n",
    "        # 使用ResNet50作为CNN的基础模型，去掉最后一层全连接层\n",
    "        self.cnn = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])  # output dim is 2048\n",
    "        # LSTM层，输入维度为io_dim，隐藏层维度为hidden_dim\n",
    "        self.rnn = nn.LSTM(io_dim, hidden_dim, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        # 将CNN的输出转换为LSTM的隐藏状态和细胞状态\n",
    "        self.h0_fc = nn.Linear(2048, hidden_dim * num_layers * self.direction_factor)\n",
    "        self.c0_fc = nn.Linear(2048, hidden_dim * num_layers * self.direction_factor)\n",
    "        # 将LSTM的输出转换为最终的输出，即字符概率分布\n",
    "        self.out_fc = nn.Linear(hidden_dim * self.direction_factor, num_classes)\n",
    "        # 将字符的索引转换为字符的embedding\n",
    "        self.embedding = nn.Embedding(num_classes, io_dim)\n",
    "        # dropout防止过拟合\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "        self.to(device)\n",
    "    \n",
    "    def init_state(self, img):\n",
    "        # 通过CNN卷出 lstm 的 hidden state 和 cell state\n",
    "        x = self.conv1(img)         # batch_size, 3, 64, 64\n",
    "        x = self.cnn(x)             # batch_size, 512, 1, 1\n",
    "        x = x.view(x.size(0), -1)   # batch_size, 512\n",
    "        x = x.unsqueeze(0)          # 1, batch_size, 512\n",
    "        h0 = self.h0_fc(x)          # 1, batch_size, hidden_dim\n",
    "        c0 = self.c0_fc(x)          # 1, batch_size, hidden_dim\n",
    "        h0 = h0.view(-1, self.hidden_dim, self.num_layers * self.direction_factor).permute(2, 0, 1).contiguous()  # 4, batch_size, hidden_dim\n",
    "        c0 = c0.view(-1, self.hidden_dim, self.num_layers * self.direction_factor).permute(2, 0, 1).contiguous()  # 4, batch_size, hidden_dim\n",
    "        return h0, c0\n",
    "    \n",
    "    def next_char(self, x, h_c_n):\n",
    "        # print(\"next char x shape: \", x.shape)\n",
    "        h_n, c_n = h_c_n\n",
    "        # x: the embedding of the last character\n",
    "        # h_n: the hidden state of the last character\n",
    "        # c_n: the cell state of the last character\n",
    "        x, (h_n, c_n) = self.rnn(x, (h_n, c_n))\n",
    "        # print(\"next char rnn output x shape: \", x.shape)\n",
    "        x = self.out_fc(x)\n",
    "        # x = self.dropout(x)\n",
    "        # print(\"next char output x shape: \", x.shape)\n",
    "        return x, (h_n, c_n)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        batch_size = img.size(0)\n",
    "        h0, c0 = self.init_state(img)\n",
    "        x = 2  # the index of the start token\n",
    "        x = torch.tensor([x] * batch_size, dtype=torch.long).view(batch_size, 1).to(self.device)\n",
    "        x = self.embedding(x)\n",
    "        # print(\"after embedding x shape: \", x.shape)\n",
    "        h_c_n = (h0, c0)\n",
    "        temp = torch.zeros(batch_size, 1, self.num_classes).to(self.device)\n",
    "        temp[:, 0, 2] = 1\n",
    "        output = [temp]\n",
    "        for i in range(1, self.max_len):\n",
    "            x, h_c_n = self.next_char(x, h_c_n)\n",
    "            output.append(x)\n",
    "            x = x.argmax(dim=-1)\n",
    "            x = self.embedding(x)\n",
    "        output = torch.cat(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = CRNN()\n",
    "model_name = get_model_name(1024, 1024, 0.1, 64, 4, \"concat\")\n",
    "model_path = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/CRNN/\"\n",
    "model.load_state_dict(torch.load(model_path + model_name))\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "\n",
    "def show_img(img):\n",
    "    img = img.squeeze().cpu().numpy()\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def get_word(output):\n",
    "    output = output.cpu().detach().numpy()\n",
    "    word = \"\"\n",
    "    for i in range(1, 64):\n",
    "        o = np.argmax(output[i])\n",
    "        if o == 3:\n",
    "            break\n",
    "        c = chr(o)\n",
    "        word += c\n",
    "    return word\n",
    "\n",
    "# test\n",
    "import random\n",
    "class RandomNegate:\n",
    "    def __call__(self, sample):\n",
    "        if random.random() > 0.5:\n",
    "            return -sample\n",
    "        return sample\n",
    "trans = transforms.Compose([\n",
    "    # transforms.Normalize((0.5), (0.5)),\n",
    "    transforms.ToPILImage(),\n",
    "    # transforms.RandomResizedCrop(size=(128, 128), scale=(0.9, 1.2), ratio=(0.9, 1.1)),\n",
    "    # transforms.RandomRotation(10),\n",
    "    # transforms.RandomAffine(10),\n",
    "    # transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    # RandomNegate()\n",
    "])\n",
    "\n",
    "dataset = RecDataset(\"IAM\", \"val\", trans)\n",
    "train_loader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (img, label) in enumerate(train_loader):\n",
    "    img, label = img.to(\"cuda:0\"), label.to(\"cuda:0\")\n",
    "    output = model(img)\n",
    "    print(\"predict:\", get_word(output[0]))\n",
    "    print(\"answer: \", get_word(label[0]))\n",
    "    img = img[0]\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    show_img(img)\n",
    "    plt.show()\n",
    "    break\n",
    "print(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
