{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个notebook用来可视化CRNN模型的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个是从另一个记事本中复制过来的，懒得改了\n",
    "\n",
    "def get_model_name(epoch, name):\n",
    "    return f\"{name}_{epoch}.pth\"\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    这是一个基于CNN和LSTM的CRNN模型，用于生成文本\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=128, hidden_dim=1024, io_dim=1024, num_layers=4, bidirectional=True, device='cuda:0'):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            num_classes: ...\n",
    "            hidden_dim: int, the dimension of the hidden state of the LSTM\n",
    "            io_dim: int, the dimension of the input and output of the LSTM\n",
    "            num_layers: int, the number of layers of the LSTM\n",
    "            bidirectional: bool, whether to use bidirectional LSTM\n",
    "            device: str, the device\n",
    "        \"\"\"\n",
    "        super(CRNN, self).__init__()\n",
    "        self.direction_factor = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        # num-classes对应ascii码表的128种字符\n",
    "        self.num_classes = num_classes\n",
    "        # hidden_dim是LSTM的隐藏层（hidden state）和细胞状态（cell state）的维度\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # io_dim是LSTM的输入和输出的维度\n",
    "        self.io_dim = io_dim\n",
    "        self.device = device\n",
    "        # max num of characters of the generated text\n",
    "        self.max_len = 64\n",
    "        # 1x1卷积层，用于将灰度图转换为3通道图像以适应ResNet的输入\n",
    "        self.conv1 = nn.Conv2d(1, 3, 1)\n",
    "        # 使用ResNet50作为CNN的基础模型，去掉最后一层全连接层\n",
    "        self.cnn = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])  # output dim is 2048\n",
    "        # LSTM层，输入维度为io_dim，隐藏层维度为hidden_dim\n",
    "        self.rnn = nn.LSTM(io_dim, hidden_dim, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        # 将CNN的输出转换为LSTM的隐藏状态和细胞状态\n",
    "        self.h0_fc = nn.Linear(2048, hidden_dim * num_layers * self.direction_factor)\n",
    "        self.c0_fc = nn.Linear(2048, hidden_dim * num_layers * self.direction_factor)\n",
    "        # 将LSTM的输出转换为最终的输出，即字符概率分布\n",
    "        self.out_fc = nn.Linear(hidden_dim * self.direction_factor, num_classes)\n",
    "        # 将字符的索引转换为字符的embedding\n",
    "        self.embedding = nn.Embedding(num_classes, io_dim)\n",
    "        # dropout防止过拟合\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "        self.to(device)\n",
    "    \n",
    "    def init_state(self, img):\n",
    "        # 通过CNN卷出 lstm 的 hidden state 和 cell state\n",
    "        x = self.conv1(img)         # batch_size, 3, 64, 64\n",
    "        x = self.cnn(x)             # batch_size, 512, 1, 1\n",
    "        x = x.view(x.size(0), -1)   # batch_size, 512\n",
    "        x = x.unsqueeze(0)          # 1, batch_size, 512\n",
    "        h0 = self.h0_fc(x)          # 1, batch_size, hidden_dim\n",
    "        c0 = self.c0_fc(x)          # 1, batch_size, hidden_dim\n",
    "        h0 = h0.view(-1, self.hidden_dim, self.num_layers * self.direction_factor).permute(2, 0, 1).contiguous()  # num_layers * direction_factor, batch_size, hidden_dim\n",
    "        c0 = c0.view(-1, self.hidden_dim, self.num_layers * self.direction_factor).permute(2, 0, 1).contiguous()  # num_layers * direction_factor, batch_size, hidden_dim\n",
    "        return h0, c0\n",
    "    \n",
    "    def next_char(self, x, h_c_n):\n",
    "        # print(\"next char x shape: \", x.shape)\n",
    "        h_n, c_n = h_c_n\n",
    "        # x: the embedding of the last character\n",
    "        # h_n: the hidden state of the last character\n",
    "        # c_n: the cell state of the last character\n",
    "        x, (h_n, c_n) = self.rnn(x, (h_n, c_n))\n",
    "        # print(\"next char rnn output x shape: \", x.shape)\n",
    "        x = self.out_fc(x)\n",
    "        # x = self.dropout(x)\n",
    "        # print(\"next char output x shape: \", x.shape)\n",
    "        return x, (h_n, c_n)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        batch_size = img.size(0)\n",
    "        h0, c0 = self.init_state(img)\n",
    "        x = 2  # the index of the start token\n",
    "        x = torch.tensor([x] * batch_size, dtype=torch.long).view(batch_size, 1).to(self.device)\n",
    "        x = self.embedding(x)\n",
    "        # print(\"after embedding x shape: \", x.shape)\n",
    "        h_c_n = (h0, c0)\n",
    "        output = torch.zeros(batch_size, self.max_len, self.num_classes).to(self.device)\n",
    "        output[:, 0, 2] = 1\n",
    "        for i in range(1, self.max_len):\n",
    "            x, h_c_n = self.next_char(x, h_c_n)\n",
    "            output[:, i, :] = x\n",
    "            x = x.argmax(dim=-1)\n",
    "            x = self.embedding(x)\n",
    "        return output\n",
    "    \n",
    "    def forward_beam(self, img):\n",
    "        # 使用束搜索，生成最可能的文本\n",
    "        num_beams = 10\n",
    "        batch_size = img.size(0)\n",
    "        h0, c0 = self.init_state(img)\n",
    "        x = 2  # the index of the start token\n",
    "        x = torch.tensor([x] * batch_size, dtype=torch.long).view(batch_size, 1).to(self.device)\n",
    "        x = self.embedding(x)\n",
    "        h_c_n = (h0, c0)\n",
    "        output = torch.zeros(batch_size, num_beams, self.max_len, self.num_classes, dtype=torch.long).to(self.device)\n",
    "        output[:, :, 0, 2] = 1\n",
    "        probabilities = torch.ones(batch_size, num_beams).to(self.device)\n",
    "        # 最一开始的时候只有一个beam，所以要先预测一次，得到初始的概率分布，并将其分散到num_beams个beam上\n",
    "        x, h_c_n = self.next_char(x, h_c_n)\n",
    "        x = torch.softmax(x, dim=-1).view(batch_size, -1)\n",
    "        for i in range(num_beams):\n",
    "            index = x.argmax(dim=-1)\n",
    "            output[:, i, 1, index] = 1\n",
    "            probabilities[:, i] = x[torch.arange(batch_size), index]\n",
    "            x[:, index] = 0\n",
    "        x = output[:, :, 1, :].argmax(dim=-1)\n",
    "        x = self.embedding(x)\n",
    "        # 将隐状态在beam维度上复制num_beams份\n",
    "        # 当前shape：num_layers * direction_factor, batch_size, hidden_dim\n",
    "        # 目标shape：num_layers * direction_factor, batch_size * num_beams, hidden_dim\n",
    "        h_n, c_n = h_c_n\n",
    "        h_n = h_n.unsqueeze(2)\n",
    "        h_n = torch.repeat_interleave(h_n, num_beams, 2)  # num_layers * direction_factor, batch_size, num_beams, hidden_dim\n",
    "        h_n = h_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "        c_n = c_n.unsqueeze(2)\n",
    "        c_n = torch.repeat_interleave(c_n, num_beams, 2)\n",
    "        c_n = c_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "        h_c_n = (h_n, c_n)\n",
    "        # 现在，\n",
    "        # x:                batch_size, num_beams, io_dim\n",
    "        # probabilities:    batch_size, num_beams\n",
    "        # output:           batch_size, num_beams, max_len, num_classes\n",
    "        # 接下来，每次预测一个字符，然后从中选出最可能的num_beams个预测\n",
    "        for i in range(2, self.max_len):\n",
    "            x = x.view(batch_size * num_beams, 1, -1)\n",
    "            h_n = h_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "            c_n = c_n.view(self.num_layers * self.direction_factor, batch_size * num_beams, self.hidden_dim)\n",
    "            h_c_n = (h_n, c_n)\n",
    "            x, h_c_n = self.next_char(x, h_c_n)\n",
    "            x = torch.softmax(x, dim=-1)\n",
    "            x = x.view(batch_size, num_beams, self.num_classes)\n",
    "            x = x * probabilities.view(batch_size, num_beams, 1)\n",
    "            x = x.view(batch_size, num_beams * self.num_classes)\n",
    "            # 找出最可能的num_beams个预测\n",
    "            chosens = torch.argsort(x, dim=-1, descending=True)[:, :num_beams]\n",
    "            chosens_indices = torch.nonzero(chosens, as_tuple=True)  # batch_size, num_beams\n",
    "            # 更新输出\n",
    "            new_output = torch.zeros(batch_size, num_beams, self.max_len, self.num_classes, dtype=torch.long, device=self.device)\n",
    "            new_output[chosens_indices[0], torch.arange(num_beams), i] = output[chosens_indices[0], \n",
    "            break\n",
    "        return\n",
    "\n",
    "\n",
    "        # for i in range(1, self.max_len):\n",
    "        #     x, h_c_n = self.next_char(x, h_c_n)\n",
    "        #     x = torch.softmax(x, dim=-1)\n",
    "        #     x = x.view(num_beams, -1)\n",
    "        #     x = x * probabilities.view(num_beams, 1)\n",
    "        #     # 找出最可能的num_beams个预测\n",
    "        #     chosen = torch.argsort(x.view(-1), descending=True)[:num_beams]\n",
    "        #     chosen_beams = chosen // self.num_classes\n",
    "        #     chosen_chars = chosen % self.num_classes\n",
    "        #     # 更新概率\n",
    "        #     probabilities = x.view(-1)[chosen]\n",
    "        #     print(probabilities)\n",
    "        #     # 更新输出\n",
    "        #     output = output[chosen_beams]\n",
    "        #     output[:, i, chosen_chars] = 1\n",
    "        #     # 更新输入\n",
    "        #     x = chosen_chars.view(num_beams, 1)\n",
    "        #     x = self.embedding(x)\n",
    "        return output, probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = CRNN()\n",
    "model_name = get_model_name(7, \"CRNN\")\n",
    "model_path = \"/root/autodl-tmp/APS360_Project/Machine_Learning_Output/CRNN/\"\n",
    "model.load_state_dict(torch.load(model_path + model_name, weights_only=True))\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "\n",
    "def show_img(img):\n",
    "    img = img.squeeze().cpu().numpy()\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def get_word(output):\n",
    "    output = output.cpu().detach().numpy()\n",
    "    word = \"\"\n",
    "    for i in range(1, 64):\n",
    "        o = np.argmax(output[i])\n",
    "        if o == 3:\n",
    "            break\n",
    "        c = chr(o)\n",
    "        word += c\n",
    "    return word\n",
    "\n",
    "# test\n",
    "dataset = RecDataset(\"IAM\", \"val\")\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 0, 6, 7, 8]], device='cuda:0')\n",
      "(tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), tensor([1, 2, 3, 4, 5, 7, 8, 9], device='cuda:0'))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (img, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      2\u001b[0m     img, label \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m), label\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     output, probability \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward_beam(img)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict:\u001b[39m\u001b[38;5;124m\"\u001b[39m, get_word(output[i]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability:\u001b[39m\u001b[38;5;124m\"\u001b[39m, probability[i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "for step, (img, label) in enumerate(train_loader):\n",
    "    img, label = img.to(\"cuda:0\"), label.to(\"cuda:0\")\n",
    "    output, probability = model.forward_beam(img)\n",
    "    for i in range(10):\n",
    "        print(\"predict:\", get_word(output[i]), \"probability:\", probability[i].item())\n",
    "    print(\"answer: \", get_word(label[0]))\n",
    "    img = img[0]\n",
    "    # print(img.min().item(), img.max().item(), img.mean().item())\n",
    "    \n",
    "    show_img(img)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
