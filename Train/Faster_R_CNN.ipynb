{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个文件用来训练Segmentation模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的Faster R-CNN模型\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "\n",
    "# 获取分类器的输入特征数\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# 替换预训练的头部为一个新的，只有两个类别（背景和单词）\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.trans = transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        img -= img.mean()\n",
    "        img /= img.std()\n",
    "        # img = self.trans(img)\n",
    "\n",
    "        # 将 (x, y, w, h) 格式的边界框转换为 (x1, y1, x2, y2) 格式\n",
    "        label[:, 2] = label[:, 0] + label[:, 2]\n",
    "        label[:, 3] = label[:, 1] + label[:, 3]\n",
    "\n",
    "        # 仅保留包含单词的边界框\n",
    "        indices = label.sum(dim=-1) > 0\n",
    "        label = label[indices]\n",
    "\n",
    "        # 制造classifier的标签\n",
    "        temp = torch.ones(len(label), dtype=torch.long)\n",
    "        label = {'boxes': label, 'labels': temp}\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    # 使用默认的 collate 处理图片（因为图片大小相同）\n",
    "    images = default_collate(images)\n",
    "    \n",
    "    # 不尝试合并 targets，因为它们包含不同数量的边界框\n",
    "    # 直接作为列表返回\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ModifiedDataset(SegDataset('IAM', 'train'))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 step 0 loss: 3.180299758911133\n",
      "Epoch 0 step 1 loss: 4.038980484008789\n",
      "Epoch 0 step 2 loss: 3.400888204574585\n",
      "Epoch 0 step 3 loss: 2.805983066558838\n",
      "Epoch 0 step 4 loss: 3.053529977798462\n",
      "Epoch 0 step 5 loss: 2.9373779296875\n",
      "Epoch 0 step 6 loss: 2.796520948410034\n",
      "Epoch 0 step 7 loss: 2.8418173789978027\n",
      "Epoch 0 step 8 loss: 2.8542990684509277\n",
      "Epoch 0 step 9 loss: 2.8125131130218506\n",
      "Epoch 0 step 10 loss: 2.76536226272583\n",
      "Epoch 0 step 11 loss: 2.725536584854126\n",
      "Epoch 0 step 12 loss: 2.750455379486084\n",
      "Epoch 0 step 13 loss: 2.7165558338165283\n",
      "Epoch 0 step 14 loss: 2.678511619567871\n",
      "Epoch 0 step 15 loss: 2.6542582511901855\n",
      "Epoch 0 step 16 loss: 2.5888171195983887\n",
      "Epoch 0 step 17 loss: 2.6470413208007812\n",
      "Epoch 0 step 18 loss: 2.6519579887390137\n",
      "Epoch 0 step 19 loss: 2.6029562950134277\n",
      "Epoch 0 step 20 loss: 2.5891218185424805\n",
      "Epoch 0 step 21 loss: 2.587179183959961\n",
      "Epoch 0 step 22 loss: 2.5505104064941406\n",
      "Epoch 0 step 23 loss: 2.5062966346740723\n",
      "Epoch 0 step 24 loss: 2.567988634109497\n",
      "Epoch 0 step 25 loss: 2.5212016105651855\n",
      "Epoch 0 step 26 loss: 2.468451499938965\n",
      "Epoch 0 step 27 loss: 2.5299928188323975\n",
      "Epoch 0 step 28 loss: 2.4608676433563232\n",
      "Epoch 0 step 29 loss: 2.5171597003936768\n",
      "Epoch 0 step 30 loss: 2.3679912090301514\n",
      "Epoch 0 step 31 loss: 2.431220054626465\n",
      "Epoch 0 step 32 loss: 2.354043483734131\n",
      "Epoch 0 step 33 loss: 2.427164077758789\n",
      "Epoch 0 step 34 loss: 2.407613754272461\n",
      "Epoch 0 step 35 loss: 2.392595052719116\n",
      "Epoch 0 step 36 loss: 2.347870349884033\n",
      "Epoch 0 step 37 loss: 2.35306715965271\n",
      "Epoch 0 step 38 loss: 2.257352113723755\n",
      "Epoch 0 loss: 2.257352113723755\n",
      "Epoch 1 step 0 loss: 2.374342203140259\n",
      "Epoch 1 step 1 loss: 2.174917459487915\n",
      "Epoch 1 step 2 loss: 1.8204319477081299\n",
      "Epoch 1 step 3 loss: 1.6029919385910034\n",
      "Epoch 1 step 4 loss: 1.5372427701950073\n",
      "Epoch 1 step 5 loss: 1.3940246105194092\n",
      "Epoch 1 step 6 loss: 1.3545335531234741\n",
      "Epoch 1 step 7 loss: 1.3119826316833496\n",
      "Epoch 1 step 8 loss: 1.2943456172943115\n",
      "Epoch 1 step 9 loss: 1.3248095512390137\n",
      "Epoch 1 step 10 loss: 1.3098809719085693\n",
      "Epoch 1 step 11 loss: 1.3419113159179688\n",
      "Epoch 1 step 12 loss: 1.4807968139648438\n",
      "Epoch 1 step 13 loss: 1.6618025302886963\n",
      "Epoch 1 step 14 loss: 1.776686191558838\n",
      "Epoch 1 step 15 loss: 1.797912359237671\n",
      "Epoch 1 step 16 loss: 1.7333941459655762\n",
      "Epoch 1 step 17 loss: 1.7488189935684204\n",
      "Epoch 1 step 18 loss: 1.7325690984725952\n",
      "Epoch 1 step 19 loss: 1.77301025390625\n",
      "Epoch 1 step 20 loss: 1.7526018619537354\n",
      "Epoch 1 step 21 loss: 1.6378095149993896\n",
      "Epoch 1 step 22 loss: 1.5593222379684448\n",
      "Epoch 1 step 23 loss: 1.5616261959075928\n",
      "Epoch 1 step 24 loss: 1.5638737678527832\n",
      "Epoch 1 step 25 loss: 1.558171033859253\n",
      "Epoch 1 step 26 loss: 1.5964277982711792\n",
      "Epoch 1 step 27 loss: 1.5349608659744263\n",
      "Epoch 1 step 28 loss: 1.502575159072876\n",
      "Epoch 1 step 29 loss: 1.5058459043502808\n",
      "Epoch 1 step 30 loss: 1.4537643194198608\n",
      "Epoch 1 step 31 loss: 1.4259133338928223\n",
      "Epoch 1 step 32 loss: 1.439111590385437\n",
      "Epoch 1 step 33 loss: 1.4342020750045776\n",
      "Epoch 1 step 34 loss: 1.409639835357666\n",
      "Epoch 1 step 35 loss: 1.4285931587219238\n",
      "Epoch 1 step 36 loss: 1.425715684890747\n",
      "Epoch 1 step 37 loss: 1.431659460067749\n",
      "Epoch 1 step 38 loss: 1.4267317056655884\n",
      "Epoch 1 loss: 1.4267317056655884\n",
      "Epoch 2 step 0 loss: 1.2845631837844849\n",
      "Epoch 2 step 1 loss: 1.2458686828613281\n",
      "Epoch 2 step 2 loss: 1.2366111278533936\n",
      "Epoch 2 step 3 loss: 1.2456445693969727\n",
      "Epoch 2 step 4 loss: 1.2197390794754028\n",
      "Epoch 2 step 5 loss: 1.1771774291992188\n",
      "Epoch 2 step 6 loss: 1.1688958406448364\n",
      "Epoch 2 step 7 loss: 1.1538679599761963\n",
      "Epoch 2 step 8 loss: 1.1534889936447144\n",
      "Epoch 2 step 9 loss: 1.13931143283844\n",
      "Epoch 2 step 10 loss: 1.122991681098938\n",
      "Epoch 2 step 11 loss: 1.1324833631515503\n",
      "Epoch 2 step 12 loss: 1.109100341796875\n",
      "Epoch 2 step 13 loss: 1.1019057035446167\n",
      "Epoch 2 step 14 loss: 1.1021748781204224\n",
      "Epoch 2 step 15 loss: 1.0807331800460815\n",
      "Epoch 2 step 16 loss: 1.0243648290634155\n",
      "Epoch 2 step 17 loss: 1.0820376873016357\n",
      "Epoch 2 step 18 loss: 1.00315523147583\n",
      "Epoch 2 step 19 loss: 1.0081087350845337\n",
      "Epoch 2 step 20 loss: 1.00010085105896\n",
      "Epoch 2 step 21 loss: 1.0844614505767822\n",
      "Epoch 2 step 22 loss: 1.0126254558563232\n",
      "Epoch 2 step 23 loss: 1.0438189506530762\n",
      "Epoch 2 step 24 loss: 1.0190216302871704\n",
      "Epoch 2 step 25 loss: 0.986087441444397\n",
      "Epoch 2 step 26 loss: 1.0118963718414307\n",
      "Epoch 2 step 27 loss: 1.0244320631027222\n",
      "Epoch 2 step 28 loss: 0.9931755065917969\n",
      "Epoch 2 step 29 loss: 1.0396087169647217\n",
      "Epoch 2 step 30 loss: 1.033182144165039\n",
      "Epoch 2 step 31 loss: 0.9800678491592407\n",
      "Epoch 2 step 32 loss: 0.981290876865387\n",
      "Epoch 2 step 33 loss: 0.9849294424057007\n",
      "Epoch 2 step 34 loss: 0.9707702398300171\n",
      "Epoch 2 step 35 loss: 0.9720332026481628\n",
      "Epoch 2 step 36 loss: 0.9832570552825928\n",
      "Epoch 2 step 37 loss: 0.9639599323272705\n",
      "Epoch 2 step 38 loss: 0.9323711395263672\n",
      "Epoch 2 loss: 0.9323711395263672\n",
      "Epoch 3 step 0 loss: 0.8178306818008423\n",
      "Epoch 3 step 1 loss: 0.8000050187110901\n",
      "Epoch 3 step 2 loss: 0.8276873230934143\n",
      "Epoch 3 step 3 loss: 0.7862210869789124\n",
      "Epoch 3 step 4 loss: 0.7484973669052124\n",
      "Epoch 3 step 5 loss: 0.7331951856613159\n",
      "Epoch 3 step 6 loss: 0.7534292340278625\n",
      "Epoch 3 step 7 loss: 0.738349437713623\n",
      "Epoch 3 step 8 loss: 0.7567428350448608\n",
      "Epoch 3 step 9 loss: 0.727819561958313\n",
      "Epoch 3 step 10 loss: 0.7867759466171265\n",
      "Epoch 3 step 11 loss: 0.7276129722595215\n",
      "Epoch 3 step 12 loss: 0.7073374390602112\n",
      "Epoch 3 step 13 loss: 0.7031123042106628\n",
      "Epoch 3 step 14 loss: 0.7364574074745178\n",
      "Epoch 3 step 15 loss: 0.7220762372016907\n",
      "Epoch 3 step 16 loss: 0.7476602792739868\n",
      "Epoch 3 step 17 loss: 0.7352370023727417\n",
      "Epoch 3 step 18 loss: 0.7065222859382629\n",
      "Epoch 3 step 19 loss: 0.7471228837966919\n",
      "Epoch 3 step 20 loss: 0.7088773846626282\n",
      "Epoch 3 step 21 loss: 0.7369396686553955\n",
      "Epoch 3 step 22 loss: 0.7689006924629211\n",
      "Epoch 3 step 23 loss: 0.6959475874900818\n",
      "Epoch 3 step 24 loss: 0.6918833255767822\n",
      "Epoch 3 step 25 loss: 0.7411531209945679\n",
      "Epoch 3 step 26 loss: 0.7167468070983887\n",
      "Epoch 3 step 27 loss: 0.7285033464431763\n",
      "Epoch 3 step 28 loss: 0.7059687376022339\n",
      "Epoch 3 step 29 loss: 0.68607097864151\n",
      "Epoch 3 step 30 loss: 0.660948634147644\n",
      "Epoch 3 step 31 loss: 0.7450112700462341\n",
      "Epoch 3 step 32 loss: 0.7325687408447266\n",
      "Epoch 3 step 33 loss: 0.748160719871521\n",
      "Epoch 3 step 34 loss: 0.6860198974609375\n",
      "Epoch 3 step 35 loss: 0.67641282081604\n",
      "Epoch 3 step 36 loss: 0.6591229438781738\n",
      "Epoch 3 step 37 loss: 0.6531950831413269\n",
      "Epoch 3 step 38 loss: 0.6780127286911011\n",
      "Epoch 3 loss: 0.6780127286911011\n",
      "Epoch 4 step 0 loss: 0.5974682569503784\n",
      "Epoch 4 step 1 loss: 0.590394914150238\n",
      "Epoch 4 step 2 loss: 0.5528104305267334\n",
      "Epoch 4 step 3 loss: 0.5220150351524353\n",
      "Epoch 4 step 4 loss: 0.5397020578384399\n",
      "Epoch 4 step 5 loss: 0.586298942565918\n",
      "Epoch 4 step 6 loss: 0.5286686420440674\n",
      "Epoch 4 step 7 loss: 0.55989009141922\n",
      "Epoch 4 step 8 loss: 0.551138162612915\n",
      "Epoch 4 step 9 loss: 0.46666091680526733\n",
      "Epoch 4 step 10 loss: 0.6203525066375732\n",
      "Epoch 4 step 11 loss: 0.589392900466919\n",
      "Epoch 4 step 12 loss: 0.5269012451171875\n",
      "Epoch 4 step 13 loss: 0.5802741646766663\n",
      "Epoch 4 step 14 loss: 0.5287119150161743\n",
      "Epoch 4 step 15 loss: 0.5845645666122437\n",
      "Epoch 4 step 16 loss: 0.6056639552116394\n",
      "Epoch 4 step 17 loss: 0.5308219194412231\n",
      "Epoch 4 step 18 loss: 0.5039533376693726\n",
      "Epoch 4 step 19 loss: 0.5514204502105713\n",
      "Epoch 4 step 20 loss: 0.5595747828483582\n",
      "Epoch 4 step 21 loss: 0.5464799404144287\n",
      "Epoch 4 step 22 loss: 0.5781804919242859\n",
      "Epoch 4 step 23 loss: 0.5259499549865723\n",
      "Epoch 4 step 24 loss: 0.5028536319732666\n",
      "Epoch 4 step 25 loss: 0.4598105847835541\n",
      "Epoch 4 step 26 loss: 0.5935634970664978\n",
      "Epoch 4 step 27 loss: 0.6238123178482056\n",
      "Epoch 4 step 28 loss: 0.5430008172988892\n",
      "Epoch 4 step 29 loss: 0.5266907215118408\n",
      "Epoch 4 step 30 loss: 0.6115849018096924\n",
      "Epoch 4 step 31 loss: 0.4807599186897278\n",
      "Epoch 4 step 32 loss: 0.5745421648025513\n",
      "Epoch 4 step 33 loss: 0.5397729873657227\n",
      "Epoch 4 step 34 loss: 0.5197193622589111\n",
      "Epoch 4 step 35 loss: 0.5532413721084595\n",
      "Epoch 4 step 36 loss: 0.5126771330833435\n",
      "Epoch 4 step 37 loss: 0.5572217702865601\n",
      "Epoch 4 step 38 loss: 0.530561089515686\n",
      "Epoch 4 loss: 0.530561089515686\n",
      "Epoch 5 step 0 loss: 0.4636409878730774\n",
      "Epoch 5 step 1 loss: 0.4885958135128021\n",
      "Epoch 5 step 2 loss: 0.4756716191768646\n",
      "Epoch 5 step 3 loss: 0.4478786885738373\n",
      "Epoch 5 step 4 loss: 0.4464397132396698\n",
      "Epoch 5 step 5 loss: 0.5315500497817993\n",
      "Epoch 5 step 6 loss: 0.45742228627204895\n",
      "Epoch 5 step 7 loss: 0.5120081901550293\n",
      "Epoch 5 step 8 loss: 0.4846264123916626\n",
      "Epoch 5 step 9 loss: 0.4430115818977356\n",
      "Epoch 5 step 10 loss: 0.4607643485069275\n",
      "Epoch 5 step 11 loss: 0.4722180664539337\n",
      "Epoch 5 step 12 loss: 0.4056214988231659\n",
      "Epoch 5 step 13 loss: 0.5006942749023438\n",
      "Epoch 5 step 14 loss: 0.5044305324554443\n",
      "Epoch 5 step 15 loss: 0.47437506914138794\n",
      "Epoch 5 step 16 loss: 0.403091698884964\n",
      "Epoch 5 step 17 loss: 0.4024518132209778\n",
      "Epoch 5 step 18 loss: 0.4943675994873047\n",
      "Epoch 5 step 19 loss: 0.49494031071662903\n",
      "Epoch 5 step 20 loss: 0.4697861075401306\n",
      "Epoch 5 step 21 loss: 0.46444010734558105\n",
      "Epoch 5 step 22 loss: 0.4279186427593231\n",
      "Epoch 5 step 23 loss: 0.49654367566108704\n",
      "Epoch 5 step 24 loss: 0.47782227396965027\n",
      "Epoch 5 step 25 loss: 0.43179047107696533\n",
      "Epoch 5 step 26 loss: 0.44628721475601196\n",
      "Epoch 5 step 27 loss: 0.44386497139930725\n",
      "Epoch 5 step 28 loss: 0.4483679533004761\n",
      "Epoch 5 step 29 loss: 0.4708137512207031\n",
      "Epoch 5 step 30 loss: 0.47314000129699707\n",
      "Epoch 5 step 31 loss: 0.4975786805152893\n",
      "Epoch 5 step 32 loss: 0.4486220180988312\n",
      "Epoch 5 step 33 loss: 0.45814910531044006\n",
      "Epoch 5 step 34 loss: 0.4358152449131012\n",
      "Epoch 5 step 35 loss: 0.44929563999176025\n",
      "Epoch 5 step 36 loss: 0.3900910019874573\n",
      "Epoch 5 step 37 loss: 0.40648409724235535\n",
      "Epoch 5 step 38 loss: 0.32801318168640137\n",
      "Epoch 5 loss: 0.32801318168640137\n",
      "Epoch 6 step 0 loss: 0.4428294003009796\n",
      "Epoch 6 step 1 loss: 0.44219374656677246\n",
      "Epoch 6 step 2 loss: 0.4525696635246277\n",
      "Epoch 6 step 3 loss: 0.49047309160232544\n",
      "Epoch 6 step 4 loss: 0.3587152361869812\n",
      "Epoch 6 step 5 loss: 0.4611980617046356\n",
      "Epoch 6 step 6 loss: 0.4237407445907593\n",
      "Epoch 6 step 7 loss: 0.44206637144088745\n",
      "Epoch 6 step 8 loss: 0.4185906648635864\n",
      "Epoch 6 step 9 loss: 0.3840249180793762\n",
      "Epoch 6 step 10 loss: 0.41386324167251587\n",
      "Epoch 6 step 11 loss: 0.35019451379776\n",
      "Epoch 6 step 12 loss: 0.34334489703178406\n",
      "Epoch 6 step 13 loss: 0.35408228635787964\n",
      "Epoch 6 step 14 loss: 0.42820248007774353\n",
      "Epoch 6 step 15 loss: 0.3801918625831604\n",
      "Epoch 6 step 16 loss: 0.4016960859298706\n",
      "Epoch 6 step 17 loss: 0.37518179416656494\n",
      "Epoch 6 step 18 loss: 0.3805764317512512\n",
      "Epoch 6 step 19 loss: 0.4197492003440857\n",
      "Epoch 6 step 20 loss: 0.4668665826320648\n",
      "Epoch 6 step 21 loss: 0.41377270221710205\n",
      "Epoch 6 step 22 loss: 0.36430275440216064\n",
      "Epoch 6 step 23 loss: 0.43060609698295593\n",
      "Epoch 6 step 24 loss: 0.44105610251426697\n",
      "Epoch 6 step 25 loss: 0.4717477858066559\n",
      "Epoch 6 step 26 loss: 0.3509353995323181\n",
      "Epoch 6 step 27 loss: 0.3960210084915161\n",
      "Epoch 6 step 28 loss: 0.40271061658859253\n",
      "Epoch 6 step 29 loss: 0.38146764039993286\n",
      "Epoch 6 step 30 loss: 0.3979095220565796\n",
      "Epoch 6 step 31 loss: 0.45535311102867126\n",
      "Epoch 6 step 32 loss: 0.3755064308643341\n",
      "Epoch 6 step 33 loss: 0.41873010993003845\n",
      "Epoch 6 step 34 loss: 0.4374055862426758\n",
      "Epoch 6 step 35 loss: 0.4250260293483734\n",
      "Epoch 6 step 36 loss: 0.3434305191040039\n",
      "Epoch 6 step 37 loss: 0.38791394233703613\n",
      "Epoch 6 step 38 loss: 0.41439133882522583\n",
      "Epoch 6 loss: 0.41439133882522583\n",
      "Epoch 7 step 0 loss: 0.4137496054172516\n",
      "Epoch 7 step 1 loss: 0.36882221698760986\n",
      "Epoch 7 step 2 loss: 0.3734948933124542\n",
      "Epoch 7 step 3 loss: 0.40339404344558716\n",
      "Epoch 7 step 4 loss: 0.38455402851104736\n",
      "Epoch 7 step 5 loss: 0.3650907278060913\n",
      "Epoch 7 step 6 loss: 0.36335811018943787\n",
      "Epoch 7 step 7 loss: 0.39828166365623474\n",
      "Epoch 7 step 8 loss: 0.37782949209213257\n",
      "Epoch 7 step 9 loss: 0.3844827711582184\n",
      "Epoch 7 step 10 loss: 0.40861475467681885\n",
      "Epoch 7 step 11 loss: 0.3548802137374878\n",
      "Epoch 7 step 12 loss: 0.39918163418769836\n",
      "Epoch 7 step 13 loss: 0.37566059827804565\n",
      "Epoch 7 step 14 loss: 0.3168398439884186\n",
      "Epoch 7 step 15 loss: 0.36791741847991943\n",
      "Epoch 7 step 16 loss: 0.365416556596756\n",
      "Epoch 7 step 17 loss: 0.41322940587997437\n",
      "Epoch 7 step 18 loss: 0.39895394444465637\n",
      "Epoch 7 step 19 loss: 0.38901472091674805\n",
      "Epoch 7 step 20 loss: 0.3967073857784271\n",
      "Epoch 7 step 21 loss: 0.40237921476364136\n",
      "Epoch 7 step 22 loss: 0.37143152952194214\n",
      "Epoch 7 step 23 loss: 0.3441329598426819\n",
      "Epoch 7 step 24 loss: 0.4017513394355774\n",
      "Epoch 7 step 25 loss: 0.3493702709674835\n",
      "Epoch 7 step 26 loss: 0.365802526473999\n",
      "Epoch 7 step 27 loss: 0.3708227276802063\n",
      "Epoch 7 step 28 loss: 0.38090699911117554\n",
      "Epoch 7 step 29 loss: 0.43611466884613037\n",
      "Epoch 7 step 30 loss: 0.3490453362464905\n",
      "Epoch 7 step 31 loss: 0.41651803255081177\n",
      "Epoch 7 step 32 loss: 0.4007568359375\n",
      "Epoch 7 step 33 loss: 0.3917211890220642\n",
      "Epoch 7 step 34 loss: 0.34433555603027344\n",
      "Epoch 7 step 35 loss: 0.416764497756958\n",
      "Epoch 7 step 36 loss: 0.2971624732017517\n",
      "Epoch 7 step 37 loss: 0.43865886330604553\n",
      "Epoch 7 step 38 loss: 0.3497394621372223\n",
      "Epoch 7 loss: 0.3497394621372223\n",
      "Epoch 8 step 0 loss: 0.36981236934661865\n",
      "Epoch 8 step 1 loss: 0.42289090156555176\n",
      "Epoch 8 step 2 loss: 0.37848955392837524\n",
      "Epoch 8 step 3 loss: 0.37737274169921875\n",
      "Epoch 8 step 4 loss: 0.45821017026901245\n",
      "Epoch 8 step 5 loss: 0.37457382678985596\n",
      "Epoch 8 step 6 loss: 0.4033016562461853\n",
      "Epoch 8 step 7 loss: 0.4010811448097229\n",
      "Epoch 8 step 8 loss: 0.3567550778388977\n",
      "Epoch 8 step 9 loss: 0.3947766423225403\n",
      "Epoch 8 step 10 loss: 0.3703713119029999\n",
      "Epoch 8 step 11 loss: 0.3482714593410492\n",
      "Epoch 8 step 12 loss: 0.4120211899280548\n",
      "Epoch 8 step 13 loss: 0.3409936726093292\n",
      "Epoch 8 step 14 loss: 0.3711579740047455\n",
      "Epoch 8 step 15 loss: 0.348768949508667\n",
      "Epoch 8 step 16 loss: 0.3628327548503876\n",
      "Epoch 8 step 17 loss: 0.37522587180137634\n",
      "Epoch 8 step 18 loss: 0.4108862280845642\n",
      "Epoch 8 step 19 loss: 0.33043524622917175\n",
      "Epoch 8 step 20 loss: 0.3714808225631714\n",
      "Epoch 8 step 21 loss: 0.322942316532135\n",
      "Epoch 8 step 22 loss: 0.3595350682735443\n",
      "Epoch 8 step 23 loss: 0.3876512050628662\n",
      "Epoch 8 step 24 loss: 0.368443101644516\n",
      "Epoch 8 step 25 loss: 0.324077844619751\n",
      "Epoch 8 step 26 loss: 0.38609832525253296\n",
      "Epoch 8 step 27 loss: 0.35603153705596924\n",
      "Epoch 8 step 28 loss: 0.38916707038879395\n",
      "Epoch 8 step 29 loss: 0.39345529675483704\n",
      "Epoch 8 step 30 loss: 0.3516925275325775\n",
      "Epoch 8 step 31 loss: 0.40068650245666504\n",
      "Epoch 8 step 32 loss: 0.37796759605407715\n",
      "Epoch 8 step 33 loss: 0.35995733737945557\n",
      "Epoch 8 step 34 loss: 0.36707791686058044\n",
      "Epoch 8 step 35 loss: 0.37776580452919006\n",
      "Epoch 8 step 36 loss: 0.36351191997528076\n",
      "Epoch 8 step 37 loss: 0.325695276260376\n",
      "Epoch 8 step 38 loss: 0.33582252264022827\n",
      "Epoch 8 loss: 0.33582252264022827\n",
      "Epoch 9 step 0 loss: 0.34728625416755676\n",
      "Epoch 9 step 1 loss: 0.38529515266418457\n",
      "Epoch 9 step 2 loss: 0.4397026300430298\n",
      "Epoch 9 step 3 loss: 0.3405591547489166\n",
      "Epoch 9 step 4 loss: 0.40859031677246094\n",
      "Epoch 9 step 5 loss: 0.37763285636901855\n",
      "Epoch 9 step 6 loss: 0.3252469301223755\n",
      "Epoch 9 step 7 loss: 0.40159401297569275\n",
      "Epoch 9 step 8 loss: 0.45633143186569214\n",
      "Epoch 9 step 9 loss: 0.376994252204895\n",
      "Epoch 9 step 10 loss: 0.3917579650878906\n",
      "Epoch 9 step 11 loss: 0.37288370728492737\n",
      "Epoch 9 step 12 loss: 0.3745153844356537\n",
      "Epoch 9 step 13 loss: 0.39155837893486023\n",
      "Epoch 9 step 14 loss: 0.4051055312156677\n",
      "Epoch 9 step 15 loss: 0.4132479727268219\n",
      "Epoch 9 step 16 loss: 0.34424853324890137\n",
      "Epoch 9 step 17 loss: 0.34336555004119873\n",
      "Epoch 9 step 18 loss: 0.4190216660499573\n",
      "Epoch 9 step 19 loss: 0.35451221466064453\n",
      "Epoch 9 step 20 loss: 0.3438248634338379\n",
      "Epoch 9 step 21 loss: 0.3861122131347656\n",
      "Epoch 9 step 22 loss: 0.31024160981178284\n",
      "Epoch 9 step 23 loss: 0.3567045331001282\n",
      "Epoch 9 step 24 loss: 0.30585914850234985\n",
      "Epoch 9 step 25 loss: 0.393079936504364\n",
      "Epoch 9 step 26 loss: 0.34116774797439575\n",
      "Epoch 9 step 27 loss: 0.36131685972213745\n",
      "Epoch 9 step 28 loss: 0.39465898275375366\n",
      "Epoch 9 step 29 loss: 0.3597455620765686\n",
      "Epoch 9 step 30 loss: 0.39669084548950195\n",
      "Epoch 9 step 31 loss: 0.35592228174209595\n",
      "Epoch 9 step 32 loss: 0.3973362445831299\n",
      "Epoch 9 step 33 loss: 0.3543322682380676\n",
      "Epoch 9 step 34 loss: 0.34306061267852783\n",
      "Epoch 9 step 35 loss: 0.3201819062232971\n",
      "Epoch 9 step 36 loss: 0.3631945252418518\n",
      "Epoch 9 step 37 loss: 0.3198838233947754\n",
      "Epoch 9 step 38 loss: 0.39503008127212524\n",
      "Epoch 9 loss: 0.39503008127212524\n",
      "Epoch 10 step 0 loss: 0.3794804811477661\n",
      "Epoch 10 step 1 loss: 0.3663111627101898\n",
      "Epoch 10 step 2 loss: 0.389104962348938\n",
      "Epoch 10 step 3 loss: 0.37876152992248535\n",
      "Epoch 10 step 4 loss: 0.3465978503227234\n",
      "Epoch 10 step 5 loss: 0.3608759641647339\n",
      "Epoch 10 step 6 loss: 0.41565990447998047\n",
      "Epoch 10 step 7 loss: 0.40356308221817017\n",
      "Epoch 10 step 8 loss: 0.37249505519866943\n",
      "Epoch 10 step 9 loss: 0.33675986528396606\n",
      "Epoch 10 step 10 loss: 0.3906238377094269\n",
      "Epoch 10 step 11 loss: 0.41808128356933594\n",
      "Epoch 10 step 12 loss: 0.36487019062042236\n",
      "Epoch 10 step 13 loss: 0.36102426052093506\n",
      "Epoch 10 step 14 loss: 0.3537556529045105\n",
      "Epoch 10 step 15 loss: 0.3539835512638092\n",
      "Epoch 10 step 16 loss: 0.35763588547706604\n",
      "Epoch 10 step 17 loss: 0.37523210048675537\n",
      "Epoch 10 step 18 loss: 0.39468830823898315\n",
      "Epoch 10 step 19 loss: 0.40308961272239685\n",
      "Epoch 10 step 20 loss: 0.3622398376464844\n",
      "Epoch 10 step 21 loss: 0.36092081665992737\n",
      "Epoch 10 step 22 loss: 0.3665458559989929\n",
      "Epoch 10 step 23 loss: 0.39087432622909546\n",
      "Epoch 10 step 24 loss: 0.35146740078926086\n",
      "Epoch 10 step 25 loss: 0.35822466015815735\n",
      "Epoch 10 step 26 loss: 0.3979555368423462\n",
      "Epoch 10 step 27 loss: 0.3728456497192383\n",
      "Epoch 10 step 28 loss: 0.3672173321247101\n",
      "Epoch 10 step 29 loss: 0.3913900852203369\n",
      "Epoch 10 step 30 loss: 0.3832908272743225\n",
      "Epoch 10 step 31 loss: 0.39441925287246704\n",
      "Epoch 10 step 32 loss: 0.39305686950683594\n",
      "Epoch 10 step 33 loss: 0.3652922511100769\n",
      "Epoch 10 step 34 loss: 0.38002562522888184\n",
      "Epoch 10 step 35 loss: 0.3725486397743225\n",
      "Epoch 10 step 36 loss: 0.31916195154190063\n",
      "Epoch 10 step 37 loss: 0.39251863956451416\n",
      "Epoch 10 step 38 loss: 0.40015268325805664\n",
      "Epoch 10 loss: 0.40015268325805664\n",
      "Epoch 11 step 0 loss: 0.4015575051307678\n",
      "Epoch 11 step 1 loss: 0.3517005145549774\n",
      "Epoch 11 step 2 loss: 0.3802061676979065\n",
      "Epoch 11 step 3 loss: 0.35028302669525146\n",
      "Epoch 11 step 4 loss: 0.377392053604126\n",
      "Epoch 11 step 5 loss: 0.3886834383010864\n",
      "Epoch 11 step 6 loss: 0.3807215690612793\n",
      "Epoch 11 step 7 loss: 0.3638840615749359\n",
      "Epoch 11 step 8 loss: 0.37707483768463135\n",
      "Epoch 11 step 9 loss: 0.3475518226623535\n",
      "Epoch 11 step 10 loss: 0.331999808549881\n",
      "Epoch 11 step 11 loss: 0.36686646938323975\n",
      "Epoch 11 step 12 loss: 0.3844442367553711\n",
      "Epoch 11 step 13 loss: 0.37012994289398193\n",
      "Epoch 11 step 14 loss: 0.3943328559398651\n",
      "Epoch 11 step 15 loss: 0.371265172958374\n",
      "Epoch 11 step 16 loss: 0.39940959215164185\n",
      "Epoch 11 step 17 loss: 0.37685614824295044\n",
      "Epoch 11 step 18 loss: 0.35608792304992676\n",
      "Epoch 11 step 19 loss: 0.38699179887771606\n",
      "Epoch 11 step 20 loss: 0.37012943625450134\n",
      "Epoch 11 step 21 loss: 0.3875278830528259\n",
      "Epoch 11 step 22 loss: 0.34858447313308716\n",
      "Epoch 11 step 23 loss: 0.31874871253967285\n",
      "Epoch 11 step 24 loss: 0.3757578134536743\n",
      "Epoch 11 step 25 loss: 0.3428771197795868\n",
      "Epoch 11 step 26 loss: 0.38778746128082275\n",
      "Epoch 11 step 27 loss: 0.3924024999141693\n",
      "Epoch 11 step 28 loss: 0.393665611743927\n",
      "Epoch 11 step 29 loss: 0.3196132779121399\n",
      "Epoch 11 step 30 loss: 0.3368088901042938\n",
      "Epoch 11 step 31 loss: 0.35912007093429565\n",
      "Epoch 11 step 32 loss: 0.40907061100006104\n",
      "Epoch 11 step 33 loss: 0.42699533700942993\n",
      "Epoch 11 step 34 loss: 0.3281143009662628\n",
      "Epoch 11 step 35 loss: 0.3926585614681244\n",
      "Epoch 11 step 36 loss: 0.4376920759677887\n",
      "Epoch 11 step 37 loss: 0.35343846678733826\n",
      "Epoch 11 step 38 loss: 0.32536157965660095\n",
      "Epoch 11 loss: 0.32536157965660095\n",
      "Epoch 12 step 0 loss: 0.4271092116832733\n",
      "Epoch 12 step 1 loss: 0.36977261304855347\n",
      "Epoch 12 step 2 loss: 0.4335906207561493\n",
      "Epoch 12 step 3 loss: 0.40037673711776733\n",
      "Epoch 12 step 4 loss: 0.39680203795433044\n",
      "Epoch 12 step 5 loss: 0.4278607964515686\n",
      "Epoch 12 step 6 loss: 0.3684139847755432\n",
      "Epoch 12 step 7 loss: 0.4254741668701172\n",
      "Epoch 12 step 8 loss: 0.39809074997901917\n",
      "Epoch 12 step 9 loss: 0.3419506251811981\n",
      "Epoch 12 step 10 loss: 0.37856265902519226\n",
      "Epoch 12 step 11 loss: 0.39752086997032166\n",
      "Epoch 12 step 12 loss: 0.40371018648147583\n",
      "Epoch 12 step 13 loss: 0.3735077977180481\n",
      "Epoch 12 step 14 loss: 0.362820029258728\n",
      "Epoch 12 step 15 loss: 0.396231472492218\n",
      "Epoch 12 step 16 loss: 0.3905826807022095\n",
      "Epoch 12 step 17 loss: 0.3324703574180603\n",
      "Epoch 12 step 18 loss: 0.38311755657196045\n",
      "Epoch 12 step 19 loss: 0.34637314081192017\n",
      "Epoch 12 step 20 loss: 0.3243933916091919\n",
      "Epoch 12 step 21 loss: 0.37507060170173645\n",
      "Epoch 12 step 22 loss: 0.3778553605079651\n",
      "Epoch 12 step 23 loss: 0.3649114966392517\n",
      "Epoch 12 step 24 loss: 0.36567020416259766\n",
      "Epoch 12 step 25 loss: 0.3940941095352173\n",
      "Epoch 12 step 26 loss: 0.3238806128501892\n",
      "Epoch 12 step 27 loss: 0.4311860501766205\n",
      "Epoch 12 step 28 loss: 0.378909707069397\n",
      "Epoch 12 step 29 loss: 0.3998613953590393\n",
      "Epoch 12 step 30 loss: 0.32138878107070923\n",
      "Epoch 12 step 31 loss: 0.3874053359031677\n",
      "Epoch 12 step 32 loss: 0.36766019463539124\n",
      "Epoch 12 step 33 loss: 0.39840036630630493\n",
      "Epoch 12 step 34 loss: 0.3418262302875519\n",
      "Epoch 12 step 35 loss: 0.33374151587486267\n",
      "Epoch 12 step 36 loss: 0.4280117154121399\n",
      "Epoch 12 step 37 loss: 0.3560202717781067\n",
      "Epoch 12 step 38 loss: 0.39033058285713196\n",
      "Epoch 12 loss: 0.39033058285713196\n",
      "Epoch 13 step 0 loss: 0.43020111322402954\n",
      "Epoch 13 step 1 loss: 0.37944987416267395\n",
      "Epoch 13 step 2 loss: 0.4256460666656494\n",
      "Epoch 13 step 3 loss: 0.36017757654190063\n",
      "Epoch 13 step 4 loss: 0.4037797152996063\n",
      "Epoch 13 step 5 loss: 0.42191779613494873\n",
      "Epoch 13 step 6 loss: 0.3854498565196991\n",
      "Epoch 13 step 7 loss: 0.40374955534935\n",
      "Epoch 13 step 8 loss: 0.36745843291282654\n",
      "Epoch 13 step 9 loss: 0.3668621778488159\n",
      "Epoch 13 step 10 loss: 0.3441990315914154\n",
      "Epoch 13 step 11 loss: 0.3891688883304596\n",
      "Epoch 13 step 12 loss: 0.3733930289745331\n",
      "Epoch 13 step 13 loss: 0.3373497724533081\n",
      "Epoch 13 step 14 loss: 0.39033204317092896\n",
      "Epoch 13 step 15 loss: 0.3777344226837158\n",
      "Epoch 13 step 16 loss: 0.4156702160835266\n",
      "Epoch 13 step 17 loss: 0.3741300106048584\n",
      "Epoch 13 step 18 loss: 0.3391580581665039\n",
      "Epoch 13 step 19 loss: 0.380204975605011\n",
      "Epoch 13 step 20 loss: 0.3853815495967865\n",
      "Epoch 13 step 21 loss: 0.3412681818008423\n",
      "Epoch 13 step 22 loss: 0.3367650508880615\n",
      "Epoch 13 step 23 loss: 0.35944777727127075\n",
      "Epoch 13 step 24 loss: 0.3953804671764374\n",
      "Epoch 13 step 25 loss: 0.36757439374923706\n",
      "Epoch 13 step 26 loss: 0.3887835144996643\n",
      "Epoch 13 step 27 loss: 0.364382266998291\n",
      "Epoch 13 step 28 loss: 0.36244261264801025\n",
      "Epoch 13 step 29 loss: 0.37346893548965454\n",
      "Epoch 13 step 30 loss: 0.36330127716064453\n",
      "Epoch 13 step 31 loss: 0.3397616147994995\n",
      "Epoch 13 step 32 loss: 0.3645828366279602\n",
      "Epoch 13 step 33 loss: 0.3873101472854614\n",
      "Epoch 13 step 34 loss: 0.34925568103790283\n",
      "Epoch 13 step 35 loss: 0.33226895332336426\n",
      "Epoch 13 step 36 loss: 0.3919040560722351\n",
      "Epoch 13 step 37 loss: 0.3499647080898285\n",
      "Epoch 13 step 38 loss: 0.4056125283241272\n",
      "Epoch 13 loss: 0.4056125283241272\n",
      "Epoch 14 step 0 loss: 0.3865177035331726\n",
      "Epoch 14 step 1 loss: 0.42353153228759766\n",
      "Epoch 14 step 2 loss: 0.3563489615917206\n",
      "Epoch 14 step 3 loss: 0.40232348442077637\n",
      "Epoch 14 step 4 loss: 0.3609883487224579\n",
      "Epoch 14 step 5 loss: 0.37122756242752075\n",
      "Epoch 14 step 6 loss: 0.3821706175804138\n",
      "Epoch 14 step 7 loss: 0.4258330464363098\n",
      "Epoch 14 step 8 loss: 0.3477485775947571\n",
      "Epoch 14 step 9 loss: 0.3825964033603668\n",
      "Epoch 14 step 10 loss: 0.36664336919784546\n",
      "Epoch 14 step 11 loss: 0.3642456531524658\n",
      "Epoch 14 step 12 loss: 0.38234248757362366\n",
      "Epoch 14 step 13 loss: 0.4415951371192932\n",
      "Epoch 14 step 14 loss: 0.357967346906662\n",
      "Epoch 14 step 15 loss: 0.33318179845809937\n",
      "Epoch 14 step 16 loss: 0.34293490648269653\n",
      "Epoch 14 step 17 loss: 0.3788818120956421\n",
      "Epoch 14 step 18 loss: 0.3376361131668091\n",
      "Epoch 14 step 19 loss: 0.3698462247848511\n",
      "Epoch 14 step 20 loss: 0.37944716215133667\n",
      "Epoch 14 step 21 loss: 0.3850948214530945\n",
      "Epoch 14 step 22 loss: 0.33826643228530884\n",
      "Epoch 14 step 23 loss: 0.44639912247657776\n",
      "Epoch 14 step 24 loss: 0.3578069806098938\n",
      "Epoch 14 step 25 loss: 0.3520929217338562\n",
      "Epoch 14 step 26 loss: 0.3860723376274109\n",
      "Epoch 14 step 27 loss: 0.3266780376434326\n",
      "Epoch 14 step 28 loss: 0.3783484995365143\n",
      "Epoch 14 step 29 loss: 0.38497042655944824\n",
      "Epoch 14 step 30 loss: 0.3776005506515503\n",
      "Epoch 14 step 31 loss: 0.3051251769065857\n",
      "Epoch 14 step 32 loss: 0.3714211881160736\n",
      "Epoch 14 step 33 loss: 0.3337665796279907\n",
      "Epoch 14 step 34 loss: 0.32696714997291565\n",
      "Epoch 14 step 35 loss: 0.33442631363868713\n",
      "Epoch 14 step 36 loss: 0.4045315980911255\n",
      "Epoch 14 step 37 loss: 0.32916656136512756\n",
      "Epoch 14 step 38 loss: 0.35460522770881653\n",
      "Epoch 14 loss: 0.35460522770881653\n",
      "Epoch 15 step 0 loss: 0.38237327337265015\n",
      "Epoch 15 step 1 loss: 0.3375071883201599\n",
      "Epoch 15 step 2 loss: 0.4187934398651123\n",
      "Epoch 15 step 3 loss: 0.3475271463394165\n",
      "Epoch 15 step 4 loss: 0.3518698215484619\n",
      "Epoch 15 step 5 loss: 0.35519957542419434\n",
      "Epoch 15 step 6 loss: 0.4059657156467438\n",
      "Epoch 15 step 7 loss: 0.41980165243148804\n",
      "Epoch 15 step 8 loss: 0.40529680252075195\n",
      "Epoch 15 step 9 loss: 0.38822731375694275\n",
      "Epoch 15 step 10 loss: 0.3539623022079468\n",
      "Epoch 15 step 11 loss: 0.38611114025115967\n",
      "Epoch 15 step 12 loss: 0.4029095768928528\n",
      "Epoch 15 step 13 loss: 0.39802590012550354\n",
      "Epoch 15 step 14 loss: 0.38272011280059814\n",
      "Epoch 15 step 15 loss: 0.377244770526886\n",
      "Epoch 15 step 16 loss: 0.370767205953598\n",
      "Epoch 15 step 17 loss: 0.3855184316635132\n",
      "Epoch 15 step 18 loss: 0.34357839822769165\n",
      "Epoch 15 step 19 loss: 0.2973877787590027\n",
      "Epoch 15 step 20 loss: 0.3905770480632782\n",
      "Epoch 15 step 21 loss: 0.3532872200012207\n",
      "Epoch 15 step 22 loss: 0.3760325312614441\n",
      "Epoch 15 step 23 loss: 0.3753364682197571\n",
      "Epoch 15 step 24 loss: 0.3763394355773926\n",
      "Epoch 15 step 25 loss: 0.33173543214797974\n",
      "Epoch 15 step 26 loss: 0.42949461936950684\n",
      "Epoch 15 step 27 loss: 0.41289764642715454\n",
      "Epoch 15 step 28 loss: 0.4619864821434021\n",
      "Epoch 15 step 29 loss: 0.40362775325775146\n",
      "Epoch 15 step 30 loss: 0.40468907356262207\n",
      "Epoch 15 step 31 loss: 0.43591099977493286\n",
      "Epoch 15 step 32 loss: 0.4366826117038727\n",
      "Epoch 15 step 33 loss: 0.4421941637992859\n",
      "Epoch 15 step 34 loss: 0.3796093761920929\n",
      "Epoch 15 step 35 loss: 0.42365700006484985\n",
      "Epoch 15 step 36 loss: 0.3899390697479248\n",
      "Epoch 15 step 37 loss: 0.40730977058410645\n",
      "Epoch 15 step 38 loss: 0.4152097702026367\n",
      "Epoch 15 loss: 0.4152097702026367\n",
      "Epoch 16 step 0 loss: 0.4659542739391327\n",
      "Epoch 16 step 1 loss: 0.426788330078125\n",
      "Epoch 16 step 2 loss: 0.39359384775161743\n",
      "Epoch 16 step 3 loss: 0.4866940379142761\n",
      "Epoch 16 step 4 loss: 0.4535185694694519\n",
      "Epoch 16 step 5 loss: 0.38864564895629883\n",
      "Epoch 16 step 6 loss: 0.44515261054039\n",
      "Epoch 16 step 7 loss: 0.4128912687301636\n",
      "Epoch 16 step 8 loss: 0.38118618726730347\n",
      "Epoch 16 step 9 loss: 0.39115238189697266\n",
      "Epoch 16 step 10 loss: 0.3598865866661072\n",
      "Epoch 16 step 11 loss: 0.405666321516037\n",
      "Epoch 16 step 12 loss: 0.42068374156951904\n",
      "Epoch 16 step 13 loss: 0.37347733974456787\n",
      "Epoch 16 step 14 loss: 0.37051013112068176\n",
      "Epoch 16 step 15 loss: 0.3625681400299072\n",
      "Epoch 16 step 16 loss: 0.40137729048728943\n",
      "Epoch 16 step 17 loss: 0.41724103689193726\n",
      "Epoch 16 step 18 loss: 0.3744296431541443\n",
      "Epoch 16 step 19 loss: 0.3813738524913788\n",
      "Epoch 16 step 20 loss: 0.41196468472480774\n",
      "Epoch 16 step 21 loss: 0.389884889125824\n",
      "Epoch 16 step 22 loss: 0.39270079135894775\n",
      "Epoch 16 step 23 loss: 0.4086846113204956\n",
      "Epoch 16 step 24 loss: 0.44636523723602295\n",
      "Epoch 16 step 25 loss: 0.3874491751194\n",
      "Epoch 16 step 26 loss: 0.4224092960357666\n",
      "Epoch 16 step 27 loss: 0.3798907399177551\n",
      "Epoch 16 step 28 loss: 0.35466885566711426\n",
      "Epoch 16 step 29 loss: 0.4719814360141754\n",
      "Epoch 16 step 30 loss: 0.3880666196346283\n",
      "Epoch 16 step 31 loss: 0.3992907404899597\n",
      "Epoch 16 step 32 loss: 0.43412601947784424\n",
      "Epoch 16 step 33 loss: 0.43727532029151917\n",
      "Epoch 16 step 34 loss: 0.3817897439002991\n",
      "Epoch 16 step 35 loss: 0.3967542052268982\n",
      "Epoch 16 step 36 loss: 0.37375399470329285\n",
      "Epoch 16 step 37 loss: 0.4261157512664795\n",
      "Epoch 16 step 38 loss: 0.4196753203868866\n",
      "Epoch 16 loss: 0.4196753203868866\n",
      "Epoch 17 step 0 loss: 0.36689135432243347\n",
      "Epoch 17 step 1 loss: 0.4106042981147766\n",
      "Epoch 17 step 2 loss: 0.4212413430213928\n",
      "Epoch 17 step 3 loss: 0.3673122525215149\n",
      "Epoch 17 step 4 loss: 0.4263591766357422\n",
      "Epoch 17 step 5 loss: 0.38385695219039917\n",
      "Epoch 17 step 6 loss: 0.40189844369888306\n",
      "Epoch 17 step 7 loss: 0.42454516887664795\n",
      "Epoch 17 step 8 loss: 0.36627379059791565\n",
      "Epoch 17 step 9 loss: 0.39516326785087585\n",
      "Epoch 17 step 10 loss: 0.40976253151893616\n",
      "Epoch 17 step 11 loss: 0.3568158745765686\n",
      "Epoch 17 step 12 loss: 0.4272945523262024\n",
      "Epoch 17 step 13 loss: 0.3972232937812805\n",
      "Epoch 17 step 14 loss: 0.3816588222980499\n",
      "Epoch 17 step 15 loss: 0.36630523204803467\n",
      "Epoch 17 step 16 loss: 0.33826255798339844\n",
      "Epoch 17 step 17 loss: 0.40491700172424316\n",
      "Epoch 17 step 18 loss: 0.3778337836265564\n",
      "Epoch 17 step 19 loss: 0.3832090198993683\n",
      "Epoch 17 step 20 loss: 0.37928542494773865\n",
      "Epoch 17 step 21 loss: 0.33926087617874146\n",
      "Epoch 17 step 22 loss: 0.35174620151519775\n",
      "Epoch 17 step 23 loss: 0.36976802349090576\n",
      "Epoch 17 step 24 loss: 0.3809834420681\n",
      "Epoch 17 step 25 loss: 0.38045889139175415\n",
      "Epoch 17 step 26 loss: 0.36471861600875854\n",
      "Epoch 17 step 27 loss: 0.3820219933986664\n",
      "Epoch 17 step 28 loss: 0.3916046917438507\n",
      "Epoch 17 step 29 loss: 0.44354352355003357\n",
      "Epoch 17 step 30 loss: 0.4316592216491699\n",
      "Epoch 17 step 31 loss: 0.3527408242225647\n",
      "Epoch 17 step 32 loss: 0.38856077194213867\n",
      "Epoch 17 step 33 loss: 0.34973302483558655\n",
      "Epoch 17 step 34 loss: 0.3436708152294159\n",
      "Epoch 17 step 35 loss: 0.36394304037094116\n",
      "Epoch 17 step 36 loss: 0.3612464666366577\n",
      "Epoch 17 step 37 loss: 0.4024314284324646\n",
      "Epoch 17 step 38 loss: 0.43103843927383423\n",
      "Epoch 17 loss: 0.43103843927383423\n",
      "Epoch 18 step 0 loss: 0.3760928511619568\n",
      "Epoch 18 step 1 loss: 0.35700932145118713\n",
      "Epoch 18 step 2 loss: 0.4135211706161499\n",
      "Epoch 18 step 3 loss: 0.4139694273471832\n",
      "Epoch 18 step 4 loss: 0.37077492475509644\n",
      "Epoch 18 step 5 loss: 0.42903241515159607\n",
      "Epoch 18 step 6 loss: 0.3417961001396179\n",
      "Epoch 18 step 7 loss: 0.3861514627933502\n",
      "Epoch 18 step 8 loss: 0.35974636673927307\n",
      "Epoch 18 step 9 loss: 0.4078442454338074\n",
      "Epoch 18 step 10 loss: 0.39223653078079224\n",
      "Epoch 18 step 11 loss: 0.35442742705345154\n",
      "Epoch 18 step 12 loss: 0.3405243158340454\n",
      "Epoch 18 step 13 loss: 0.39554715156555176\n",
      "Epoch 18 step 14 loss: 0.3820374608039856\n",
      "Epoch 18 step 15 loss: 0.38877636194229126\n",
      "Epoch 18 step 16 loss: 0.38113436102867126\n",
      "Epoch 18 step 17 loss: 0.3862881064414978\n",
      "Epoch 18 step 18 loss: 0.35691964626312256\n",
      "Epoch 18 step 19 loss: 0.41593220829963684\n",
      "Epoch 18 step 20 loss: 0.3991197943687439\n",
      "Epoch 18 step 21 loss: 0.38221603631973267\n",
      "Epoch 18 step 22 loss: 0.3807882070541382\n",
      "Epoch 18 step 23 loss: 0.36354807019233704\n",
      "Epoch 18 step 24 loss: 0.3743147552013397\n",
      "Epoch 18 step 25 loss: 0.32820722460746765\n",
      "Epoch 18 step 26 loss: 0.32825401425361633\n",
      "Epoch 18 step 27 loss: 0.35756438970565796\n",
      "Epoch 18 step 28 loss: 0.3456413745880127\n",
      "Epoch 18 step 29 loss: 0.36639341711997986\n",
      "Epoch 18 step 30 loss: 0.37314900755882263\n",
      "Epoch 18 step 31 loss: 0.32764285802841187\n",
      "Epoch 18 step 32 loss: 0.37165191769599915\n",
      "Epoch 18 step 33 loss: 0.38660043478012085\n",
      "Epoch 18 step 34 loss: 0.385999858379364\n",
      "Epoch 18 step 35 loss: 0.40077197551727295\n",
      "Epoch 18 step 36 loss: 0.36139369010925293\n",
      "Epoch 18 step 37 loss: 0.38719162344932556\n",
      "Epoch 18 step 38 loss: 0.4339844584465027\n",
      "Epoch 18 loss: 0.4339844584465027\n",
      "Epoch 19 step 0 loss: 0.40757063031196594\n",
      "Epoch 19 step 1 loss: 0.3642793893814087\n",
      "Epoch 19 step 2 loss: 0.36358803510665894\n",
      "Epoch 19 step 3 loss: 0.41796156764030457\n",
      "Epoch 19 step 4 loss: 0.40329521894454956\n",
      "Epoch 19 step 5 loss: 0.3439241051673889\n",
      "Epoch 19 step 6 loss: 0.416885644197464\n",
      "Epoch 19 step 7 loss: 0.39563819766044617\n",
      "Epoch 19 step 8 loss: 0.3448089361190796\n",
      "Epoch 19 step 9 loss: 0.3889302611351013\n",
      "Epoch 19 step 10 loss: 0.3587802052497864\n",
      "Epoch 19 step 11 loss: 0.37261104583740234\n",
      "Epoch 19 step 12 loss: 0.3362463116645813\n",
      "Epoch 19 step 13 loss: 0.41428515315055847\n",
      "Epoch 19 step 14 loss: 0.3810226321220398\n",
      "Epoch 19 step 15 loss: 0.3629222512245178\n",
      "Epoch 19 step 16 loss: 0.374501496553421\n",
      "Epoch 19 step 17 loss: 0.41460302472114563\n",
      "Epoch 19 step 18 loss: 0.35289886593818665\n",
      "Epoch 19 step 19 loss: 0.400848388671875\n",
      "Epoch 19 step 20 loss: 0.3861709535121918\n",
      "Epoch 19 step 21 loss: 0.366975873708725\n",
      "Epoch 19 step 22 loss: 0.34776249527931213\n",
      "Epoch 19 step 23 loss: 0.3434060215950012\n",
      "Epoch 19 step 24 loss: 0.38247451186180115\n",
      "Epoch 19 step 25 loss: 0.3701910376548767\n",
      "Epoch 19 step 26 loss: 0.40204542875289917\n",
      "Epoch 19 step 27 loss: 0.41309860348701477\n",
      "Epoch 19 step 28 loss: 0.41659781336784363\n",
      "Epoch 19 step 29 loss: 0.3399638235569\n",
      "Epoch 19 step 30 loss: 0.3932853937149048\n",
      "Epoch 19 step 31 loss: 0.38768696784973145\n",
      "Epoch 19 step 32 loss: 0.37580931186676025\n",
      "Epoch 19 step 33 loss: 0.4158938229084015\n",
      "Epoch 19 step 34 loss: 0.3817249536514282\n",
      "Epoch 19 step 35 loss: 0.404843807220459\n",
      "Epoch 19 step 36 loss: 0.3358615040779114\n",
      "Epoch 19 step 37 loss: 0.3750358819961548\n",
      "Epoch 19 step 38 loss: 0.3865845799446106\n",
      "Epoch 19 loss: 0.3865845799446106\n",
      "Epoch 20 step 0 loss: 0.41753336787223816\n",
      "Epoch 20 step 1 loss: 0.3481743335723877\n",
      "Epoch 20 step 2 loss: 0.3920631408691406\n",
      "Epoch 20 step 3 loss: 0.34782302379608154\n",
      "Epoch 20 step 4 loss: 0.4351150691509247\n",
      "Epoch 20 step 5 loss: 0.4234880208969116\n",
      "Epoch 20 step 6 loss: 0.4132877588272095\n",
      "Epoch 20 step 7 loss: 0.4151555001735687\n",
      "Epoch 20 step 8 loss: 0.43112578988075256\n",
      "Epoch 20 step 9 loss: 0.4955848455429077\n",
      "Epoch 20 step 10 loss: 0.4049209952354431\n",
      "Epoch 20 step 11 loss: 0.3665584921836853\n",
      "Epoch 20 step 12 loss: 0.43983933329582214\n",
      "Epoch 20 step 13 loss: 0.34417369961738586\n",
      "Epoch 20 step 14 loss: 0.47396931052207947\n",
      "Epoch 20 step 15 loss: 0.402459979057312\n",
      "Epoch 20 step 16 loss: 0.36285173892974854\n",
      "Epoch 20 step 17 loss: 0.5041638016700745\n",
      "Epoch 20 step 18 loss: 0.3240252435207367\n",
      "Epoch 20 step 19 loss: 0.40126827359199524\n",
      "Epoch 20 step 20 loss: 0.3750506043434143\n",
      "Epoch 20 step 21 loss: 0.37448403239250183\n",
      "Epoch 20 step 22 loss: 0.3438235819339752\n",
      "Epoch 20 step 23 loss: 0.3788374662399292\n",
      "Epoch 20 step 24 loss: 0.31851932406425476\n",
      "Epoch 20 step 25 loss: 0.34591805934906006\n",
      "Epoch 20 step 26 loss: 0.34213829040527344\n",
      "Epoch 20 step 27 loss: 0.38126733899116516\n",
      "Epoch 20 step 28 loss: 0.376399427652359\n",
      "Epoch 20 step 29 loss: 0.34931695461273193\n",
      "Epoch 20 step 30 loss: 0.3596142828464508\n",
      "Epoch 20 step 31 loss: 0.3903190493583679\n",
      "Epoch 20 step 32 loss: 0.34689295291900635\n",
      "Epoch 20 step 33 loss: 0.3142356872558594\n",
      "Epoch 20 step 34 loss: 0.44508951902389526\n",
      "Epoch 20 step 35 loss: 0.39909204840660095\n",
      "Epoch 20 step 36 loss: 0.40143021941185\n",
      "Epoch 20 step 37 loss: 0.36805930733680725\n",
      "Epoch 20 step 38 loss: 0.2707332670688629\n",
      "Epoch 20 loss: 0.2707332670688629\n",
      "Epoch 21 step 0 loss: 0.4092126488685608\n",
      "Epoch 21 step 1 loss: 0.44693052768707275\n",
      "Epoch 21 step 2 loss: 0.391655832529068\n",
      "Epoch 21 step 3 loss: 0.40795427560806274\n",
      "Epoch 21 step 4 loss: 0.474301278591156\n",
      "Epoch 21 step 5 loss: 0.39761510491371155\n",
      "Epoch 21 step 6 loss: 0.4473190903663635\n",
      "Epoch 21 step 7 loss: 0.39514651894569397\n",
      "Epoch 21 step 8 loss: 0.3224334716796875\n",
      "Epoch 21 step 9 loss: 0.3727734088897705\n",
      "Epoch 21 step 10 loss: 0.340090811252594\n",
      "Epoch 21 step 11 loss: 0.3570842146873474\n",
      "Epoch 21 step 12 loss: 0.37042394280433655\n",
      "Epoch 21 step 13 loss: 0.4197387099266052\n",
      "Epoch 21 step 14 loss: 0.40977194905281067\n",
      "Epoch 21 step 15 loss: 0.42409512400627136\n",
      "Epoch 21 step 16 loss: 0.369500994682312\n",
      "Epoch 21 step 17 loss: 0.3654254972934723\n",
      "Epoch 21 step 18 loss: 0.3441632390022278\n",
      "Epoch 21 step 19 loss: 0.3345993459224701\n",
      "Epoch 21 step 20 loss: 0.3566974401473999\n",
      "Epoch 21 step 21 loss: 0.3412590026855469\n",
      "Epoch 21 step 22 loss: 0.3689849078655243\n",
      "Epoch 21 step 23 loss: 0.3704335391521454\n",
      "Epoch 21 step 24 loss: 0.3848041296005249\n",
      "Epoch 21 step 25 loss: 0.34832608699798584\n",
      "Epoch 21 step 26 loss: 0.38000723719596863\n",
      "Epoch 21 step 27 loss: 0.3760131001472473\n",
      "Epoch 21 step 28 loss: 0.3467807471752167\n",
      "Epoch 21 step 29 loss: 0.3211764097213745\n",
      "Epoch 21 step 30 loss: 0.36239176988601685\n",
      "Epoch 21 step 31 loss: 0.3445625901222229\n",
      "Epoch 21 step 32 loss: 0.35832881927490234\n",
      "Epoch 21 step 33 loss: 0.4180755019187927\n",
      "Epoch 21 step 34 loss: 0.3299638628959656\n",
      "Epoch 21 step 35 loss: 0.3490055799484253\n",
      "Epoch 21 step 36 loss: 0.3802992105484009\n",
      "Epoch 21 step 37 loss: 0.4864983558654785\n",
      "Epoch 21 step 38 loss: 0.2883092761039734\n",
      "Epoch 21 loss: 0.2883092761039734\n",
      "Epoch 22 step 0 loss: 0.3792271018028259\n",
      "Epoch 22 step 1 loss: 0.43922144174575806\n",
      "Epoch 22 step 2 loss: 0.44491952657699585\n",
      "Epoch 22 step 3 loss: 0.37809669971466064\n",
      "Epoch 22 step 4 loss: 0.4092135429382324\n",
      "Epoch 22 step 5 loss: 0.3937646746635437\n",
      "Epoch 22 step 6 loss: 0.3685236871242523\n",
      "Epoch 22 step 7 loss: 0.3591047525405884\n",
      "Epoch 22 step 8 loss: 0.4035602807998657\n",
      "Epoch 22 step 9 loss: 0.35157787799835205\n",
      "Epoch 22 step 10 loss: 0.3163143992424011\n",
      "Epoch 22 step 11 loss: 0.38680535554885864\n",
      "Epoch 22 step 12 loss: 0.3799627721309662\n",
      "Epoch 22 step 13 loss: 0.40159231424331665\n",
      "Epoch 22 step 14 loss: 0.3761329650878906\n",
      "Epoch 22 step 15 loss: 0.47362956404685974\n",
      "Epoch 22 step 16 loss: 0.39413249492645264\n",
      "Epoch 22 step 17 loss: 0.3274659812450409\n",
      "Epoch 22 step 18 loss: 0.3653481602668762\n",
      "Epoch 22 step 19 loss: 0.3648243546485901\n",
      "Epoch 22 step 20 loss: 0.38116440176963806\n",
      "Epoch 22 step 21 loss: 0.3663499653339386\n",
      "Epoch 22 step 22 loss: 0.39726102352142334\n",
      "Epoch 22 step 23 loss: 0.39446011185646057\n",
      "Epoch 22 step 24 loss: 0.402671217918396\n",
      "Epoch 22 step 25 loss: 0.40857890248298645\n",
      "Epoch 22 step 26 loss: 0.4007683992385864\n",
      "Epoch 22 step 27 loss: 0.3514392673969269\n",
      "Epoch 22 step 28 loss: 0.3678891062736511\n",
      "Epoch 22 step 29 loss: 0.3527929186820984\n",
      "Epoch 22 step 30 loss: 0.32988303899765015\n",
      "Epoch 22 step 31 loss: 0.37524330615997314\n",
      "Epoch 22 step 32 loss: 0.3571918308734894\n",
      "Epoch 22 step 33 loss: 0.3844353258609772\n",
      "Epoch 22 step 34 loss: 0.32229360938072205\n",
      "Epoch 22 step 35 loss: 0.2758539021015167\n",
      "Epoch 22 step 36 loss: 0.41692543029785156\n",
      "Epoch 22 step 37 loss: 0.3363332748413086\n",
      "Epoch 22 step 38 loss: 0.43493348360061646\n",
      "Epoch 22 loss: 0.43493348360061646\n",
      "Epoch 23 step 0 loss: 0.410032719373703\n",
      "Epoch 23 step 1 loss: 0.33503851294517517\n",
      "Epoch 23 step 2 loss: 0.4616512060165405\n",
      "Epoch 23 step 3 loss: 0.2882550358772278\n",
      "Epoch 23 step 4 loss: 0.3710942566394806\n",
      "Epoch 23 step 5 loss: 0.3241594433784485\n",
      "Epoch 23 step 6 loss: 0.4070606231689453\n",
      "Epoch 23 step 7 loss: 0.3134363293647766\n",
      "Epoch 23 step 8 loss: 0.40196534991264343\n",
      "Epoch 23 step 9 loss: 0.34126925468444824\n",
      "Epoch 23 step 10 loss: 0.38624754548072815\n",
      "Epoch 23 step 11 loss: 0.35484153032302856\n",
      "Epoch 23 step 12 loss: 0.39618390798568726\n",
      "Epoch 23 step 13 loss: 0.3217472732067108\n",
      "Epoch 23 step 14 loss: 0.353748619556427\n",
      "Epoch 23 step 15 loss: 0.3396410048007965\n",
      "Epoch 23 step 16 loss: 0.3690623342990875\n",
      "Epoch 23 step 17 loss: 0.31035488843917847\n",
      "Epoch 23 step 18 loss: 0.30466991662979126\n",
      "Epoch 23 step 19 loss: 0.3505997061729431\n",
      "Epoch 23 step 20 loss: 0.336773157119751\n",
      "Epoch 23 step 21 loss: 0.36077359318733215\n",
      "Epoch 23 step 22 loss: 0.33570635318756104\n",
      "Epoch 23 step 23 loss: 0.2813927233219147\n",
      "Epoch 23 step 24 loss: 0.34124985337257385\n",
      "Epoch 23 step 25 loss: 0.3863863945007324\n",
      "Epoch 23 step 26 loss: 0.4115564227104187\n",
      "Epoch 23 step 27 loss: 0.44282662868499756\n",
      "Epoch 23 step 28 loss: 0.3222057819366455\n",
      "Epoch 23 step 29 loss: 0.35693779587745667\n",
      "Epoch 23 step 30 loss: 0.29631301760673523\n",
      "Epoch 23 step 31 loss: 0.3558908998966217\n",
      "Epoch 23 step 32 loss: 0.2907600700855255\n",
      "Epoch 23 step 33 loss: 0.3631998896598816\n",
      "Epoch 23 step 34 loss: 0.3635989725589752\n",
      "Epoch 23 step 35 loss: 0.4054611325263977\n",
      "Epoch 23 step 36 loss: 0.3430896997451782\n",
      "Epoch 23 step 37 loss: 0.3754267394542694\n",
      "Epoch 23 step 38 loss: 0.3389444947242737\n",
      "Epoch 23 loss: 0.3389444947242737\n",
      "Epoch 24 step 0 loss: 0.38717570900917053\n",
      "Epoch 24 step 1 loss: 0.3245329260826111\n",
      "Epoch 24 step 2 loss: 0.2489241361618042\n",
      "Epoch 24 step 3 loss: 0.3089088201522827\n",
      "Epoch 24 step 4 loss: 0.3475024700164795\n",
      "Epoch 24 step 5 loss: 0.29893139004707336\n",
      "Epoch 24 step 6 loss: 0.3849969208240509\n",
      "Epoch 24 step 7 loss: 0.31856781244277954\n",
      "Epoch 24 step 8 loss: 0.3964855968952179\n",
      "Epoch 24 step 9 loss: 0.3220908045768738\n",
      "Epoch 24 step 10 loss: 0.34240150451660156\n",
      "Epoch 24 step 11 loss: 0.4019521474838257\n",
      "Epoch 24 step 12 loss: 0.3072482645511627\n",
      "Epoch 24 step 13 loss: 0.39148759841918945\n",
      "Epoch 24 step 14 loss: 0.29591256380081177\n",
      "Epoch 24 step 15 loss: 0.41094446182250977\n",
      "Epoch 24 step 16 loss: 0.36364516615867615\n",
      "Epoch 24 step 17 loss: 0.3717336058616638\n",
      "Epoch 24 step 18 loss: 0.35665589570999146\n",
      "Epoch 24 step 19 loss: 0.3224146366119385\n",
      "Epoch 24 step 20 loss: 0.2902073264122009\n",
      "Epoch 24 step 21 loss: 0.32654839754104614\n",
      "Epoch 24 step 22 loss: 0.3273800313472748\n",
      "Epoch 24 step 23 loss: 0.3889269530773163\n",
      "Epoch 24 step 24 loss: 0.2938941717147827\n",
      "Epoch 24 step 25 loss: 0.3326907157897949\n",
      "Epoch 24 step 26 loss: 0.333212673664093\n",
      "Epoch 24 step 27 loss: 0.3284473419189453\n",
      "Epoch 24 step 28 loss: 0.35919153690338135\n",
      "Epoch 24 step 29 loss: 0.3451608419418335\n",
      "Epoch 24 step 30 loss: 0.3312797546386719\n",
      "Epoch 24 step 31 loss: 0.291798859834671\n",
      "Epoch 24 step 32 loss: 0.37999412417411804\n",
      "Epoch 24 step 33 loss: 0.3215484917163849\n",
      "Epoch 24 step 34 loss: 0.31357184052467346\n",
      "Epoch 24 step 35 loss: 0.3114652633666992\n",
      "Epoch 24 step 36 loss: 0.373573899269104\n",
      "Epoch 24 step 37 loss: 0.3759056031703949\n",
      "Epoch 24 step 38 loss: 0.32046306133270264\n",
      "Epoch 24 loss: 0.32046306133270264\n",
      "Epoch 25 step 0 loss: 0.3086405396461487\n",
      "Epoch 25 step 1 loss: 0.30093902349472046\n",
      "Epoch 25 step 2 loss: 0.34465473890304565\n",
      "Epoch 25 step 3 loss: 0.33229899406433105\n",
      "Epoch 25 step 4 loss: 0.34890154004096985\n",
      "Epoch 25 step 5 loss: 0.3230959177017212\n",
      "Epoch 25 step 6 loss: 0.3583246171474457\n",
      "Epoch 25 step 7 loss: 0.32187116146087646\n",
      "Epoch 25 step 8 loss: 0.43108558654785156\n",
      "Epoch 25 step 9 loss: 0.31213340163230896\n",
      "Epoch 25 step 10 loss: 0.3094538152217865\n",
      "Epoch 25 step 11 loss: 0.34453457593917847\n",
      "Epoch 25 step 12 loss: 0.3272298276424408\n",
      "Epoch 25 step 13 loss: 0.3359941244125366\n",
      "Epoch 25 step 14 loss: 0.3222455680370331\n",
      "Epoch 25 step 15 loss: 0.3046213686466217\n",
      "Epoch 25 step 16 loss: 0.3425365090370178\n",
      "Epoch 25 step 17 loss: 0.3232174515724182\n",
      "Epoch 25 step 18 loss: 0.25236931443214417\n",
      "Epoch 25 step 19 loss: 0.39972206950187683\n",
      "Epoch 25 step 20 loss: 0.3330107629299164\n",
      "Epoch 25 step 21 loss: 0.3952139616012573\n",
      "Epoch 25 step 22 loss: 0.34355247020721436\n",
      "Epoch 25 step 23 loss: 0.35749000310897827\n",
      "Epoch 25 step 24 loss: 0.34789037704467773\n",
      "Epoch 25 step 25 loss: 0.34788045287132263\n",
      "Epoch 25 step 26 loss: 0.3351997137069702\n",
      "Epoch 25 step 27 loss: 0.37419649958610535\n",
      "Epoch 25 step 28 loss: 0.43037426471710205\n",
      "Epoch 25 step 29 loss: 0.33420413732528687\n",
      "Epoch 25 step 30 loss: 0.3483548164367676\n",
      "Epoch 25 step 31 loss: 0.32478630542755127\n",
      "Epoch 25 step 32 loss: 0.30202797055244446\n",
      "Epoch 25 step 33 loss: 0.35746699571609497\n",
      "Epoch 25 step 34 loss: 0.3418840765953064\n",
      "Epoch 25 step 35 loss: 0.347259521484375\n",
      "Epoch 25 step 36 loss: 0.38148823380470276\n",
      "Epoch 25 step 37 loss: 0.3415117859840393\n",
      "Epoch 25 step 38 loss: 0.3592362105846405\n",
      "Epoch 25 loss: 0.3592362105846405\n",
      "Epoch 26 step 0 loss: 0.32640326023101807\n",
      "Epoch 26 step 1 loss: 0.3577730357646942\n",
      "Epoch 26 step 2 loss: 0.34454092383384705\n",
      "Epoch 26 step 3 loss: 0.4134337604045868\n",
      "Epoch 26 step 4 loss: 0.29006463289260864\n",
      "Epoch 26 step 5 loss: 0.31848204135894775\n",
      "Epoch 26 step 6 loss: 0.3594971299171448\n",
      "Epoch 26 step 7 loss: 0.38279402256011963\n",
      "Epoch 26 step 8 loss: 0.3055773079395294\n",
      "Epoch 26 step 9 loss: 0.3564564287662506\n",
      "Epoch 26 step 10 loss: 0.3799823224544525\n",
      "Epoch 26 step 11 loss: 0.38003048300743103\n",
      "Epoch 26 step 12 loss: 0.3584757447242737\n",
      "Epoch 26 step 13 loss: 0.40179455280303955\n",
      "Epoch 26 step 14 loss: 0.3492961525917053\n",
      "Epoch 26 step 15 loss: 0.3299601078033447\n",
      "Epoch 26 step 16 loss: 0.31414514780044556\n",
      "Epoch 26 step 17 loss: 0.32542723417282104\n",
      "Epoch 26 step 18 loss: 0.4337323307991028\n",
      "Epoch 26 step 19 loss: 0.38298919796943665\n",
      "Epoch 26 step 20 loss: 0.3567168712615967\n",
      "Epoch 26 step 21 loss: 0.3759075403213501\n",
      "Epoch 26 step 22 loss: 0.37270587682724\n",
      "Epoch 26 step 23 loss: 0.33810773491859436\n",
      "Epoch 26 step 24 loss: 0.2969358265399933\n",
      "Epoch 26 step 25 loss: 0.3247203230857849\n",
      "Epoch 26 step 26 loss: 0.2945401668548584\n",
      "Epoch 26 step 27 loss: 0.36720454692840576\n",
      "Epoch 26 step 28 loss: 0.34974485635757446\n",
      "Epoch 26 step 29 loss: 0.3347843885421753\n",
      "Epoch 26 step 30 loss: 0.29589807987213135\n",
      "Epoch 26 step 31 loss: 0.27133679389953613\n",
      "Epoch 26 step 32 loss: 0.3686433434486389\n",
      "Epoch 26 step 33 loss: 0.32079169154167175\n",
      "Epoch 26 step 34 loss: 0.3675476312637329\n",
      "Epoch 26 step 35 loss: 0.3162478804588318\n",
      "Epoch 26 step 36 loss: 0.3334256410598755\n",
      "Epoch 26 step 37 loss: 0.29808539152145386\n",
      "Epoch 26 step 38 loss: 0.29575058817863464\n",
      "Epoch 26 loss: 0.29575058817863464\n",
      "Epoch 27 step 0 loss: 0.34265652298927307\n",
      "Epoch 27 step 1 loss: 0.32367974519729614\n",
      "Epoch 27 step 2 loss: 0.3517981171607971\n",
      "Epoch 27 step 3 loss: 0.29795271158218384\n",
      "Epoch 27 step 4 loss: 0.28471839427948\n",
      "Epoch 27 step 5 loss: 0.35737520456314087\n",
      "Epoch 27 step 6 loss: 0.3622773587703705\n",
      "Epoch 27 step 7 loss: 0.3448127806186676\n",
      "Epoch 27 step 8 loss: 0.2771357595920563\n",
      "Epoch 27 step 9 loss: 0.34436923265457153\n",
      "Epoch 27 step 10 loss: 0.31832751631736755\n",
      "Epoch 27 step 11 loss: 0.36427778005599976\n",
      "Epoch 27 step 12 loss: 0.3474472165107727\n",
      "Epoch 27 step 13 loss: 0.3510403633117676\n",
      "Epoch 27 step 14 loss: 0.35616999864578247\n",
      "Epoch 27 step 15 loss: 0.3792305886745453\n",
      "Epoch 27 step 16 loss: 0.3637069761753082\n",
      "Epoch 27 step 17 loss: 0.3662921190261841\n",
      "Epoch 27 step 18 loss: 0.32226285338401794\n",
      "Epoch 27 step 19 loss: 0.25519847869873047\n",
      "Epoch 27 step 20 loss: 0.3553023636341095\n",
      "Epoch 27 step 21 loss: 0.3866654634475708\n",
      "Epoch 27 step 22 loss: 0.33381879329681396\n",
      "Epoch 27 step 23 loss: 0.3639901578426361\n",
      "Epoch 27 step 24 loss: 0.33280864357948303\n",
      "Epoch 27 step 25 loss: 0.3104228377342224\n",
      "Epoch 27 step 26 loss: 0.34385138750076294\n",
      "Epoch 27 step 27 loss: 0.29139789938926697\n",
      "Epoch 27 step 28 loss: 0.3451688587665558\n",
      "Epoch 27 step 29 loss: 0.26666682958602905\n",
      "Epoch 27 step 30 loss: 0.4833979308605194\n",
      "Epoch 27 step 31 loss: 0.35724204778671265\n",
      "Epoch 27 step 32 loss: 0.33706700801849365\n",
      "Epoch 27 step 33 loss: 0.310018390417099\n",
      "Epoch 27 step 34 loss: 0.3564430773258209\n",
      "Epoch 27 step 35 loss: 0.34660661220550537\n",
      "Epoch 27 step 36 loss: 0.32420021295547485\n",
      "Epoch 27 step 37 loss: 0.284853994846344\n",
      "Epoch 27 step 38 loss: 0.25683581829071045\n",
      "Epoch 27 loss: 0.25683581829071045\n",
      "Epoch 28 step 0 loss: 0.2877148985862732\n",
      "Epoch 28 step 1 loss: 0.3036470115184784\n",
      "Epoch 28 step 2 loss: 0.34411194920539856\n",
      "Epoch 28 step 3 loss: 0.3213101923465729\n",
      "Epoch 28 step 4 loss: 0.33950188755989075\n",
      "Epoch 28 step 5 loss: 0.31932011246681213\n",
      "Epoch 28 step 6 loss: 0.33908605575561523\n",
      "Epoch 28 step 7 loss: 0.3520476222038269\n",
      "Epoch 28 step 8 loss: 0.30795544385910034\n",
      "Epoch 28 step 9 loss: 0.3637939393520355\n",
      "Epoch 28 step 10 loss: 0.30948778986930847\n",
      "Epoch 28 step 11 loss: 0.3084009289741516\n",
      "Epoch 28 step 12 loss: 0.331504225730896\n",
      "Epoch 28 step 13 loss: 0.3998212218284607\n",
      "Epoch 28 step 14 loss: 0.3455401360988617\n",
      "Epoch 28 step 15 loss: 0.3235672116279602\n",
      "Epoch 28 step 16 loss: 0.3647902011871338\n",
      "Epoch 28 step 17 loss: 0.2933973968029022\n",
      "Epoch 28 step 18 loss: 0.3457079827785492\n",
      "Epoch 28 step 19 loss: 0.3571128249168396\n",
      "Epoch 28 step 20 loss: 0.3933704197406769\n",
      "Epoch 28 step 21 loss: 0.3584078848361969\n",
      "Epoch 28 step 22 loss: 0.35293158888816833\n",
      "Epoch 28 step 23 loss: 0.2939855456352234\n",
      "Epoch 28 step 24 loss: 0.3586960732936859\n",
      "Epoch 28 step 25 loss: 0.3801000714302063\n",
      "Epoch 28 step 26 loss: 0.32958197593688965\n",
      "Epoch 28 step 27 loss: 0.34297627210617065\n",
      "Epoch 28 step 28 loss: 0.40694910287857056\n",
      "Epoch 28 step 29 loss: 0.32103440165519714\n",
      "Epoch 28 step 30 loss: 0.34883761405944824\n",
      "Epoch 28 step 31 loss: 0.3810315430164337\n",
      "Epoch 28 step 32 loss: 0.3440268039703369\n",
      "Epoch 28 step 33 loss: 0.29071691632270813\n",
      "Epoch 28 step 34 loss: 0.38323190808296204\n",
      "Epoch 28 step 35 loss: 0.37133878469467163\n",
      "Epoch 28 step 36 loss: 0.3446827530860901\n",
      "Epoch 28 step 37 loss: 0.2506401538848877\n",
      "Epoch 28 step 38 loss: 0.38232624530792236\n",
      "Epoch 28 loss: 0.38232624530792236\n",
      "Epoch 29 step 0 loss: 0.3463420271873474\n",
      "Epoch 29 step 1 loss: 0.3563212752342224\n",
      "Epoch 29 step 2 loss: 0.3757004141807556\n",
      "Epoch 29 step 3 loss: 0.34207049012184143\n",
      "Epoch 29 step 4 loss: 0.2983783185482025\n",
      "Epoch 29 step 5 loss: 0.2924153208732605\n",
      "Epoch 29 step 6 loss: 0.2928108274936676\n",
      "Epoch 29 step 7 loss: 0.32230275869369507\n",
      "Epoch 29 step 8 loss: 0.35183313488960266\n",
      "Epoch 29 step 9 loss: 0.35448938608169556\n",
      "Epoch 29 step 10 loss: 0.34346237778663635\n",
      "Epoch 29 step 11 loss: 0.32120653986930847\n",
      "Epoch 29 step 12 loss: 0.3397976756095886\n",
      "Epoch 29 step 13 loss: 0.2809067964553833\n",
      "Epoch 29 step 14 loss: 0.33203697204589844\n",
      "Epoch 29 step 15 loss: 0.3110469579696655\n",
      "Epoch 29 step 16 loss: 0.3272964358329773\n",
      "Epoch 29 step 17 loss: 0.3045879006385803\n",
      "Epoch 29 step 18 loss: 0.3541235327720642\n",
      "Epoch 29 step 19 loss: 0.3613676428794861\n",
      "Epoch 29 step 20 loss: 0.3845755457878113\n",
      "Epoch 29 step 21 loss: 0.2978115975856781\n",
      "Epoch 29 step 22 loss: 0.27469563484191895\n",
      "Epoch 29 step 23 loss: 0.3957262933254242\n",
      "Epoch 29 step 24 loss: 0.2978559732437134\n",
      "Epoch 29 step 25 loss: 0.3405103385448456\n",
      "Epoch 29 step 26 loss: 0.3178051710128784\n",
      "Epoch 29 step 27 loss: 0.28308671712875366\n",
      "Epoch 29 step 28 loss: 0.34434497356414795\n",
      "Epoch 29 step 29 loss: 0.2950752377510071\n",
      "Epoch 29 step 30 loss: 0.28920596837997437\n",
      "Epoch 29 step 31 loss: 0.36350947618484497\n",
      "Epoch 29 step 32 loss: 0.29067832231521606\n",
      "Epoch 29 step 33 loss: 0.37628161907196045\n",
      "Epoch 29 step 34 loss: 0.2837517261505127\n",
      "Epoch 29 step 35 loss: 0.3810000717639923\n",
      "Epoch 29 step 36 loss: 0.312935471534729\n",
      "Epoch 29 step 37 loss: 0.2956451177597046\n",
      "Epoch 29 step 38 loss: 0.33674561977386475\n",
      "Epoch 29 loss: 0.33674561977386475\n",
      "Epoch 30 step 0 loss: 0.2739852964878082\n",
      "Epoch 30 step 1 loss: 0.37927818298339844\n",
      "Epoch 30 step 2 loss: 0.2879820466041565\n",
      "Epoch 30 step 3 loss: 0.3201882839202881\n",
      "Epoch 30 step 4 loss: 0.2692827582359314\n",
      "Epoch 30 step 5 loss: 0.28434616327285767\n",
      "Epoch 30 step 6 loss: 0.3225014805793762\n",
      "Epoch 30 step 7 loss: 0.2560906708240509\n",
      "Epoch 30 step 8 loss: 0.25260913372039795\n",
      "Epoch 30 step 9 loss: 0.32863378524780273\n",
      "Epoch 30 step 10 loss: 0.26753637194633484\n",
      "Epoch 30 step 11 loss: 0.29524654150009155\n",
      "Epoch 30 step 12 loss: 0.32069510221481323\n",
      "Epoch 30 step 13 loss: 0.26871466636657715\n",
      "Epoch 30 step 14 loss: 0.2569694519042969\n",
      "Epoch 30 step 15 loss: 0.3033777177333832\n",
      "Epoch 30 step 16 loss: 0.3015771806240082\n",
      "Epoch 30 step 17 loss: 0.3032769560813904\n",
      "Epoch 30 step 18 loss: 0.298598051071167\n",
      "Epoch 30 step 19 loss: 0.2495911419391632\n",
      "Epoch 30 step 20 loss: 0.31947118043899536\n",
      "Epoch 30 step 21 loss: 0.31941550970077515\n",
      "Epoch 30 step 22 loss: 0.3167286813259125\n",
      "Epoch 30 step 23 loss: 0.2682989835739136\n",
      "Epoch 30 step 24 loss: 0.36408481001853943\n",
      "Epoch 30 step 25 loss: 0.3176582455635071\n",
      "Epoch 30 step 26 loss: 0.3508011996746063\n",
      "Epoch 30 step 27 loss: 0.3440014719963074\n",
      "Epoch 30 step 28 loss: 0.31130337715148926\n",
      "Epoch 30 step 29 loss: 0.28413569927215576\n",
      "Epoch 30 step 30 loss: 0.29740744829177856\n",
      "Epoch 30 step 31 loss: 0.3232455253601074\n",
      "Epoch 30 step 32 loss: 0.2527867555618286\n",
      "Epoch 30 step 33 loss: 0.33733826875686646\n",
      "Epoch 30 step 34 loss: 0.38607966899871826\n",
      "Epoch 30 step 35 loss: 0.20759513974189758\n",
      "Epoch 30 step 36 loss: 0.34777453541755676\n",
      "Epoch 30 step 37 loss: 0.3546006679534912\n",
      "Epoch 30 step 38 loss: 0.3025500178337097\n",
      "Epoch 30 loss: 0.3025500178337097\n",
      "Epoch 31 step 0 loss: 0.323871374130249\n",
      "Epoch 31 step 1 loss: 0.30268511176109314\n",
      "Epoch 31 step 2 loss: 0.30209535360336304\n",
      "Epoch 31 step 3 loss: 0.30547934770584106\n",
      "Epoch 31 step 4 loss: 0.33817920088768005\n",
      "Epoch 31 step 5 loss: 0.30599552392959595\n",
      "Epoch 31 step 6 loss: 0.3361988067626953\n",
      "Epoch 31 step 7 loss: 0.3207937479019165\n",
      "Epoch 31 step 8 loss: 0.3050152659416199\n",
      "Epoch 31 step 9 loss: 0.2802583575248718\n",
      "Epoch 31 step 10 loss: 0.29429152607917786\n",
      "Epoch 31 step 11 loss: 0.3068232834339142\n",
      "Epoch 31 step 12 loss: 0.28214576840400696\n",
      "Epoch 31 step 13 loss: 0.2872183918952942\n",
      "Epoch 31 step 14 loss: 0.2995755970478058\n",
      "Epoch 31 step 15 loss: 0.2641680836677551\n",
      "Epoch 31 step 16 loss: 0.29289960861206055\n",
      "Epoch 31 step 17 loss: 0.22950537502765656\n",
      "Epoch 31 step 18 loss: 0.4107654094696045\n",
      "Epoch 31 step 19 loss: 0.3206520080566406\n",
      "Epoch 31 step 20 loss: 0.29325810074806213\n",
      "Epoch 31 step 21 loss: 0.2853284478187561\n",
      "Epoch 31 step 22 loss: 0.2778526842594147\n",
      "Epoch 31 step 23 loss: 0.3089466691017151\n",
      "Epoch 31 step 24 loss: 0.3095569312572479\n",
      "Epoch 31 step 25 loss: 0.29414916038513184\n",
      "Epoch 31 step 26 loss: 0.26832088828086853\n",
      "Epoch 31 step 27 loss: 0.2856215238571167\n",
      "Epoch 31 step 28 loss: 0.261311799287796\n",
      "Epoch 31 step 29 loss: 0.2568711042404175\n",
      "Epoch 31 step 30 loss: 0.25565144419670105\n",
      "Epoch 31 step 31 loss: 0.2918854355812073\n",
      "Epoch 31 step 32 loss: 0.2915860116481781\n",
      "Epoch 31 step 33 loss: 0.33870992064476013\n",
      "Epoch 31 step 34 loss: 0.30443841218948364\n",
      "Epoch 31 step 35 loss: 0.2532992959022522\n",
      "Epoch 31 step 36 loss: 0.28090256452560425\n",
      "Epoch 31 step 37 loss: 0.29559624195098877\n",
      "Epoch 31 step 38 loss: 0.33930259943008423\n",
      "Epoch 31 loss: 0.33930259943008423\n",
      "Epoch 32 step 0 loss: 0.43652158975601196\n",
      "Epoch 32 step 1 loss: 0.36329275369644165\n",
      "Epoch 32 step 2 loss: 0.30831456184387207\n",
      "Epoch 32 step 3 loss: 0.4103853702545166\n",
      "Epoch 32 step 4 loss: 0.4029557704925537\n",
      "Epoch 32 step 5 loss: 0.43200474977493286\n",
      "Epoch 32 step 6 loss: 0.34552204608917236\n",
      "Epoch 32 step 7 loss: 0.36459681391716003\n",
      "Epoch 32 step 8 loss: 0.3439054787158966\n",
      "Epoch 32 step 9 loss: 0.36100584268569946\n",
      "Epoch 32 step 10 loss: 0.3515845537185669\n",
      "Epoch 32 step 11 loss: 0.3212374746799469\n",
      "Epoch 32 step 12 loss: 0.35849660634994507\n",
      "Epoch 32 step 13 loss: 0.37330326437950134\n",
      "Epoch 32 step 14 loss: 0.35012006759643555\n",
      "Epoch 32 step 15 loss: 0.2774542570114136\n",
      "Epoch 32 step 16 loss: 0.3359442949295044\n",
      "Epoch 32 step 17 loss: 0.35421493649482727\n",
      "Epoch 32 step 18 loss: 0.35623058676719666\n",
      "Epoch 32 step 19 loss: 0.298028826713562\n",
      "Epoch 32 step 20 loss: 0.3173457980155945\n",
      "Epoch 32 step 21 loss: 0.27985361218452454\n",
      "Epoch 32 step 22 loss: 0.33296507596969604\n",
      "Epoch 32 step 23 loss: 0.36718860268592834\n",
      "Epoch 32 step 24 loss: 0.2597676217556\n",
      "Epoch 32 step 25 loss: 0.31900808215141296\n",
      "Epoch 32 step 26 loss: 0.31183773279190063\n",
      "Epoch 32 step 27 loss: 0.32224735617637634\n",
      "Epoch 32 step 28 loss: 0.37311333417892456\n",
      "Epoch 32 step 29 loss: 0.3626313805580139\n",
      "Epoch 32 step 30 loss: 0.3258277177810669\n",
      "Epoch 32 step 31 loss: 0.3203026056289673\n",
      "Epoch 32 step 32 loss: 0.30694296956062317\n",
      "Epoch 32 step 33 loss: 0.30019521713256836\n",
      "Epoch 32 step 34 loss: 0.31271839141845703\n",
      "Epoch 32 step 35 loss: 0.27183061838150024\n",
      "Epoch 32 step 36 loss: 0.39186984300613403\n",
      "Epoch 32 step 37 loss: 0.2898871898651123\n",
      "Epoch 32 step 38 loss: 0.3792496919631958\n",
      "Epoch 32 loss: 0.3792496919631958\n",
      "Epoch 33 step 0 loss: 0.32417595386505127\n",
      "Epoch 33 step 1 loss: 0.3057073950767517\n",
      "Epoch 33 step 2 loss: 0.3600758910179138\n",
      "Epoch 33 step 3 loss: 0.33857113122940063\n",
      "Epoch 33 step 4 loss: 0.3335776627063751\n",
      "Epoch 33 step 5 loss: 0.32558321952819824\n",
      "Epoch 33 step 6 loss: 0.3885498642921448\n",
      "Epoch 33 step 7 loss: 0.29061341285705566\n",
      "Epoch 33 step 8 loss: 0.3205057382583618\n",
      "Epoch 33 step 9 loss: 0.28752779960632324\n",
      "Epoch 33 step 10 loss: 0.3451734781265259\n",
      "Epoch 33 step 11 loss: 0.3647696375846863\n",
      "Epoch 33 step 12 loss: 0.31712818145751953\n",
      "Epoch 33 step 13 loss: 0.28235501050949097\n",
      "Epoch 33 step 14 loss: 0.2858973741531372\n",
      "Epoch 33 step 15 loss: 0.330400288105011\n",
      "Epoch 33 step 16 loss: 0.2666706442832947\n",
      "Epoch 33 step 17 loss: 0.3687080144882202\n",
      "Epoch 33 step 18 loss: 0.34628716111183167\n",
      "Epoch 33 step 19 loss: 0.30671387910842896\n",
      "Epoch 33 step 20 loss: 0.2692069411277771\n",
      "Epoch 33 step 21 loss: 0.3825068771839142\n",
      "Epoch 33 step 22 loss: 0.21529601514339447\n",
      "Epoch 33 step 23 loss: 0.3538706600666046\n",
      "Epoch 33 step 24 loss: 0.3265855312347412\n",
      "Epoch 33 step 25 loss: 0.2673906683921814\n",
      "Epoch 33 step 26 loss: 0.33674606680870056\n",
      "Epoch 33 step 27 loss: 0.2560505270957947\n",
      "Epoch 33 step 28 loss: 0.27126312255859375\n",
      "Epoch 33 step 29 loss: 0.26468637585639954\n",
      "Epoch 33 step 30 loss: 0.2857476770877838\n",
      "Epoch 33 step 31 loss: 0.36621493101119995\n",
      "Epoch 33 step 32 loss: 0.3004164695739746\n",
      "Epoch 33 step 33 loss: 0.3219617009162903\n",
      "Epoch 33 step 34 loss: 0.3360748589038849\n",
      "Epoch 33 step 35 loss: 0.24493271112442017\n",
      "Epoch 33 step 36 loss: 0.26088330149650574\n",
      "Epoch 33 step 37 loss: 0.3458990156650543\n",
      "Epoch 33 step 38 loss: 0.30660754442214966\n",
      "Epoch 33 loss: 0.30660754442214966\n",
      "Epoch 34 step 0 loss: 0.29560041427612305\n",
      "Epoch 34 step 1 loss: 0.2829805016517639\n",
      "Epoch 34 step 2 loss: 0.2877068519592285\n",
      "Epoch 34 step 3 loss: 0.34374767541885376\n",
      "Epoch 34 step 4 loss: 0.3320593535900116\n",
      "Epoch 34 step 5 loss: 0.3336188793182373\n",
      "Epoch 34 step 6 loss: 0.30202510952949524\n",
      "Epoch 34 step 7 loss: 0.3734985589981079\n",
      "Epoch 34 step 8 loss: 0.39108437299728394\n",
      "Epoch 34 step 9 loss: 0.3562527298927307\n",
      "Epoch 34 step 10 loss: 0.34377995133399963\n",
      "Epoch 34 step 11 loss: 0.33193644881248474\n",
      "Epoch 34 step 12 loss: 0.3906397223472595\n",
      "Epoch 34 step 13 loss: 0.4311680495738983\n",
      "Epoch 34 step 14 loss: 0.35790467262268066\n",
      "Epoch 34 step 15 loss: 0.37566494941711426\n",
      "Epoch 34 step 16 loss: 0.3725683093070984\n",
      "Epoch 34 step 17 loss: 0.3018535375595093\n",
      "Epoch 34 step 18 loss: 0.3764491081237793\n",
      "Epoch 34 step 19 loss: 0.3222627639770508\n",
      "Epoch 34 step 20 loss: 0.3184972107410431\n",
      "Epoch 34 step 21 loss: 0.3731726109981537\n",
      "Epoch 34 step 22 loss: 0.3967720568180084\n",
      "Epoch 34 step 23 loss: 0.24623684585094452\n",
      "Epoch 34 step 24 loss: 0.35769641399383545\n",
      "Epoch 34 step 25 loss: 0.3290644884109497\n",
      "Epoch 34 step 26 loss: 0.33674824237823486\n",
      "Epoch 34 step 27 loss: 0.3567793369293213\n",
      "Epoch 34 step 28 loss: 0.2978406548500061\n",
      "Epoch 34 step 29 loss: 0.3045482635498047\n",
      "Epoch 34 step 30 loss: 0.24560648202896118\n",
      "Epoch 34 step 31 loss: 0.3453260660171509\n",
      "Epoch 34 step 32 loss: 0.33546197414398193\n",
      "Epoch 34 step 33 loss: 0.26833105087280273\n",
      "Epoch 34 step 34 loss: 0.27847859263420105\n",
      "Epoch 34 step 35 loss: 0.2391887903213501\n",
      "Epoch 34 step 36 loss: 0.30574551224708557\n",
      "Epoch 34 step 37 loss: 0.29536744952201843\n",
      "Epoch 34 step 38 loss: 0.2773585617542267\n",
      "Epoch 34 loss: 0.2773585617542267\n",
      "Epoch 35 step 0 loss: 0.30350738763809204\n",
      "Epoch 35 step 1 loss: 0.305421382188797\n",
      "Epoch 35 step 2 loss: 0.303598552942276\n",
      "Epoch 35 step 3 loss: 0.3004159927368164\n",
      "Epoch 35 step 4 loss: 0.26885536313056946\n",
      "Epoch 35 step 5 loss: 0.26883164048194885\n",
      "Epoch 35 step 6 loss: 0.28894779086112976\n",
      "Epoch 35 step 7 loss: 0.3203771412372589\n",
      "Epoch 35 step 8 loss: 0.30910637974739075\n",
      "Epoch 35 step 9 loss: 0.3458898067474365\n",
      "Epoch 35 step 10 loss: 0.24429546296596527\n",
      "Epoch 35 step 11 loss: 0.2897450625896454\n",
      "Epoch 35 step 12 loss: 0.29729586839675903\n",
      "Epoch 35 step 13 loss: 0.3309229612350464\n",
      "Epoch 35 step 14 loss: 0.2994806170463562\n",
      "Epoch 35 step 15 loss: 0.2835032045841217\n",
      "Epoch 35 step 16 loss: 0.3433932065963745\n",
      "Epoch 35 step 17 loss: 0.3520333468914032\n",
      "Epoch 35 step 18 loss: 0.2459675520658493\n",
      "Epoch 35 step 19 loss: 0.3013153076171875\n",
      "Epoch 35 step 20 loss: 0.279588907957077\n",
      "Epoch 35 step 21 loss: 0.29698362946510315\n",
      "Epoch 35 step 22 loss: 0.2803751826286316\n",
      "Epoch 35 step 23 loss: 0.38507649302482605\n",
      "Epoch 35 step 24 loss: 0.2871840000152588\n",
      "Epoch 35 step 25 loss: 0.39088255167007446\n",
      "Epoch 35 step 26 loss: 0.3493156433105469\n",
      "Epoch 35 step 27 loss: 0.40637892484664917\n",
      "Epoch 35 step 28 loss: 0.4049215316772461\n",
      "Epoch 35 step 29 loss: 0.37275853753089905\n",
      "Epoch 35 step 30 loss: 0.474895179271698\n",
      "Epoch 35 step 31 loss: 0.3368874192237854\n",
      "Epoch 35 step 32 loss: 0.34503963589668274\n",
      "Epoch 35 step 33 loss: 0.37177959084510803\n",
      "Epoch 35 step 34 loss: 0.3159388303756714\n",
      "Epoch 35 step 35 loss: 0.3172067105770111\n",
      "Epoch 35 step 36 loss: 0.27288395166397095\n",
      "Epoch 35 step 37 loss: 0.3054163157939911\n",
      "Epoch 35 step 38 loss: 0.2099183052778244\n",
      "Epoch 35 loss: 0.2099183052778244\n",
      "Epoch 36 step 0 loss: 0.36831143498420715\n",
      "Epoch 36 step 1 loss: 0.26905569434165955\n",
      "Epoch 36 step 2 loss: 0.41628220677375793\n",
      "Epoch 36 step 3 loss: 0.3477080464363098\n",
      "Epoch 36 step 4 loss: 0.38512399792671204\n",
      "Epoch 36 step 5 loss: 0.3844757080078125\n",
      "Epoch 36 step 6 loss: 0.29914745688438416\n",
      "Epoch 36 step 7 loss: 0.3306467533111572\n",
      "Epoch 36 step 8 loss: 0.33798640966415405\n",
      "Epoch 36 step 9 loss: 0.3244597613811493\n",
      "Epoch 36 step 10 loss: 0.35498905181884766\n",
      "Epoch 36 step 11 loss: 0.3691916763782501\n",
      "Epoch 36 step 12 loss: 0.34511491656303406\n",
      "Epoch 36 step 13 loss: 0.3242419958114624\n",
      "Epoch 36 step 14 loss: 0.3942279517650604\n",
      "Epoch 36 step 15 loss: 0.3517344892024994\n",
      "Epoch 36 step 16 loss: 0.3429783582687378\n",
      "Epoch 36 step 17 loss: 0.3919766843318939\n",
      "Epoch 36 step 18 loss: 0.30785253643989563\n",
      "Epoch 36 step 19 loss: 0.2653563320636749\n",
      "Epoch 36 step 20 loss: 0.3775232434272766\n",
      "Epoch 36 step 21 loss: 0.37794816493988037\n",
      "Epoch 36 step 22 loss: 0.37293726205825806\n",
      "Epoch 36 step 23 loss: 0.38242554664611816\n",
      "Epoch 36 step 24 loss: 0.3814380168914795\n",
      "Epoch 36 step 25 loss: 0.34781500697135925\n",
      "Epoch 36 step 26 loss: 0.3829144239425659\n",
      "Epoch 36 step 27 loss: 0.32342371344566345\n",
      "Epoch 36 step 28 loss: 0.3926732540130615\n",
      "Epoch 36 step 29 loss: 0.36923205852508545\n",
      "Epoch 36 step 30 loss: 0.27570465207099915\n",
      "Epoch 36 step 31 loss: 0.39213207364082336\n",
      "Epoch 36 step 32 loss: 0.35530009865760803\n",
      "Epoch 36 step 33 loss: 0.3961358964443207\n",
      "Epoch 36 step 34 loss: 0.3333369195461273\n",
      "Epoch 36 step 35 loss: 0.30032840371131897\n",
      "Epoch 36 step 36 loss: 0.34625229239463806\n",
      "Epoch 36 step 37 loss: 0.35495489835739136\n",
      "Epoch 36 step 38 loss: 0.2916744351387024\n",
      "Epoch 36 loss: 0.2916744351387024\n",
      "Epoch 37 step 0 loss: 0.3338591456413269\n",
      "Epoch 37 step 1 loss: 0.3325185775756836\n",
      "Epoch 37 step 2 loss: 0.3157045245170593\n",
      "Epoch 37 step 3 loss: 0.34705621004104614\n",
      "Epoch 37 step 4 loss: 0.296401709318161\n",
      "Epoch 37 step 5 loss: 0.30457404255867004\n",
      "Epoch 37 step 6 loss: 0.3347301185131073\n",
      "Epoch 37 step 7 loss: 0.3292648196220398\n",
      "Epoch 37 step 8 loss: 0.23518729209899902\n",
      "Epoch 37 step 9 loss: 0.3124592900276184\n",
      "Epoch 37 step 10 loss: 0.27185168862342834\n",
      "Epoch 37 step 11 loss: 0.2972913086414337\n",
      "Epoch 37 step 12 loss: 0.3464386761188507\n",
      "Epoch 37 step 13 loss: 0.2973942160606384\n",
      "Epoch 37 step 14 loss: 0.3140742778778076\n",
      "Epoch 37 step 15 loss: 0.28383585810661316\n",
      "Epoch 37 step 16 loss: 0.3112913966178894\n",
      "Epoch 37 step 17 loss: 0.2962791323661804\n",
      "Epoch 37 step 18 loss: 0.35043856501579285\n",
      "Epoch 37 step 19 loss: 0.24999688565731049\n",
      "Epoch 37 step 20 loss: 0.32899096608161926\n",
      "Epoch 37 step 21 loss: 0.3515590727329254\n",
      "Epoch 37 step 22 loss: 0.3324548900127411\n",
      "Epoch 37 step 23 loss: 0.3604776859283447\n",
      "Epoch 37 step 24 loss: 0.29645973443984985\n",
      "Epoch 37 step 25 loss: 0.3610295057296753\n",
      "Epoch 37 step 26 loss: 0.27176573872566223\n",
      "Epoch 37 step 27 loss: 0.2750585079193115\n",
      "Epoch 37 step 28 loss: 0.28180164098739624\n",
      "Epoch 37 step 29 loss: 0.369112491607666\n",
      "Epoch 37 step 30 loss: 0.37267133593559265\n",
      "Epoch 37 step 31 loss: 0.32969561219215393\n",
      "Epoch 37 step 32 loss: 0.2694648206233978\n",
      "Epoch 37 step 33 loss: 0.2861182987689972\n",
      "Epoch 37 step 34 loss: 0.3059448003768921\n",
      "Epoch 37 step 35 loss: 0.2659608721733093\n",
      "Epoch 37 step 36 loss: 0.3249432444572449\n",
      "Epoch 37 step 37 loss: 0.31387609243392944\n",
      "Epoch 37 step 38 loss: 0.2936812937259674\n",
      "Epoch 37 loss: 0.2936812937259674\n",
      "Epoch 38 step 0 loss: 0.3493172824382782\n",
      "Epoch 38 step 1 loss: 0.43679672479629517\n",
      "Epoch 38 step 2 loss: 0.31268343329429626\n",
      "Epoch 38 step 3 loss: 0.32438594102859497\n",
      "Epoch 38 step 4 loss: 0.35880202054977417\n",
      "Epoch 38 step 5 loss: 0.3594895601272583\n",
      "Epoch 38 step 6 loss: 0.30802029371261597\n",
      "Epoch 38 step 7 loss: 0.3970848023891449\n",
      "Epoch 38 step 8 loss: 0.3256303668022156\n",
      "Epoch 38 step 9 loss: 0.28969085216522217\n",
      "Epoch 38 step 10 loss: 0.36903393268585205\n",
      "Epoch 38 step 11 loss: 0.36665189266204834\n",
      "Epoch 38 step 12 loss: 0.30959072709083557\n",
      "Epoch 38 step 13 loss: 0.3991157114505768\n",
      "Epoch 38 step 14 loss: 0.36132970452308655\n",
      "Epoch 38 step 15 loss: 0.3098794221878052\n",
      "Epoch 38 step 16 loss: 0.282680869102478\n",
      "Epoch 38 step 17 loss: 0.31709229946136475\n",
      "Epoch 38 step 18 loss: 0.29947707056999207\n",
      "Epoch 38 step 19 loss: 0.26096874475479126\n",
      "Epoch 38 step 20 loss: 0.3090377449989319\n",
      "Epoch 38 step 21 loss: 0.2785405218601227\n",
      "Epoch 38 step 22 loss: 0.24044080078601837\n",
      "Epoch 38 step 23 loss: 0.2954885959625244\n",
      "Epoch 38 step 24 loss: 0.3013572096824646\n",
      "Epoch 38 step 25 loss: 0.370892733335495\n",
      "Epoch 38 step 26 loss: 0.31886985898017883\n",
      "Epoch 38 step 27 loss: 0.30750203132629395\n",
      "Epoch 38 step 28 loss: 0.24211880564689636\n",
      "Epoch 38 step 29 loss: 0.23658770322799683\n",
      "Epoch 38 step 30 loss: 0.2780022919178009\n",
      "Epoch 38 step 31 loss: 0.3465370833873749\n",
      "Epoch 38 step 32 loss: 0.27114173769950867\n",
      "Epoch 38 step 33 loss: 0.31793156266212463\n",
      "Epoch 38 step 34 loss: 0.2959204912185669\n",
      "Epoch 38 step 35 loss: 0.3148830533027649\n",
      "Epoch 38 step 36 loss: 0.239939346909523\n",
      "Epoch 38 step 37 loss: 0.303046852350235\n",
      "Epoch 38 step 38 loss: 0.31560593843460083\n",
      "Epoch 38 loss: 0.31560593843460083\n",
      "Epoch 39 step 0 loss: 0.2829301953315735\n",
      "Epoch 39 step 1 loss: 0.30806127190589905\n",
      "Epoch 39 step 2 loss: 0.2977442741394043\n",
      "Epoch 39 step 3 loss: 0.2452784776687622\n",
      "Epoch 39 step 4 loss: 0.26942020654678345\n",
      "Epoch 39 step 5 loss: 0.3187904953956604\n",
      "Epoch 39 step 6 loss: 0.3481954336166382\n",
      "Epoch 39 step 7 loss: 0.2817917764186859\n",
      "Epoch 39 step 8 loss: 0.26645803451538086\n",
      "Epoch 39 step 9 loss: 0.3307730257511139\n",
      "Epoch 39 step 10 loss: 0.30680784583091736\n",
      "Epoch 39 step 11 loss: 0.31478559970855713\n",
      "Epoch 39 step 12 loss: 0.3025083541870117\n",
      "Epoch 39 step 13 loss: 0.2781391739845276\n",
      "Epoch 39 step 14 loss: 0.37183117866516113\n",
      "Epoch 39 step 15 loss: 0.3322645127773285\n",
      "Epoch 39 step 16 loss: 0.3414987027645111\n",
      "Epoch 39 step 17 loss: 0.2412724792957306\n",
      "Epoch 39 step 18 loss: 0.30726906657218933\n",
      "Epoch 39 step 19 loss: 0.30076923966407776\n",
      "Epoch 39 step 20 loss: 0.2931719720363617\n",
      "Epoch 39 step 21 loss: 0.2701572775840759\n",
      "Epoch 39 step 22 loss: 0.3164445459842682\n",
      "Epoch 39 step 23 loss: 0.3579135239124298\n",
      "Epoch 39 step 24 loss: 0.31554603576660156\n",
      "Epoch 39 step 25 loss: 0.3676737844944\n",
      "Epoch 39 step 26 loss: 0.3176139295101166\n",
      "Epoch 39 step 27 loss: 0.3017415404319763\n",
      "Epoch 39 step 28 loss: 0.34868723154067993\n",
      "Epoch 39 step 29 loss: 0.23874877393245697\n",
      "Epoch 39 step 30 loss: 0.4315880537033081\n",
      "Epoch 39 step 31 loss: 0.36846134066581726\n",
      "Epoch 39 step 32 loss: 0.3970896005630493\n",
      "Epoch 39 step 33 loss: 0.3394509553909302\n",
      "Epoch 39 step 34 loss: 0.3290020823478699\n",
      "Epoch 39 step 35 loss: 0.3717251121997833\n",
      "Epoch 39 step 36 loss: 0.4009941816329956\n",
      "Epoch 39 step 37 loss: 0.2209756076335907\n",
      "Epoch 39 step 38 loss: 0.37984025478363037\n",
      "Epoch 39 loss: 0.37984025478363037\n",
      "Epoch 40 step 0 loss: 0.3835877776145935\n",
      "Epoch 40 step 1 loss: 0.3281764090061188\n",
      "Epoch 40 step 2 loss: 0.23350298404693604\n",
      "Epoch 40 step 3 loss: 0.2782098352909088\n",
      "Epoch 40 step 4 loss: 0.31725794076919556\n",
      "Epoch 40 step 5 loss: 0.28514501452445984\n",
      "Epoch 40 step 6 loss: 0.2711924910545349\n",
      "Epoch 40 step 7 loss: 0.39069893956184387\n",
      "Epoch 40 step 8 loss: 0.36830294132232666\n",
      "Epoch 40 step 9 loss: 0.29924049973487854\n",
      "Epoch 40 step 10 loss: 0.325783371925354\n",
      "Epoch 40 step 11 loss: 0.3658038377761841\n",
      "Epoch 40 step 12 loss: 0.2927433252334595\n",
      "Epoch 40 step 13 loss: 0.3227357864379883\n",
      "Epoch 40 step 14 loss: 0.31494319438934326\n",
      "Epoch 40 step 15 loss: 0.37898823618888855\n",
      "Epoch 40 step 16 loss: 0.267625093460083\n",
      "Epoch 40 step 17 loss: 0.29349207878112793\n",
      "Epoch 40 step 18 loss: 0.3201367259025574\n",
      "Epoch 40 step 19 loss: 0.2735406458377838\n",
      "Epoch 40 step 20 loss: 0.27588504552841187\n",
      "Epoch 40 step 21 loss: 0.3139997124671936\n",
      "Epoch 40 step 22 loss: 0.29098618030548096\n",
      "Epoch 40 step 23 loss: 0.3529626429080963\n",
      "Epoch 40 step 24 loss: 0.3487142026424408\n",
      "Epoch 40 step 25 loss: 0.2857481837272644\n",
      "Epoch 40 step 26 loss: 0.31495898962020874\n",
      "Epoch 40 step 27 loss: 0.32593443989753723\n",
      "Epoch 40 step 28 loss: 0.3074057996273041\n",
      "Epoch 40 step 29 loss: 0.29732292890548706\n",
      "Epoch 40 step 30 loss: 0.3942312002182007\n",
      "Epoch 40 step 31 loss: 0.2792300581932068\n",
      "Epoch 40 step 32 loss: 0.24678874015808105\n",
      "Epoch 40 step 33 loss: 0.42314231395721436\n",
      "Epoch 40 step 34 loss: 0.3205438554286957\n",
      "Epoch 40 step 35 loss: 0.2937507629394531\n",
      "Epoch 40 step 36 loss: 0.2994265556335449\n",
      "Epoch 40 step 37 loss: 0.2838810384273529\n",
      "Epoch 40 step 38 loss: 0.2532065510749817\n",
      "Epoch 40 loss: 0.2532065510749817\n",
      "Epoch 41 step 0 loss: 0.292788565158844\n",
      "Epoch 41 step 1 loss: 0.2901710569858551\n",
      "Epoch 41 step 2 loss: 0.3109252154827118\n",
      "Epoch 41 step 3 loss: 0.2616015374660492\n",
      "Epoch 41 step 4 loss: 0.2807246744632721\n",
      "Epoch 41 step 5 loss: 0.32096508145332336\n",
      "Epoch 41 step 6 loss: 0.2878243327140808\n",
      "Epoch 41 step 7 loss: 0.30563509464263916\n",
      "Epoch 41 step 8 loss: 0.37664589285850525\n",
      "Epoch 41 step 9 loss: 0.3335711359977722\n",
      "Epoch 41 step 10 loss: 0.2597522437572479\n",
      "Epoch 41 step 11 loss: 0.38477301597595215\n",
      "Epoch 41 step 12 loss: 0.32013139128685\n",
      "Epoch 41 step 13 loss: 0.24319389462471008\n",
      "Epoch 41 step 14 loss: 0.28160595893859863\n",
      "Epoch 41 step 15 loss: 0.28200167417526245\n",
      "Epoch 41 step 16 loss: 0.28287139534950256\n",
      "Epoch 41 step 17 loss: 0.2667606472969055\n",
      "Epoch 41 step 18 loss: 0.3140828013420105\n",
      "Epoch 41 step 19 loss: 0.28957879543304443\n",
      "Epoch 41 step 20 loss: 0.34590476751327515\n",
      "Epoch 41 step 21 loss: 0.25936317443847656\n",
      "Epoch 41 step 22 loss: 0.31517738103866577\n",
      "Epoch 41 step 23 loss: 0.324224054813385\n",
      "Epoch 41 step 24 loss: 0.289333313703537\n",
      "Epoch 41 step 25 loss: 0.21014486253261566\n",
      "Epoch 41 step 26 loss: 0.35706910490989685\n",
      "Epoch 41 step 27 loss: 0.253339946269989\n",
      "Epoch 41 step 28 loss: 0.2917613983154297\n",
      "Epoch 41 step 29 loss: 0.2409769743680954\n",
      "Epoch 41 step 30 loss: 0.33143794536590576\n",
      "Epoch 41 step 31 loss: 0.31545165181159973\n",
      "Epoch 41 step 32 loss: 0.3696557879447937\n",
      "Epoch 41 step 33 loss: 0.32614096999168396\n",
      "Epoch 41 step 34 loss: 0.29913535714149475\n",
      "Epoch 41 step 35 loss: 0.3687696158885956\n",
      "Epoch 41 step 36 loss: 0.350064218044281\n",
      "Epoch 41 step 37 loss: 0.3878195583820343\n",
      "Epoch 41 step 38 loss: 0.42488858103752136\n",
      "Epoch 41 loss: 0.42488858103752136\n",
      "Epoch 42 step 0 loss: 0.30119431018829346\n",
      "Epoch 42 step 1 loss: 0.3726175129413605\n",
      "Epoch 42 step 2 loss: 0.3550521731376648\n",
      "Epoch 42 step 3 loss: 0.41807442903518677\n",
      "Epoch 42 step 4 loss: 0.46285322308540344\n",
      "Epoch 42 step 5 loss: 0.43256205320358276\n",
      "Epoch 42 step 6 loss: 0.3481011986732483\n",
      "Epoch 42 step 7 loss: 0.5420736074447632\n",
      "Epoch 42 step 8 loss: 0.42195925116539\n",
      "Epoch 42 step 9 loss: 0.3786991238594055\n",
      "Epoch 42 step 10 loss: 0.4092216491699219\n",
      "Epoch 42 step 11 loss: 0.4823891222476959\n",
      "Epoch 42 step 12 loss: 0.33217906951904297\n",
      "Epoch 42 step 13 loss: 0.4167693555355072\n",
      "Epoch 42 step 14 loss: 0.49121034145355225\n",
      "Epoch 42 step 15 loss: 0.4586694836616516\n",
      "Epoch 42 step 16 loss: 0.37463250756263733\n",
      "Epoch 42 step 17 loss: 0.315247505903244\n",
      "Epoch 42 step 18 loss: 0.443928062915802\n",
      "Epoch 42 step 19 loss: 0.33337777853012085\n",
      "Epoch 42 step 20 loss: 0.4407714903354645\n",
      "Epoch 42 step 21 loss: 0.3613433241844177\n",
      "Epoch 42 step 22 loss: 0.4627555310726166\n",
      "Epoch 42 step 23 loss: 0.38534167408943176\n",
      "Epoch 42 step 24 loss: 0.3585972785949707\n",
      "Epoch 42 step 25 loss: 0.2848181128501892\n",
      "Epoch 42 step 26 loss: 0.40579742193222046\n",
      "Epoch 42 step 27 loss: 0.308852881193161\n",
      "Epoch 42 step 28 loss: 0.3386303186416626\n",
      "Epoch 42 step 29 loss: 0.3362422287464142\n",
      "Epoch 42 step 30 loss: 0.31699445843696594\n",
      "Epoch 42 step 31 loss: 0.3514108955860138\n",
      "Epoch 42 step 32 loss: 0.3669400215148926\n",
      "Epoch 42 step 33 loss: 0.3999253213405609\n",
      "Epoch 42 step 34 loss: 0.4327811002731323\n",
      "Epoch 42 step 35 loss: 0.315418541431427\n",
      "Epoch 42 step 36 loss: 0.33441004157066345\n",
      "Epoch 42 step 37 loss: 0.3953677713871002\n",
      "Epoch 42 step 38 loss: 0.41413038969039917\n",
      "Epoch 42 loss: 0.41413038969039917\n",
      "Epoch 43 step 0 loss: 0.34100106358528137\n",
      "Epoch 43 step 1 loss: 0.3642432391643524\n",
      "Epoch 43 step 2 loss: 0.39323505759239197\n",
      "Epoch 43 step 3 loss: 0.31867706775665283\n",
      "Epoch 43 step 4 loss: 0.29567885398864746\n",
      "Epoch 43 step 5 loss: 0.35289451479911804\n",
      "Epoch 43 step 6 loss: 0.31624817848205566\n",
      "Epoch 43 step 7 loss: 0.392499715089798\n",
      "Epoch 43 step 8 loss: 0.41189903020858765\n",
      "Epoch 43 step 9 loss: 0.32568395137786865\n",
      "Epoch 43 step 10 loss: 0.3711993098258972\n",
      "Epoch 43 step 11 loss: 0.3149975538253784\n",
      "Epoch 43 step 12 loss: 0.3379508852958679\n",
      "Epoch 43 step 13 loss: 0.30950427055358887\n",
      "Epoch 43 step 14 loss: 0.34546133875846863\n",
      "Epoch 43 step 15 loss: 0.33865272998809814\n",
      "Epoch 43 step 16 loss: 0.30683764815330505\n",
      "Epoch 43 step 17 loss: 0.38311535120010376\n",
      "Epoch 43 step 18 loss: 0.26396071910858154\n",
      "Epoch 43 step 19 loss: 0.25649094581604004\n",
      "Epoch 43 step 20 loss: 0.339139461517334\n",
      "Epoch 43 step 21 loss: 0.3286057412624359\n",
      "Epoch 43 step 22 loss: 0.35443955659866333\n",
      "Epoch 43 step 23 loss: 0.2677425146102905\n",
      "Epoch 43 step 24 loss: 0.3141799569129944\n",
      "Epoch 43 step 25 loss: 0.32975369691848755\n",
      "Epoch 43 step 26 loss: 0.4018605947494507\n",
      "Epoch 43 step 27 loss: 0.37129342555999756\n",
      "Epoch 43 step 28 loss: 0.31315872073173523\n",
      "Epoch 43 step 29 loss: 0.3339373767375946\n",
      "Epoch 43 step 30 loss: 0.2663319408893585\n",
      "Epoch 43 step 31 loss: 0.30330726504325867\n",
      "Epoch 43 step 32 loss: 0.29267221689224243\n",
      "Epoch 43 step 33 loss: 0.2469077706336975\n",
      "Epoch 43 step 34 loss: 0.2709101736545563\n",
      "Epoch 43 step 35 loss: 0.33281847834587097\n",
      "Epoch 43 step 36 loss: 0.27159860730171204\n",
      "Epoch 43 step 37 loss: 0.3111279606819153\n",
      "Epoch 43 step 38 loss: 0.30873796343803406\n",
      "Epoch 43 loss: 0.30873796343803406\n",
      "Epoch 44 step 0 loss: 0.2815060615539551\n",
      "Epoch 44 step 1 loss: 0.30770474672317505\n",
      "Epoch 44 step 2 loss: 0.2739443778991699\n",
      "Epoch 44 step 3 loss: 0.40476512908935547\n",
      "Epoch 44 step 4 loss: 0.2584126591682434\n",
      "Epoch 44 step 5 loss: 0.31707215309143066\n",
      "Epoch 44 step 6 loss: 0.31620287895202637\n",
      "Epoch 44 step 7 loss: 0.3285464644432068\n",
      "Epoch 44 step 8 loss: 0.26139363646507263\n",
      "Epoch 44 step 9 loss: 0.29594945907592773\n",
      "Epoch 44 step 10 loss: 0.3411394953727722\n",
      "Epoch 44 step 11 loss: 0.2797884941101074\n",
      "Epoch 44 step 12 loss: 0.37786757946014404\n",
      "Epoch 44 step 13 loss: 0.33933931589126587\n",
      "Epoch 44 step 14 loss: 0.33220380544662476\n",
      "Epoch 44 step 15 loss: 0.2596125900745392\n",
      "Epoch 44 step 16 loss: 0.31539386510849\n",
      "Epoch 44 step 17 loss: 0.27773141860961914\n",
      "Epoch 44 step 18 loss: 0.3843971788883209\n",
      "Epoch 44 step 19 loss: 0.3594617247581482\n",
      "Epoch 44 step 20 loss: 0.30759698152542114\n",
      "Epoch 44 step 21 loss: 0.3207300305366516\n",
      "Epoch 44 step 22 loss: 0.35584214329719543\n",
      "Epoch 44 step 23 loss: 0.3929637372493744\n",
      "Epoch 44 step 24 loss: 0.3934653103351593\n",
      "Epoch 44 step 25 loss: 0.41577255725860596\n",
      "Epoch 44 step 26 loss: 0.29719191789627075\n",
      "Epoch 44 step 27 loss: 0.37405332922935486\n",
      "Epoch 44 step 28 loss: 0.4276290535926819\n",
      "Epoch 44 step 29 loss: 0.3309516906738281\n",
      "Epoch 44 step 30 loss: 0.524268627166748\n",
      "Epoch 44 step 31 loss: 0.25172752141952515\n",
      "Epoch 44 step 32 loss: 0.4381209909915924\n",
      "Epoch 44 step 33 loss: 0.3841061294078827\n",
      "Epoch 44 step 34 loss: 0.38581639528274536\n",
      "Epoch 44 step 35 loss: 0.34313493967056274\n",
      "Epoch 44 step 36 loss: 0.34215423464775085\n",
      "Epoch 44 step 37 loss: 0.3224940896034241\n",
      "Epoch 44 step 38 loss: 0.21028271317481995\n",
      "Epoch 44 loss: 0.21028271317481995\n",
      "Epoch 45 step 0 loss: 0.3296777009963989\n",
      "Epoch 45 step 1 loss: 0.34105244278907776\n",
      "Epoch 45 step 2 loss: 0.3584694564342499\n",
      "Epoch 45 step 3 loss: 0.3725590407848358\n",
      "Epoch 45 step 4 loss: 0.35317325592041016\n",
      "Epoch 45 step 5 loss: 0.3120400607585907\n",
      "Epoch 45 step 6 loss: 0.31965917348861694\n",
      "Epoch 45 step 7 loss: 0.3107164204120636\n",
      "Epoch 45 step 8 loss: 0.33275577425956726\n",
      "Epoch 45 step 9 loss: 0.28102046251296997\n",
      "Epoch 45 step 10 loss: 0.297877699136734\n",
      "Epoch 45 step 11 loss: 0.3103933036327362\n",
      "Epoch 45 step 12 loss: 0.3570360541343689\n",
      "Epoch 45 step 13 loss: 0.3149549067020416\n",
      "Epoch 45 step 14 loss: 0.3727720379829407\n",
      "Epoch 45 step 15 loss: 0.4011218249797821\n",
      "Epoch 45 step 16 loss: 0.2934655547142029\n",
      "Epoch 45 step 17 loss: 0.34072309732437134\n",
      "Epoch 45 step 18 loss: 0.27237409353256226\n",
      "Epoch 45 step 19 loss: 0.39507782459259033\n",
      "Epoch 45 step 20 loss: 0.324040025472641\n",
      "Epoch 45 step 21 loss: 0.28896769881248474\n",
      "Epoch 45 step 22 loss: 0.30071505904197693\n",
      "Epoch 45 step 23 loss: 0.28890979290008545\n",
      "Epoch 45 step 24 loss: 0.2720465362071991\n",
      "Epoch 45 step 25 loss: 0.3895326554775238\n",
      "Epoch 45 step 26 loss: 0.2735883295536041\n",
      "Epoch 45 step 27 loss: 0.31133121252059937\n",
      "Epoch 45 step 28 loss: 0.3848420977592468\n",
      "Epoch 45 step 29 loss: 0.3071373701095581\n",
      "Epoch 45 step 30 loss: 0.29607322812080383\n",
      "Epoch 45 step 31 loss: 0.2629587650299072\n",
      "Epoch 45 step 32 loss: 0.3965085446834564\n",
      "Epoch 45 step 33 loss: 0.2400292307138443\n",
      "Epoch 45 step 34 loss: 0.33018332719802856\n",
      "Epoch 45 step 35 loss: 0.24226292967796326\n",
      "Epoch 45 step 36 loss: 0.2939910888671875\n",
      "Epoch 45 step 37 loss: 0.3303956687450409\n",
      "Epoch 45 step 38 loss: 0.3154084384441376\n",
      "Epoch 45 loss: 0.3154084384441376\n",
      "Epoch 46 step 0 loss: 0.38354331254959106\n",
      "Epoch 46 step 1 loss: 0.31088995933532715\n",
      "Epoch 46 step 2 loss: 0.4553056061267853\n",
      "Epoch 46 step 3 loss: 0.2735632658004761\n",
      "Epoch 46 step 4 loss: 0.3365050256252289\n",
      "Epoch 46 step 5 loss: 0.33382314443588257\n",
      "Epoch 46 step 6 loss: 0.41658174991607666\n",
      "Epoch 46 step 7 loss: 0.39593303203582764\n",
      "Epoch 46 step 8 loss: 0.29674866795539856\n",
      "Epoch 46 step 9 loss: 0.30858150124549866\n",
      "Epoch 46 step 10 loss: 0.29891055822372437\n",
      "Epoch 46 step 11 loss: 0.2918631434440613\n",
      "Epoch 46 step 12 loss: 0.3480624556541443\n",
      "Epoch 46 step 13 loss: 0.24769333004951477\n",
      "Epoch 46 step 14 loss: 0.2578933835029602\n",
      "Epoch 46 step 15 loss: 0.3733792304992676\n",
      "Epoch 46 step 16 loss: 0.3534970283508301\n",
      "Epoch 46 step 17 loss: 0.4176301956176758\n",
      "Epoch 46 step 18 loss: 0.29163557291030884\n",
      "Epoch 46 step 19 loss: 0.3097124993801117\n",
      "Epoch 46 step 20 loss: 0.33988189697265625\n",
      "Epoch 46 step 21 loss: 0.3071661591529846\n",
      "Epoch 46 step 22 loss: 0.3287073075771332\n",
      "Epoch 46 step 23 loss: 0.33653774857521057\n",
      "Epoch 46 step 24 loss: 0.27399688959121704\n",
      "Epoch 46 step 25 loss: 0.4005248546600342\n",
      "Epoch 46 step 26 loss: 0.2550998032093048\n",
      "Epoch 46 step 27 loss: 0.4012290835380554\n",
      "Epoch 46 step 28 loss: 0.2969595789909363\n",
      "Epoch 46 step 29 loss: 0.30608952045440674\n",
      "Epoch 46 step 30 loss: 0.31819236278533936\n",
      "Epoch 46 step 31 loss: 0.2994937002658844\n",
      "Epoch 46 step 32 loss: 0.2712775468826294\n",
      "Epoch 46 step 33 loss: 0.3057924807071686\n",
      "Epoch 46 step 34 loss: 0.25933343172073364\n",
      "Epoch 46 step 35 loss: 0.26712191104888916\n",
      "Epoch 46 step 36 loss: 0.29915913939476013\n",
      "Epoch 46 step 37 loss: 0.32382678985595703\n",
      "Epoch 46 step 38 loss: 0.3075748383998871\n",
      "Epoch 46 loss: 0.3075748383998871\n",
      "Epoch 47 step 0 loss: 0.3750595152378082\n",
      "Epoch 47 step 1 loss: 0.367580771446228\n",
      "Epoch 47 step 2 loss: 0.31377971172332764\n",
      "Epoch 47 step 3 loss: 0.2900415360927582\n",
      "Epoch 47 step 4 loss: 0.3405396640300751\n",
      "Epoch 47 step 5 loss: 0.3209502398967743\n",
      "Epoch 47 step 6 loss: 0.4206130802631378\n",
      "Epoch 47 step 7 loss: 0.34993577003479004\n",
      "Epoch 47 step 8 loss: 0.3138524293899536\n",
      "Epoch 47 step 9 loss: 0.3127884566783905\n",
      "Epoch 47 step 10 loss: 0.4392738938331604\n",
      "Epoch 47 step 11 loss: 0.2994283139705658\n",
      "Epoch 47 step 12 loss: 0.28175023198127747\n",
      "Epoch 47 step 13 loss: 0.24305400252342224\n",
      "Epoch 47 step 14 loss: 0.3115682601928711\n",
      "Epoch 47 step 15 loss: 0.3853546380996704\n",
      "Epoch 47 step 16 loss: 0.30675193667411804\n",
      "Epoch 47 step 17 loss: 0.29698702692985535\n",
      "Epoch 47 step 18 loss: 0.318170428276062\n",
      "Epoch 47 step 19 loss: 0.36542683839797974\n",
      "Epoch 47 step 20 loss: 0.34836000204086304\n",
      "Epoch 47 step 21 loss: 0.24567998945713043\n",
      "Epoch 47 step 22 loss: 0.300649493932724\n",
      "Epoch 47 step 23 loss: 0.352533757686615\n",
      "Epoch 47 step 24 loss: 0.33841392397880554\n",
      "Epoch 47 step 25 loss: 0.3469657301902771\n",
      "Epoch 47 step 26 loss: 0.36113816499710083\n",
      "Epoch 47 step 27 loss: 0.3087291419506073\n",
      "Epoch 47 step 28 loss: 0.2574692368507385\n",
      "Epoch 47 step 29 loss: 0.25418365001678467\n",
      "Epoch 47 step 30 loss: 0.2640687823295593\n",
      "Epoch 47 step 31 loss: 0.25277474522590637\n",
      "Epoch 47 step 32 loss: 0.3151533305644989\n",
      "Epoch 47 step 33 loss: 0.34715861082077026\n",
      "Epoch 47 step 34 loss: 0.4156782627105713\n",
      "Epoch 47 step 35 loss: 0.2879818081855774\n",
      "Epoch 47 step 36 loss: 0.321237176656723\n",
      "Epoch 47 step 37 loss: 0.38487109541893005\n",
      "Epoch 47 step 38 loss: 0.2594381272792816\n",
      "Epoch 47 loss: 0.2594381272792816\n",
      "Epoch 48 step 0 loss: 0.3170878291130066\n",
      "Epoch 48 step 1 loss: 0.30874037742614746\n",
      "Epoch 48 step 2 loss: 0.33288249373435974\n",
      "Epoch 48 step 3 loss: 0.37499815225601196\n",
      "Epoch 48 step 4 loss: 0.316750168800354\n",
      "Epoch 48 step 5 loss: 0.2913210690021515\n",
      "Epoch 48 step 6 loss: 0.3608533442020416\n",
      "Epoch 48 step 7 loss: 0.36616310477256775\n",
      "Epoch 48 step 8 loss: 0.33763328194618225\n",
      "Epoch 48 step 9 loss: 0.3103695213794708\n",
      "Epoch 48 step 10 loss: 0.3210451602935791\n",
      "Epoch 48 step 11 loss: 0.24848103523254395\n",
      "Epoch 48 step 12 loss: 0.3863651752471924\n",
      "Epoch 48 step 13 loss: 0.33488553762435913\n",
      "Epoch 48 step 14 loss: 0.32284098863601685\n",
      "Epoch 48 step 15 loss: 0.2769489884376526\n",
      "Epoch 48 step 16 loss: 0.2910009026527405\n",
      "Epoch 48 step 17 loss: 0.30075398087501526\n",
      "Epoch 48 step 18 loss: 0.3444964289665222\n",
      "Epoch 48 step 19 loss: 0.270968496799469\n",
      "Epoch 48 step 20 loss: 0.3287056088447571\n",
      "Epoch 48 step 21 loss: 0.25962555408477783\n",
      "Epoch 48 step 22 loss: 0.3312574625015259\n",
      "Epoch 48 step 23 loss: 0.2826070189476013\n",
      "Epoch 48 step 24 loss: 0.33410483598709106\n",
      "Epoch 48 step 25 loss: 0.29369884729385376\n",
      "Epoch 48 step 26 loss: 0.333411306142807\n",
      "Epoch 48 step 27 loss: 0.31532973051071167\n",
      "Epoch 48 step 28 loss: 0.2759920060634613\n",
      "Epoch 48 step 29 loss: 0.2724677324295044\n",
      "Epoch 48 step 30 loss: 0.25322893261909485\n",
      "Epoch 48 step 31 loss: 0.32620131969451904\n",
      "Epoch 48 step 32 loss: 0.29425421357154846\n",
      "Epoch 48 step 33 loss: 0.3845940828323364\n",
      "Epoch 48 step 34 loss: 0.2648571729660034\n",
      "Epoch 48 step 35 loss: 0.29781052470207214\n",
      "Epoch 48 step 36 loss: 0.3580234944820404\n",
      "Epoch 48 step 37 loss: 0.2861934304237366\n",
      "Epoch 48 step 38 loss: 0.37353503704071045\n",
      "Epoch 48 loss: 0.37353503704071045\n",
      "Epoch 49 step 0 loss: 0.4917284846305847\n",
      "Epoch 49 step 1 loss: 0.3305783271789551\n",
      "Epoch 49 step 2 loss: 0.3447718024253845\n",
      "Epoch 49 step 3 loss: 0.283023864030838\n",
      "Epoch 49 step 4 loss: 0.3713997006416321\n",
      "Epoch 49 step 5 loss: 0.3552919626235962\n",
      "Epoch 49 step 6 loss: 0.3271771967411041\n",
      "Epoch 49 step 7 loss: 0.2979283928871155\n",
      "Epoch 49 step 8 loss: 0.3526678681373596\n",
      "Epoch 49 step 9 loss: 0.31701159477233887\n",
      "Epoch 49 step 10 loss: 0.37271764874458313\n",
      "Epoch 49 step 11 loss: 0.3069174587726593\n",
      "Epoch 49 step 12 loss: 0.3791586756706238\n",
      "Epoch 49 step 13 loss: 0.38107770681381226\n",
      "Epoch 49 step 14 loss: 0.333395779132843\n",
      "Epoch 49 step 15 loss: 0.3467479944229126\n",
      "Epoch 49 step 16 loss: 0.3188942074775696\n",
      "Epoch 49 step 17 loss: 0.3151463270187378\n",
      "Epoch 49 step 18 loss: 0.36709538102149963\n",
      "Epoch 49 step 19 loss: 0.29849714040756226\n",
      "Epoch 49 step 20 loss: 0.2584979236125946\n",
      "Epoch 49 step 21 loss: 0.39607512950897217\n",
      "Epoch 49 step 22 loss: 0.4171338975429535\n",
      "Epoch 49 step 23 loss: 0.29429882764816284\n",
      "Epoch 49 step 24 loss: 0.2995193302631378\n",
      "Epoch 49 step 25 loss: 0.3587017059326172\n",
      "Epoch 49 step 26 loss: 0.3612246513366699\n",
      "Epoch 49 step 27 loss: 0.3432142734527588\n",
      "Epoch 49 step 28 loss: 0.4612673223018646\n",
      "Epoch 49 step 29 loss: 0.3467203378677368\n",
      "Epoch 49 step 30 loss: 0.38175463676452637\n",
      "Epoch 49 step 31 loss: 0.44863617420196533\n",
      "Epoch 49 step 32 loss: 0.34821435809135437\n",
      "Epoch 49 step 33 loss: 0.3223225772380829\n",
      "Epoch 49 step 34 loss: 0.2827233374118805\n",
      "Epoch 49 step 35 loss: 0.3817787766456604\n",
      "Epoch 49 step 36 loss: 0.30221226811408997\n",
      "Epoch 49 step 37 loss: 0.3263011872768402\n",
      "Epoch 49 step 38 loss: 0.3838845491409302\n",
      "Epoch 49 loss: 0.3838845491409302\n",
      "Epoch 50 step 0 loss: 0.38507139682769775\n",
      "Epoch 50 step 1 loss: 0.3790886104106903\n",
      "Epoch 50 step 2 loss: 0.2840610146522522\n",
      "Epoch 50 step 3 loss: 0.30294427275657654\n",
      "Epoch 50 step 4 loss: 0.3458876609802246\n",
      "Epoch 50 step 5 loss: 0.2788292169570923\n",
      "Epoch 50 step 6 loss: 0.3721511960029602\n",
      "Epoch 50 step 7 loss: 0.3580518364906311\n",
      "Epoch 50 step 8 loss: 0.2888907194137573\n",
      "Epoch 50 step 9 loss: 0.3269065320491791\n",
      "Epoch 50 step 10 loss: 0.33417046070098877\n",
      "Epoch 50 step 11 loss: 0.34423747658729553\n",
      "Epoch 50 step 12 loss: 0.35977452993392944\n",
      "Epoch 50 step 13 loss: 0.3867616355419159\n",
      "Epoch 50 step 14 loss: 0.43190768361091614\n",
      "Epoch 50 step 15 loss: 0.39467141032218933\n",
      "Epoch 50 step 16 loss: 0.3380895256996155\n",
      "Epoch 50 step 17 loss: 0.4732750654220581\n",
      "Epoch 50 step 18 loss: 0.38627538084983826\n",
      "Epoch 50 step 19 loss: 0.37018245458602905\n",
      "Epoch 50 step 20 loss: 0.3382375240325928\n",
      "Epoch 50 step 21 loss: 0.38040292263031006\n",
      "Epoch 50 step 22 loss: 0.431896835565567\n",
      "Epoch 50 step 23 loss: 0.40451109409332275\n",
      "Epoch 50 step 24 loss: 0.478870153427124\n",
      "Epoch 50 step 25 loss: 0.41067439317703247\n",
      "Epoch 50 step 26 loss: 0.34425339102745056\n",
      "Epoch 50 step 27 loss: 0.2989710867404938\n",
      "Epoch 50 step 28 loss: 0.3393614590167999\n",
      "Epoch 50 step 29 loss: 0.3978426158428192\n",
      "Epoch 50 step 30 loss: 0.42141884565353394\n",
      "Epoch 50 step 31 loss: 0.4125992953777313\n",
      "Epoch 50 step 32 loss: 0.3448670208454132\n",
      "Epoch 50 step 33 loss: 0.3030858039855957\n",
      "Epoch 50 step 34 loss: 0.3678990304470062\n",
      "Epoch 50 step 35 loss: 0.39928728342056274\n",
      "Epoch 50 step 36 loss: 0.2821260392665863\n",
      "Epoch 50 step 37 loss: 0.36553412675857544\n",
      "Epoch 50 step 38 loss: 0.32985544204711914\n",
      "Epoch 50 loss: 0.32985544204711914\n",
      "Epoch 51 step 0 loss: 0.30371585488319397\n",
      "Epoch 51 step 1 loss: 0.33012956380844116\n",
      "Epoch 51 step 2 loss: 0.332019567489624\n",
      "Epoch 51 step 3 loss: 0.3010964095592499\n",
      "Epoch 51 step 4 loss: 0.358082115650177\n",
      "Epoch 51 step 5 loss: 0.2742992043495178\n",
      "Epoch 51 step 6 loss: 0.41165345907211304\n",
      "Epoch 51 step 7 loss: 0.35380780696868896\n",
      "Epoch 51 step 8 loss: 0.3127303719520569\n",
      "Epoch 51 step 9 loss: 0.2466011941432953\n",
      "Epoch 51 step 10 loss: 0.3392085134983063\n",
      "Epoch 51 step 11 loss: 0.2359602451324463\n",
      "Epoch 51 step 12 loss: 0.26327264308929443\n",
      "Epoch 51 step 13 loss: 0.33695176243782043\n",
      "Epoch 51 step 14 loss: 0.3687379062175751\n",
      "Epoch 51 step 15 loss: 0.37043479084968567\n",
      "Epoch 51 step 16 loss: 0.3006812036037445\n",
      "Epoch 51 step 17 loss: 0.34677648544311523\n",
      "Epoch 51 step 18 loss: 0.37578704953193665\n",
      "Epoch 51 step 19 loss: 0.4286905527114868\n",
      "Epoch 51 step 20 loss: 0.32651224732398987\n",
      "Epoch 51 step 21 loss: 0.36204323172569275\n",
      "Epoch 51 step 22 loss: 0.3965088427066803\n",
      "Epoch 51 step 23 loss: 0.44223853945732117\n",
      "Epoch 51 step 24 loss: 0.35790354013442993\n",
      "Epoch 51 step 25 loss: 0.3556285798549652\n",
      "Epoch 51 step 26 loss: 0.3050101697444916\n",
      "Epoch 51 step 27 loss: 0.2745477557182312\n",
      "Epoch 51 step 28 loss: 0.29055720567703247\n",
      "Epoch 51 step 29 loss: 0.41161608695983887\n",
      "Epoch 51 step 30 loss: 0.36465194821357727\n",
      "Epoch 51 step 31 loss: 0.31093862652778625\n",
      "Epoch 51 step 32 loss: 0.35733163356781006\n",
      "Epoch 51 step 33 loss: 0.28624284267425537\n",
      "Epoch 51 step 34 loss: 0.4187414050102234\n",
      "Epoch 51 step 35 loss: 0.36447760462760925\n",
      "Epoch 51 step 36 loss: 0.2778743505477905\n",
      "Epoch 51 step 37 loss: 0.3770092725753784\n",
      "Epoch 51 step 38 loss: 0.2980126738548279\n",
      "Epoch 51 loss: 0.2980126738548279\n",
      "Epoch 52 step 0 loss: 0.30366578698158264\n",
      "Epoch 52 step 1 loss: 0.40340790152549744\n",
      "Epoch 52 step 2 loss: 0.3116172254085541\n",
      "Epoch 52 step 3 loss: 0.2797384262084961\n",
      "Epoch 52 step 4 loss: 0.2734508812427521\n",
      "Epoch 52 step 5 loss: 0.34684252738952637\n",
      "Epoch 52 step 6 loss: 0.3140285611152649\n",
      "Epoch 52 step 7 loss: 0.36181381344795227\n",
      "Epoch 52 step 8 loss: 0.43439623713493347\n",
      "Epoch 52 step 9 loss: 0.3525789678096771\n",
      "Epoch 52 step 10 loss: 0.3376024067401886\n",
      "Epoch 52 step 11 loss: 0.33792844414711\n",
      "Epoch 52 step 12 loss: 0.3414101302623749\n",
      "Epoch 52 step 13 loss: 0.284723699092865\n",
      "Epoch 52 step 14 loss: 0.35750746726989746\n",
      "Epoch 52 step 15 loss: 0.3487761616706848\n",
      "Epoch 52 step 16 loss: 0.31986796855926514\n",
      "Epoch 52 step 17 loss: 0.3034586012363434\n",
      "Epoch 52 step 18 loss: 0.3916676342487335\n",
      "Epoch 52 step 19 loss: 0.2679101228713989\n",
      "Epoch 52 step 20 loss: 0.3083023726940155\n",
      "Epoch 52 step 21 loss: 0.21897852420806885\n",
      "Epoch 52 step 22 loss: 0.2916041910648346\n",
      "Epoch 52 step 23 loss: 0.25532281398773193\n",
      "Epoch 52 step 24 loss: 0.24165832996368408\n",
      "Epoch 52 step 25 loss: 0.3488325774669647\n",
      "Epoch 52 step 26 loss: 0.26427385210990906\n",
      "Epoch 52 step 27 loss: 0.299896776676178\n",
      "Epoch 52 step 28 loss: 0.3816099762916565\n",
      "Epoch 52 step 29 loss: 0.3223355710506439\n",
      "Epoch 52 step 30 loss: 0.29823797941207886\n",
      "Epoch 52 step 31 loss: 0.2574968636035919\n",
      "Epoch 52 step 32 loss: 0.2752186059951782\n",
      "Epoch 52 step 33 loss: 0.28815776109695435\n",
      "Epoch 52 step 34 loss: 0.27377232909202576\n",
      "Epoch 52 step 35 loss: 0.372549831867218\n",
      "Epoch 52 step 36 loss: 0.3477545380592346\n",
      "Epoch 52 step 37 loss: 0.39304548501968384\n",
      "Epoch 52 step 38 loss: 0.3096882998943329\n",
      "Epoch 52 loss: 0.3096882998943329\n",
      "Epoch 53 step 0 loss: 0.42131903767585754\n",
      "Epoch 53 step 1 loss: 0.3559700846672058\n",
      "Epoch 53 step 2 loss: 0.3918922543525696\n",
      "Epoch 53 step 3 loss: 0.42886367440223694\n",
      "Epoch 53 step 4 loss: 0.37233030796051025\n",
      "Epoch 53 step 5 loss: 0.30966049432754517\n",
      "Epoch 53 step 6 loss: 0.3418442904949188\n",
      "Epoch 53 step 7 loss: 0.2569011449813843\n",
      "Epoch 53 step 8 loss: 0.25987228751182556\n",
      "Epoch 53 step 9 loss: 0.3239527940750122\n",
      "Epoch 53 step 10 loss: 0.3548104763031006\n",
      "Epoch 53 step 11 loss: 0.4320946931838989\n",
      "Epoch 53 step 12 loss: 0.4655492901802063\n",
      "Epoch 53 step 13 loss: 0.3499870002269745\n",
      "Epoch 53 step 14 loss: 0.47797641158103943\n",
      "Epoch 53 step 15 loss: 0.3158671259880066\n",
      "Epoch 53 step 16 loss: 0.3205227851867676\n",
      "Epoch 53 step 17 loss: 0.4645090699195862\n",
      "Epoch 53 step 18 loss: 0.33922094106674194\n",
      "Epoch 53 step 19 loss: 0.42701423168182373\n",
      "Epoch 53 step 20 loss: 0.382030189037323\n",
      "Epoch 53 step 21 loss: 0.4072656035423279\n",
      "Epoch 53 step 22 loss: 0.3235972821712494\n",
      "Epoch 53 step 23 loss: 0.3534824550151825\n",
      "Epoch 53 step 24 loss: 0.34687718749046326\n",
      "Epoch 53 step 25 loss: 0.4868840277194977\n",
      "Epoch 53 step 26 loss: 0.39751338958740234\n",
      "Epoch 53 step 27 loss: 0.39242804050445557\n",
      "Epoch 53 step 28 loss: 0.3293955624103546\n",
      "Epoch 53 step 29 loss: 0.4214975833892822\n",
      "Epoch 53 step 30 loss: 0.4741169512271881\n",
      "Epoch 53 step 31 loss: 0.2845616042613983\n",
      "Epoch 53 step 32 loss: 0.3264293372631073\n",
      "Epoch 53 step 33 loss: 0.3289247751235962\n",
      "Epoch 53 step 34 loss: 0.39480090141296387\n",
      "Epoch 53 step 35 loss: 0.3236255943775177\n",
      "Epoch 53 step 36 loss: 0.3638102412223816\n",
      "Epoch 53 step 37 loss: 0.26302865147590637\n",
      "Epoch 53 step 38 loss: 0.30893731117248535\n",
      "Epoch 53 loss: 0.30893731117248535\n",
      "Epoch 54 step 0 loss: 0.34819838404655457\n",
      "Epoch 54 step 1 loss: 0.3109494149684906\n",
      "Epoch 54 step 2 loss: 0.3701491355895996\n",
      "Epoch 54 step 3 loss: 0.36942797899246216\n",
      "Epoch 54 step 4 loss: 0.46684929728507996\n",
      "Epoch 54 step 5 loss: 0.4350531995296478\n",
      "Epoch 54 step 6 loss: 0.3957612216472626\n",
      "Epoch 54 step 7 loss: 0.41647982597351074\n",
      "Epoch 54 step 8 loss: 0.4509437084197998\n",
      "Epoch 54 step 9 loss: 0.41580623388290405\n",
      "Epoch 54 step 10 loss: 0.35045772790908813\n",
      "Epoch 54 step 11 loss: 0.32014521956443787\n",
      "Epoch 54 step 12 loss: 0.3346347212791443\n",
      "Epoch 54 step 13 loss: 0.3175487816333771\n",
      "Epoch 54 step 14 loss: 0.40520796179771423\n",
      "Epoch 54 step 15 loss: 0.34856975078582764\n",
      "Epoch 54 step 16 loss: 0.35626524686813354\n",
      "Epoch 54 step 17 loss: 0.4151003658771515\n",
      "Epoch 54 step 18 loss: 0.5662968754768372\n",
      "Epoch 54 step 19 loss: 0.37429115176200867\n",
      "Epoch 54 step 20 loss: 0.3746988773345947\n",
      "Epoch 54 step 21 loss: 0.32261011004447937\n",
      "Epoch 54 step 22 loss: 0.31746843457221985\n",
      "Epoch 54 step 23 loss: 0.3943747580051422\n",
      "Epoch 54 step 24 loss: 0.36477094888687134\n",
      "Epoch 54 step 25 loss: 0.33436310291290283\n",
      "Epoch 54 step 26 loss: 0.4355083703994751\n",
      "Epoch 54 step 27 loss: 0.25404250621795654\n",
      "Epoch 54 step 28 loss: 0.39396995306015015\n",
      "Epoch 54 step 29 loss: 0.4531058073043823\n",
      "Epoch 54 step 30 loss: 0.3845561742782593\n",
      "Epoch 54 step 31 loss: 0.3728048801422119\n",
      "Epoch 54 step 32 loss: 0.4137755334377289\n",
      "Epoch 54 step 33 loss: 0.3584514856338501\n",
      "Epoch 54 step 34 loss: 0.44353482127189636\n",
      "Epoch 54 step 35 loss: 0.38012242317199707\n",
      "Epoch 54 step 36 loss: 0.2926182746887207\n",
      "Epoch 54 step 37 loss: 0.388395220041275\n",
      "Epoch 54 step 38 loss: 0.4748508334159851\n",
      "Epoch 54 loss: 0.4748508334159851\n",
      "Epoch 55 step 0 loss: 0.2476833462715149\n",
      "Epoch 55 step 1 loss: 0.35100194811820984\n",
      "Epoch 55 step 2 loss: 0.3372653126716614\n",
      "Epoch 55 step 3 loss: 0.5048668384552002\n",
      "Epoch 55 step 4 loss: 0.34322160482406616\n",
      "Epoch 55 step 5 loss: 0.31477460265159607\n",
      "Epoch 55 step 6 loss: 0.3217133581638336\n",
      "Epoch 55 step 7 loss: 0.5265353322029114\n",
      "Epoch 55 step 8 loss: 0.3333875834941864\n",
      "Epoch 55 step 9 loss: 0.41198474168777466\n",
      "Epoch 55 step 10 loss: 0.3889767527580261\n",
      "Epoch 55 step 11 loss: 0.324074923992157\n",
      "Epoch 55 step 12 loss: 0.3852624297142029\n",
      "Epoch 55 step 13 loss: 0.42083656787872314\n",
      "Epoch 55 step 14 loss: 0.3038300573825836\n",
      "Epoch 55 step 15 loss: 0.38754549622535706\n",
      "Epoch 55 step 16 loss: 0.30513274669647217\n",
      "Epoch 55 step 17 loss: 0.39936748147010803\n",
      "Epoch 55 step 18 loss: 0.31256529688835144\n",
      "Epoch 55 step 19 loss: 0.3183578550815582\n",
      "Epoch 55 step 20 loss: 0.34665000438690186\n",
      "Epoch 55 step 21 loss: 0.31712254881858826\n",
      "Epoch 55 step 22 loss: 0.3452679514884949\n",
      "Epoch 55 step 23 loss: 0.2927699089050293\n",
      "Epoch 55 step 24 loss: 0.3400358557701111\n",
      "Epoch 55 step 25 loss: 0.34757718443870544\n",
      "Epoch 55 step 26 loss: 0.3304359018802643\n",
      "Epoch 55 step 27 loss: 0.300150066614151\n",
      "Epoch 55 step 28 loss: 0.3272516429424286\n",
      "Epoch 55 step 29 loss: 0.49954554438591003\n",
      "Epoch 55 step 30 loss: 0.3876757323741913\n",
      "Epoch 55 step 31 loss: 0.3560509979724884\n",
      "Epoch 55 step 32 loss: 0.341493159532547\n",
      "Epoch 55 step 33 loss: 0.32065173983573914\n",
      "Epoch 55 step 34 loss: 0.34308212995529175\n",
      "Epoch 55 step 35 loss: 0.41383159160614014\n",
      "Epoch 55 step 36 loss: 0.30552881956100464\n",
      "Epoch 55 step 37 loss: 0.31829288601875305\n",
      "Epoch 55 step 38 loss: 0.35010719299316406\n",
      "Epoch 55 loss: 0.35010719299316406\n",
      "Epoch 56 step 0 loss: 0.28033366799354553\n",
      "Epoch 56 step 1 loss: 0.3265933096408844\n",
      "Epoch 56 step 2 loss: 0.35443314909935\n",
      "Epoch 56 step 3 loss: 0.3140140771865845\n",
      "Epoch 56 step 4 loss: 0.4494132697582245\n",
      "Epoch 56 step 5 loss: 0.2418673038482666\n",
      "Epoch 56 step 6 loss: 0.3726842999458313\n",
      "Epoch 56 step 7 loss: 0.40977030992507935\n",
      "Epoch 56 step 8 loss: 0.3879326283931732\n",
      "Epoch 56 step 9 loss: 0.4131324887275696\n",
      "Epoch 56 step 10 loss: 0.31578466296195984\n",
      "Epoch 56 step 11 loss: 0.34640568494796753\n",
      "Epoch 56 step 12 loss: 0.3234198987483978\n",
      "Epoch 56 step 13 loss: 0.42338821291923523\n",
      "Epoch 56 step 14 loss: 0.34967783093452454\n",
      "Epoch 56 step 15 loss: 0.2989993691444397\n",
      "Epoch 56 step 16 loss: 0.348438024520874\n",
      "Epoch 56 step 17 loss: 0.3257906436920166\n",
      "Epoch 56 step 18 loss: 0.36866140365600586\n",
      "Epoch 56 step 19 loss: 0.2992374300956726\n",
      "Epoch 56 step 20 loss: 0.3079169690608978\n",
      "Epoch 56 step 21 loss: 0.42467349767684937\n",
      "Epoch 56 step 22 loss: 0.3114688992500305\n",
      "Epoch 56 step 23 loss: 0.3126109838485718\n",
      "Epoch 56 step 24 loss: 0.36013340950012207\n",
      "Epoch 56 step 25 loss: 0.3337932825088501\n",
      "Epoch 56 step 26 loss: 0.33929482102394104\n",
      "Epoch 56 step 27 loss: 0.30845412611961365\n",
      "Epoch 56 step 28 loss: 0.2983487546443939\n",
      "Epoch 56 step 29 loss: 0.3374095559120178\n",
      "Epoch 56 step 30 loss: 0.3382043242454529\n",
      "Epoch 56 step 31 loss: 0.34922611713409424\n",
      "Epoch 56 step 32 loss: 0.36011892557144165\n",
      "Epoch 56 step 33 loss: 0.38120874762535095\n",
      "Epoch 56 step 34 loss: 0.31850185990333557\n",
      "Epoch 56 step 35 loss: 0.30729734897613525\n",
      "Epoch 56 step 36 loss: 0.30842018127441406\n",
      "Epoch 56 step 37 loss: 0.3568898141384125\n",
      "Epoch 56 step 38 loss: 0.5057175755500793\n",
      "Epoch 56 loss: 0.5057175755500793\n",
      "Epoch 57 step 0 loss: 0.30522915720939636\n",
      "Epoch 57 step 1 loss: 0.3066692650318146\n",
      "Epoch 57 step 2 loss: 0.32437509298324585\n",
      "Epoch 57 step 3 loss: 0.3358285129070282\n",
      "Epoch 57 step 4 loss: 0.3629598319530487\n",
      "Epoch 57 step 5 loss: 0.4561336636543274\n",
      "Epoch 57 step 6 loss: 0.4615832567214966\n",
      "Epoch 57 step 7 loss: 0.27333903312683105\n",
      "Epoch 57 step 8 loss: 0.28543221950531006\n",
      "Epoch 57 step 9 loss: 0.38729530572891235\n",
      "Epoch 57 step 10 loss: 0.2771502137184143\n",
      "Epoch 57 step 11 loss: 0.24847669899463654\n",
      "Epoch 57 step 12 loss: 0.3814253509044647\n",
      "Epoch 57 step 13 loss: 0.30441224575042725\n",
      "Epoch 57 step 14 loss: 0.31996050477027893\n",
      "Epoch 57 step 15 loss: 0.3607434928417206\n",
      "Epoch 57 step 16 loss: 0.3442651927471161\n",
      "Epoch 57 step 17 loss: 0.29203009605407715\n",
      "Epoch 57 step 18 loss: 0.3816620707511902\n",
      "Epoch 57 step 19 loss: 0.3252916634082794\n",
      "Epoch 57 step 20 loss: 0.2872626781463623\n",
      "Epoch 57 step 21 loss: 0.40238213539123535\n",
      "Epoch 57 step 22 loss: 0.33827778697013855\n",
      "Epoch 57 step 23 loss: 0.3465259373188019\n",
      "Epoch 57 step 24 loss: 0.27791857719421387\n",
      "Epoch 57 step 25 loss: 0.3400839567184448\n",
      "Epoch 57 step 26 loss: 0.33800750970840454\n",
      "Epoch 57 step 27 loss: 0.25023674964904785\n",
      "Epoch 57 step 28 loss: 0.27631083130836487\n",
      "Epoch 57 step 29 loss: 0.27102571725845337\n",
      "Epoch 57 step 30 loss: 0.4101320505142212\n",
      "Epoch 57 step 31 loss: 0.3055219054222107\n",
      "Epoch 57 step 32 loss: 0.3774014711380005\n",
      "Epoch 57 step 33 loss: 0.4605025053024292\n",
      "Epoch 57 step 34 loss: 0.35991328954696655\n",
      "Epoch 57 step 35 loss: 0.40619662404060364\n",
      "Epoch 57 step 36 loss: 0.3399220108985901\n",
      "Epoch 57 step 37 loss: 0.40185609459877014\n",
      "Epoch 57 step 38 loss: 0.33417433500289917\n",
      "Epoch 57 loss: 0.33417433500289917\n",
      "Epoch 58 step 0 loss: 0.4544217884540558\n",
      "Epoch 58 step 1 loss: 0.3591007590293884\n",
      "Epoch 58 step 2 loss: 0.362460732460022\n",
      "Epoch 58 step 3 loss: 0.2818593978881836\n",
      "Epoch 58 step 4 loss: 0.3160887062549591\n",
      "Epoch 58 step 5 loss: 0.42106103897094727\n",
      "Epoch 58 step 6 loss: 0.32420670986175537\n",
      "Epoch 58 step 7 loss: 0.38509678840637207\n",
      "Epoch 58 step 8 loss: 0.45371654629707336\n",
      "Epoch 58 step 9 loss: 0.39052239060401917\n",
      "Epoch 58 step 10 loss: 0.3716922402381897\n",
      "Epoch 58 step 11 loss: 0.3057297170162201\n",
      "Epoch 58 step 12 loss: 0.38485515117645264\n",
      "Epoch 58 step 13 loss: 0.382385790348053\n",
      "Epoch 58 step 14 loss: 0.3382558822631836\n",
      "Epoch 58 step 15 loss: 0.3804580271244049\n",
      "Epoch 58 step 16 loss: 0.3178229331970215\n",
      "Epoch 58 step 17 loss: 0.28200563788414\n",
      "Epoch 58 step 18 loss: 0.30907702445983887\n",
      "Epoch 58 step 19 loss: 0.3180689811706543\n",
      "Epoch 58 step 20 loss: 0.32340991497039795\n",
      "Epoch 58 step 21 loss: 0.30790597200393677\n",
      "Epoch 58 step 22 loss: 0.34056556224823\n",
      "Epoch 58 step 23 loss: 0.30777257680892944\n",
      "Epoch 58 step 24 loss: 0.3644261956214905\n",
      "Epoch 58 step 25 loss: 0.39443057775497437\n",
      "Epoch 58 step 26 loss: 0.36167266964912415\n",
      "Epoch 58 step 27 loss: 0.3382807970046997\n",
      "Epoch 58 step 28 loss: 0.3547801673412323\n",
      "Epoch 58 step 29 loss: 0.5124326944351196\n",
      "Epoch 58 step 30 loss: 0.3930976092815399\n",
      "Epoch 58 step 31 loss: 0.3438790440559387\n",
      "Epoch 58 step 32 loss: 0.3835621178150177\n",
      "Epoch 58 step 33 loss: 0.3179582357406616\n",
      "Epoch 58 step 34 loss: 0.23969894647598267\n",
      "Epoch 58 step 35 loss: 0.3583405911922455\n",
      "Epoch 58 step 36 loss: 0.3695150911808014\n",
      "Epoch 58 step 37 loss: 0.3841302692890167\n",
      "Epoch 58 step 38 loss: 0.2788535952568054\n",
      "Epoch 58 loss: 0.2788535952568054\n",
      "Epoch 59 step 0 loss: 0.34997546672821045\n",
      "Epoch 59 step 1 loss: 0.3368060290813446\n",
      "Epoch 59 step 2 loss: 0.4179364740848541\n",
      "Epoch 59 step 3 loss: 0.4103580713272095\n",
      "Epoch 59 step 4 loss: 0.29271677136421204\n",
      "Epoch 59 step 5 loss: 0.357305109500885\n",
      "Epoch 59 step 6 loss: 0.27169638872146606\n",
      "Epoch 59 step 7 loss: 0.37700775265693665\n",
      "Epoch 59 step 8 loss: 0.2667435109615326\n",
      "Epoch 59 step 9 loss: 0.3141951858997345\n",
      "Epoch 59 step 10 loss: 0.3454541862010956\n",
      "Epoch 59 step 11 loss: 0.3160766065120697\n",
      "Epoch 59 step 12 loss: 0.3502729535102844\n",
      "Epoch 59 step 13 loss: 0.33158910274505615\n",
      "Epoch 59 step 14 loss: 0.3137219250202179\n",
      "Epoch 59 step 15 loss: 0.32144859433174133\n",
      "Epoch 59 step 16 loss: 0.4324195981025696\n",
      "Epoch 59 step 17 loss: 0.36525121331214905\n",
      "Epoch 59 step 18 loss: 0.30965912342071533\n",
      "Epoch 59 step 19 loss: 0.3248533010482788\n",
      "Epoch 59 step 20 loss: 0.37183529138565063\n",
      "Epoch 59 step 21 loss: 0.34373947978019714\n",
      "Epoch 59 step 22 loss: 0.4428750276565552\n",
      "Epoch 59 step 23 loss: 0.34412938356399536\n",
      "Epoch 59 step 24 loss: 0.5005720257759094\n",
      "Epoch 59 step 25 loss: 0.37802720069885254\n",
      "Epoch 59 step 26 loss: 0.3945368528366089\n",
      "Epoch 59 step 27 loss: 0.4152183532714844\n",
      "Epoch 59 step 28 loss: 0.3857976198196411\n",
      "Epoch 59 step 29 loss: 0.449648916721344\n",
      "Epoch 59 step 30 loss: 0.39924442768096924\n",
      "Epoch 59 step 31 loss: 0.3632200062274933\n",
      "Epoch 59 step 32 loss: 0.41051429510116577\n",
      "Epoch 59 step 33 loss: 0.46955907344818115\n",
      "Epoch 59 step 34 loss: 0.3893722593784332\n",
      "Epoch 59 step 35 loss: 0.41695544123649597\n",
      "Epoch 59 step 36 loss: 0.45342859625816345\n",
      "Epoch 59 step 37 loss: 0.42187485098838806\n",
      "Epoch 59 step 38 loss: 0.4150567948818207\n",
      "Epoch 59 loss: 0.4150567948818207\n",
      "Epoch 60 step 0 loss: 0.5063948035240173\n",
      "Epoch 60 step 1 loss: 0.4258941113948822\n",
      "Epoch 60 step 2 loss: 0.4350185692310333\n",
      "Epoch 60 step 3 loss: 0.343292772769928\n",
      "Epoch 60 step 4 loss: 0.3866287171840668\n",
      "Epoch 60 step 5 loss: 0.42381036281585693\n",
      "Epoch 60 step 6 loss: 0.3152350187301636\n",
      "Epoch 60 step 7 loss: 0.3858480155467987\n",
      "Epoch 60 step 8 loss: 0.4660690426826477\n",
      "Epoch 60 step 9 loss: 0.41403812170028687\n",
      "Epoch 60 step 10 loss: 0.3698507845401764\n",
      "Epoch 60 step 11 loss: 0.3417872488498688\n",
      "Epoch 60 step 12 loss: 0.40244245529174805\n",
      "Epoch 60 step 13 loss: 0.39874738454818726\n",
      "Epoch 60 step 14 loss: 0.3757084012031555\n",
      "Epoch 60 step 15 loss: 0.44322049617767334\n",
      "Epoch 60 step 16 loss: 0.3267713487148285\n",
      "Epoch 60 step 17 loss: 0.3912772834300995\n",
      "Epoch 60 step 18 loss: 0.37096816301345825\n",
      "Epoch 60 step 19 loss: 0.39195185899734497\n",
      "Epoch 60 step 20 loss: 0.39789822697639465\n",
      "Epoch 60 step 21 loss: 0.5128618478775024\n",
      "Epoch 60 step 22 loss: 0.4075748324394226\n",
      "Epoch 60 step 23 loss: 0.32124605774879456\n",
      "Epoch 60 step 24 loss: 0.45604437589645386\n",
      "Epoch 60 step 25 loss: 0.3702530562877655\n",
      "Epoch 60 step 26 loss: 0.4880174398422241\n",
      "Epoch 60 step 27 loss: 0.3864542841911316\n",
      "Epoch 60 step 28 loss: 0.3270694613456726\n",
      "Epoch 60 step 29 loss: 0.385744571685791\n",
      "Epoch 60 step 30 loss: 0.33705347776412964\n",
      "Epoch 60 step 31 loss: 0.34734487533569336\n",
      "Epoch 60 step 32 loss: 0.367946982383728\n",
      "Epoch 60 step 33 loss: 0.3556309640407562\n",
      "Epoch 60 step 34 loss: 0.3433860242366791\n",
      "Epoch 60 step 35 loss: 0.329953134059906\n",
      "Epoch 60 step 36 loss: 0.45912355184555054\n",
      "Epoch 60 step 37 loss: 0.402606725692749\n",
      "Epoch 60 step 38 loss: 0.4530414938926697\n",
      "Epoch 60 loss: 0.4530414938926697\n",
      "Epoch 61 step 0 loss: 0.4017977714538574\n",
      "Epoch 61 step 1 loss: 0.4889983534812927\n",
      "Epoch 61 step 2 loss: 0.35836079716682434\n",
      "Epoch 61 step 3 loss: 0.34632694721221924\n",
      "Epoch 61 step 4 loss: 0.40064534544944763\n",
      "Epoch 61 step 5 loss: 0.45868176221847534\n",
      "Epoch 61 step 6 loss: 0.41315293312072754\n",
      "Epoch 61 step 7 loss: 0.3690956234931946\n",
      "Epoch 61 step 8 loss: 0.5432425141334534\n",
      "Epoch 61 step 9 loss: 0.27451133728027344\n",
      "Epoch 61 step 10 loss: 0.38944748044013977\n",
      "Epoch 61 step 11 loss: 0.3633837401866913\n",
      "Epoch 61 step 12 loss: 0.4374333918094635\n",
      "Epoch 61 step 13 loss: 0.32540392875671387\n",
      "Epoch 61 step 14 loss: 0.3261849880218506\n",
      "Epoch 61 step 15 loss: 0.34856724739074707\n",
      "Epoch 61 step 16 loss: 0.45754411816596985\n",
      "Epoch 61 step 17 loss: 0.3347770571708679\n",
      "Epoch 61 step 18 loss: 0.3667082190513611\n",
      "Epoch 61 step 19 loss: 0.27225247025489807\n",
      "Epoch 61 step 20 loss: 0.313839852809906\n",
      "Epoch 61 step 21 loss: 0.38114112615585327\n",
      "Epoch 61 step 22 loss: 0.37476009130477905\n",
      "Epoch 61 step 23 loss: 0.491188645362854\n",
      "Epoch 61 step 24 loss: 0.2707718312740326\n",
      "Epoch 61 step 25 loss: 0.3005801737308502\n",
      "Epoch 61 step 26 loss: 0.3056040406227112\n",
      "Epoch 61 step 27 loss: 0.31914445757865906\n",
      "Epoch 61 step 28 loss: 0.33812934160232544\n",
      "Epoch 61 step 29 loss: 0.32366690039634705\n",
      "Epoch 61 step 30 loss: 0.3786647617816925\n",
      "Epoch 61 step 31 loss: 0.29808509349823\n",
      "Epoch 61 step 32 loss: 0.40040817856788635\n",
      "Epoch 61 step 33 loss: 0.38561221957206726\n",
      "Epoch 61 step 34 loss: 0.3365929126739502\n",
      "Epoch 61 step 35 loss: 0.35902342200279236\n",
      "Epoch 61 step 36 loss: 0.3390614986419678\n",
      "Epoch 61 step 37 loss: 0.33276140689849854\n",
      "Epoch 61 step 38 loss: 0.4018416702747345\n",
      "Epoch 61 loss: 0.4018416702747345\n",
      "Epoch 62 step 0 loss: 0.4202994406223297\n",
      "Epoch 62 step 1 loss: 0.4739219546318054\n",
      "Epoch 62 step 2 loss: 0.3548978269100189\n",
      "Epoch 62 step 3 loss: 0.3159615993499756\n",
      "Epoch 62 step 4 loss: 0.39550748467445374\n",
      "Epoch 62 step 5 loss: 0.29572129249572754\n",
      "Epoch 62 step 6 loss: 0.4079875349998474\n",
      "Epoch 62 step 7 loss: 0.2718750834465027\n",
      "Epoch 62 step 8 loss: 0.5118375420570374\n",
      "Epoch 62 step 9 loss: 0.4342094361782074\n",
      "Epoch 62 step 10 loss: 0.4300973117351532\n",
      "Epoch 62 step 11 loss: 0.3610573709011078\n",
      "Epoch 62 step 12 loss: 0.5262429118156433\n",
      "Epoch 62 step 13 loss: 0.3934597074985504\n",
      "Epoch 62 step 14 loss: 0.49068424105644226\n",
      "Epoch 62 step 15 loss: 0.38519299030303955\n",
      "Epoch 62 step 16 loss: 0.4324987530708313\n",
      "Epoch 62 step 17 loss: 0.38566577434539795\n",
      "Epoch 62 step 18 loss: 0.4063858687877655\n",
      "Epoch 62 step 19 loss: 0.41290271282196045\n",
      "Epoch 62 step 20 loss: 0.34134361147880554\n",
      "Epoch 62 step 21 loss: 0.5154374241828918\n",
      "Epoch 62 step 22 loss: 0.3536285161972046\n",
      "Epoch 62 step 23 loss: 0.39916524291038513\n",
      "Epoch 62 step 24 loss: 0.4298667013645172\n",
      "Epoch 62 step 25 loss: 0.3406663239002228\n",
      "Epoch 62 step 26 loss: 0.30960020422935486\n",
      "Epoch 62 step 27 loss: 0.3639737665653229\n",
      "Epoch 62 step 28 loss: 0.2963050901889801\n",
      "Epoch 62 step 29 loss: 0.3668856620788574\n",
      "Epoch 62 step 30 loss: 0.3711535930633545\n",
      "Epoch 62 step 31 loss: 0.34201791882514954\n",
      "Epoch 62 step 32 loss: 0.3466997742652893\n",
      "Epoch 62 step 33 loss: 0.38803917169570923\n",
      "Epoch 62 step 34 loss: 0.41701599955558777\n",
      "Epoch 62 step 35 loss: 0.3950763940811157\n",
      "Epoch 62 step 36 loss: 0.38169169425964355\n",
      "Epoch 62 step 37 loss: 0.3672528862953186\n",
      "Epoch 62 step 38 loss: 0.288623571395874\n",
      "Epoch 62 loss: 0.288623571395874\n",
      "Epoch 63 step 0 loss: 0.40999194979667664\n",
      "Epoch 63 step 1 loss: 0.2804412245750427\n",
      "Epoch 63 step 2 loss: 0.42266273498535156\n",
      "Epoch 63 step 3 loss: 0.4621467590332031\n",
      "Epoch 63 step 4 loss: 0.3573254942893982\n",
      "Epoch 63 step 5 loss: 0.37784966826438904\n",
      "Epoch 63 step 6 loss: 0.37397584319114685\n",
      "Epoch 63 step 7 loss: 0.41587549448013306\n",
      "Epoch 63 step 8 loss: 0.43606236577033997\n",
      "Epoch 63 step 9 loss: 0.36582741141319275\n",
      "Epoch 63 step 10 loss: 0.2813299000263214\n",
      "Epoch 63 step 11 loss: 0.3560757637023926\n",
      "Epoch 63 step 12 loss: 0.32419317960739136\n",
      "Epoch 63 step 13 loss: 0.4176288843154907\n",
      "Epoch 63 step 14 loss: 0.36114469170570374\n",
      "Epoch 63 step 15 loss: 0.5234072804450989\n",
      "Epoch 63 step 16 loss: 0.32877230644226074\n",
      "Epoch 63 step 17 loss: 0.36076250672340393\n",
      "Epoch 63 step 18 loss: 0.42400142550468445\n",
      "Epoch 63 step 19 loss: 0.31474074721336365\n",
      "Epoch 63 step 20 loss: 0.3744535446166992\n",
      "Epoch 63 step 21 loss: 0.35301467776298523\n",
      "Epoch 63 step 22 loss: 0.3240766227245331\n",
      "Epoch 63 step 23 loss: 0.3677733242511749\n",
      "Epoch 63 step 24 loss: 0.3635859489440918\n",
      "Epoch 63 step 25 loss: 0.4349063038825989\n",
      "Epoch 63 step 26 loss: 0.29504626989364624\n",
      "Epoch 63 step 27 loss: 0.30884140729904175\n",
      "Epoch 63 step 28 loss: 0.47374391555786133\n",
      "Epoch 63 step 29 loss: 0.33646124601364136\n",
      "Epoch 63 step 30 loss: 0.3630114197731018\n",
      "Epoch 63 step 31 loss: 0.33114808797836304\n",
      "Epoch 63 step 32 loss: 0.36732274293899536\n",
      "Epoch 63 step 33 loss: 0.3714071810245514\n",
      "Epoch 63 step 34 loss: 0.42579975724220276\n",
      "Epoch 63 step 35 loss: 0.40398406982421875\n",
      "Epoch 63 step 36 loss: 0.371578186750412\n",
      "Epoch 63 step 37 loss: 0.33105504512786865\n",
      "Epoch 63 step 38 loss: 0.49503082036972046\n",
      "Epoch 63 loss: 0.49503082036972046\n",
      "Epoch 64 step 0 loss: 0.4786968231201172\n",
      "Epoch 64 step 1 loss: 0.6619839072227478\n",
      "Epoch 64 step 2 loss: 0.37977609038352966\n",
      "Epoch 64 step 3 loss: 0.4331004321575165\n",
      "Epoch 64 step 4 loss: 0.33202019333839417\n",
      "Epoch 64 step 5 loss: 0.45932114124298096\n",
      "Epoch 64 step 6 loss: 0.4351712167263031\n",
      "Epoch 64 step 7 loss: 0.3955775499343872\n",
      "Epoch 64 step 8 loss: 0.34679415822029114\n",
      "Epoch 64 step 9 loss: 0.41855859756469727\n",
      "Epoch 64 step 10 loss: 0.3226643204689026\n",
      "Epoch 64 step 11 loss: 0.29943326115608215\n",
      "Epoch 64 step 12 loss: 0.3311428427696228\n",
      "Epoch 64 step 13 loss: 0.3236948847770691\n",
      "Epoch 64 step 14 loss: 0.39993932843208313\n",
      "Epoch 64 step 15 loss: 0.32254037261009216\n",
      "Epoch 64 step 16 loss: 0.29455071687698364\n",
      "Epoch 64 step 17 loss: 0.45984968543052673\n",
      "Epoch 64 step 18 loss: 0.3944435119628906\n",
      "Epoch 64 step 19 loss: 0.275372177362442\n",
      "Epoch 64 step 20 loss: 0.3043988347053528\n",
      "Epoch 64 step 21 loss: 0.36142072081565857\n",
      "Epoch 64 step 22 loss: 0.31271642446517944\n",
      "Epoch 64 step 23 loss: 0.33711954951286316\n",
      "Epoch 64 step 24 loss: 0.34145912528038025\n",
      "Epoch 64 step 25 loss: 0.43624627590179443\n",
      "Epoch 64 step 26 loss: 0.45447561144828796\n",
      "Epoch 64 step 27 loss: 0.34862521290779114\n",
      "Epoch 64 step 28 loss: 0.343566358089447\n",
      "Epoch 64 step 29 loss: 0.37933188676834106\n",
      "Epoch 64 step 30 loss: 0.3505222499370575\n",
      "Epoch 64 step 31 loss: 0.32863011956214905\n",
      "Epoch 64 step 32 loss: 0.32171666622161865\n",
      "Epoch 64 step 33 loss: 0.2911202311515808\n",
      "Epoch 64 step 34 loss: 0.3256133496761322\n",
      "Epoch 64 step 35 loss: 0.3275258243083954\n",
      "Epoch 64 step 36 loss: 0.3286302387714386\n",
      "Epoch 64 step 37 loss: 0.35974621772766113\n",
      "Epoch 64 step 38 loss: 0.34211665391921997\n",
      "Epoch 64 loss: 0.34211665391921997\n",
      "Epoch 65 step 0 loss: 0.3928089141845703\n",
      "Epoch 65 step 1 loss: 0.36508864164352417\n",
      "Epoch 65 step 2 loss: 0.4109881520271301\n",
      "Epoch 65 step 3 loss: 0.2977374792098999\n",
      "Epoch 65 step 4 loss: 0.4680163860321045\n",
      "Epoch 65 step 5 loss: 0.2692883014678955\n",
      "Epoch 65 step 6 loss: 0.30981940031051636\n",
      "Epoch 65 step 7 loss: 0.3569730818271637\n",
      "Epoch 65 step 8 loss: 0.4104325473308563\n",
      "Epoch 65 step 9 loss: 0.3717724680900574\n",
      "Epoch 65 step 10 loss: 0.3961804509162903\n",
      "Epoch 65 step 11 loss: 0.3830864429473877\n",
      "Epoch 65 step 12 loss: 0.42706045508384705\n",
      "Epoch 65 step 13 loss: 0.34791213274002075\n",
      "Epoch 65 step 14 loss: 0.3265429139137268\n",
      "Epoch 65 step 15 loss: 0.3833414614200592\n",
      "Epoch 65 step 16 loss: 0.35026487708091736\n",
      "Epoch 65 step 17 loss: 0.3561793267726898\n",
      "Epoch 65 step 18 loss: 0.2954915463924408\n",
      "Epoch 65 step 19 loss: 0.28586187958717346\n",
      "Epoch 65 step 20 loss: 0.3960559368133545\n",
      "Epoch 65 step 21 loss: 0.43963199853897095\n",
      "Epoch 65 step 22 loss: 0.3019993007183075\n",
      "Epoch 65 step 23 loss: 0.41730377078056335\n",
      "Epoch 65 step 24 loss: 0.3290315568447113\n",
      "Epoch 65 step 25 loss: 0.34726765751838684\n",
      "Epoch 65 step 26 loss: 0.332651823759079\n",
      "Epoch 65 step 27 loss: 0.3841530382633209\n",
      "Epoch 65 step 28 loss: 0.3611450493335724\n",
      "Epoch 65 step 29 loss: 0.35633233189582825\n",
      "Epoch 65 step 30 loss: 0.5605166554450989\n",
      "Epoch 65 step 31 loss: 0.3617576062679291\n",
      "Epoch 65 step 32 loss: 0.4131523072719574\n",
      "Epoch 65 step 33 loss: 0.42317306995391846\n",
      "Epoch 65 step 34 loss: 0.3176826536655426\n",
      "Epoch 65 step 35 loss: 0.42716842889785767\n",
      "Epoch 65 step 36 loss: 0.38983067870140076\n",
      "Epoch 65 step 37 loss: 0.38123568892478943\n",
      "Epoch 65 step 38 loss: 0.33442890644073486\n",
      "Epoch 65 loss: 0.33442890644073486\n",
      "Epoch 66 step 0 loss: 0.34874916076660156\n",
      "Epoch 66 step 1 loss: 0.3270456790924072\n",
      "Epoch 66 step 2 loss: 0.47712963819503784\n",
      "Epoch 66 step 3 loss: 0.40815499424934387\n",
      "Epoch 66 step 4 loss: 0.3535747528076172\n",
      "Epoch 66 step 5 loss: 0.3005167841911316\n",
      "Epoch 66 step 6 loss: 0.3077083230018616\n",
      "Epoch 66 step 7 loss: 0.2960345149040222\n",
      "Epoch 66 step 8 loss: 0.42337530851364136\n",
      "Epoch 66 step 9 loss: 0.3131917119026184\n",
      "Epoch 66 step 10 loss: 0.39151352643966675\n",
      "Epoch 66 step 11 loss: 0.4065670967102051\n",
      "Epoch 66 step 12 loss: 0.3977336287498474\n",
      "Epoch 66 step 13 loss: 0.3889316916465759\n",
      "Epoch 66 step 14 loss: 0.4390396177768707\n",
      "Epoch 66 step 15 loss: 0.45383089780807495\n",
      "Epoch 66 step 16 loss: 0.3243972659111023\n",
      "Epoch 66 step 17 loss: 0.3239189386367798\n",
      "Epoch 66 step 18 loss: 0.3316775858402252\n",
      "Epoch 66 step 19 loss: 0.3317180573940277\n",
      "Epoch 66 step 20 loss: 0.42079979181289673\n",
      "Epoch 66 step 21 loss: 0.3524596691131592\n",
      "Epoch 66 step 22 loss: 0.38369232416152954\n",
      "Epoch 66 step 23 loss: 0.38141730427742004\n",
      "Epoch 66 step 24 loss: 0.29138511419296265\n",
      "Epoch 66 step 25 loss: 0.2903922200202942\n",
      "Epoch 66 step 26 loss: 0.4675620198249817\n",
      "Epoch 66 step 27 loss: 0.43356287479400635\n",
      "Epoch 66 step 28 loss: 0.43504977226257324\n",
      "Epoch 66 step 29 loss: 0.3292366564273834\n",
      "Epoch 66 step 30 loss: 0.40215104818344116\n",
      "Epoch 66 step 31 loss: 0.30017364025115967\n",
      "Epoch 66 step 32 loss: 0.38502150774002075\n",
      "Epoch 66 step 33 loss: 0.3234961926937103\n",
      "Epoch 66 step 34 loss: 0.39583343267440796\n",
      "Epoch 66 step 35 loss: 0.361237496137619\n",
      "Epoch 66 step 36 loss: 0.35196417570114136\n",
      "Epoch 66 step 37 loss: 0.4352110028266907\n",
      "Epoch 66 step 38 loss: 0.28549399971961975\n",
      "Epoch 66 loss: 0.28549399971961975\n",
      "Epoch 67 step 0 loss: 0.34326398372650146\n",
      "Epoch 67 step 1 loss: 0.43458619713783264\n",
      "Epoch 67 step 2 loss: 0.44138914346694946\n",
      "Epoch 67 step 3 loss: 0.40960657596588135\n",
      "Epoch 67 step 4 loss: 0.29419636726379395\n",
      "Epoch 67 step 5 loss: 0.4299297034740448\n",
      "Epoch 67 step 6 loss: 0.28231021761894226\n",
      "Epoch 67 step 7 loss: 0.3726154565811157\n",
      "Epoch 67 step 8 loss: 0.3052194118499756\n",
      "Epoch 67 step 9 loss: 0.33455005288124084\n",
      "Epoch 67 step 10 loss: 0.29537099599838257\n",
      "Epoch 67 step 11 loss: 0.4482981562614441\n",
      "Epoch 67 step 12 loss: 0.2458522617816925\n",
      "Epoch 67 step 13 loss: 0.4025529623031616\n",
      "Epoch 67 step 14 loss: 0.31815826892852783\n",
      "Epoch 67 step 15 loss: 0.37639355659484863\n",
      "Epoch 67 step 16 loss: 0.3224312365055084\n",
      "Epoch 67 step 17 loss: 0.24765315651893616\n",
      "Epoch 67 step 18 loss: 0.31913870573043823\n",
      "Epoch 67 step 19 loss: 0.32211875915527344\n",
      "Epoch 67 step 20 loss: 0.41132327914237976\n",
      "Epoch 67 step 21 loss: 0.3181489408016205\n",
      "Epoch 67 step 22 loss: 0.4057047963142395\n",
      "Epoch 67 step 23 loss: 0.3875194787979126\n",
      "Epoch 67 step 24 loss: 0.4070042073726654\n",
      "Epoch 67 step 25 loss: 0.34987908601760864\n",
      "Epoch 67 step 26 loss: 0.3045090138912201\n",
      "Epoch 67 step 27 loss: 0.385334849357605\n",
      "Epoch 67 step 28 loss: 0.3681055009365082\n",
      "Epoch 67 step 29 loss: 0.3106513023376465\n",
      "Epoch 67 step 30 loss: 0.3108336925506592\n",
      "Epoch 67 step 31 loss: 0.3936501443386078\n",
      "Epoch 67 step 32 loss: 0.34920960664749146\n",
      "Epoch 67 step 33 loss: 0.44963976740837097\n",
      "Epoch 67 step 34 loss: 0.3165505826473236\n",
      "Epoch 67 step 35 loss: 0.3789459466934204\n",
      "Epoch 67 step 36 loss: 0.30396324396133423\n",
      "Epoch 67 step 37 loss: 0.41124027967453003\n",
      "Epoch 67 step 38 loss: 0.4044552147388458\n",
      "Epoch 67 loss: 0.4044552147388458\n",
      "Epoch 68 step 0 loss: 0.4513609707355499\n",
      "Epoch 68 step 1 loss: 0.4240260124206543\n",
      "Epoch 68 step 2 loss: 0.550099790096283\n",
      "Epoch 68 step 3 loss: 0.36509546637535095\n",
      "Epoch 68 step 4 loss: 0.4770585298538208\n",
      "Epoch 68 step 5 loss: 0.39191651344299316\n",
      "Epoch 68 step 6 loss: 0.49076226353645325\n",
      "Epoch 68 step 7 loss: 0.36839160323143005\n",
      "Epoch 68 step 8 loss: 0.4728407561779022\n",
      "Epoch 68 step 9 loss: 0.3203921914100647\n",
      "Epoch 68 step 10 loss: 0.43048611283302307\n",
      "Epoch 68 step 11 loss: 0.2936822175979614\n",
      "Epoch 68 step 12 loss: 0.4164666533470154\n",
      "Epoch 68 step 13 loss: 0.333949476480484\n",
      "Epoch 68 step 14 loss: 0.3864956200122833\n",
      "Epoch 68 step 15 loss: 0.27595049142837524\n",
      "Epoch 68 step 16 loss: 0.6159340143203735\n",
      "Epoch 68 step 17 loss: 0.3785337805747986\n",
      "Epoch 68 step 18 loss: 0.44056883454322815\n",
      "Epoch 68 step 19 loss: 0.42598482966423035\n",
      "Epoch 68 step 20 loss: 0.34700900316238403\n",
      "Epoch 68 step 21 loss: 0.3806859850883484\n",
      "Epoch 68 step 22 loss: 0.4234969913959503\n",
      "Epoch 68 step 23 loss: 0.3170187771320343\n",
      "Epoch 68 step 24 loss: 0.4050256013870239\n",
      "Epoch 68 step 25 loss: 0.3449356257915497\n",
      "Epoch 68 step 26 loss: 0.3452199697494507\n",
      "Epoch 68 step 27 loss: 0.37526094913482666\n",
      "Epoch 68 step 28 loss: 0.3586801290512085\n",
      "Epoch 68 step 29 loss: 0.30677929520606995\n",
      "Epoch 68 step 30 loss: 0.2878663241863251\n",
      "Epoch 68 step 31 loss: 0.3518536686897278\n",
      "Epoch 68 step 32 loss: 0.35552364587783813\n",
      "Epoch 68 step 33 loss: 0.3257255256175995\n",
      "Epoch 68 step 34 loss: 0.3010276257991791\n",
      "Epoch 68 step 35 loss: 0.3499678075313568\n",
      "Epoch 68 step 36 loss: 0.32587820291519165\n",
      "Epoch 68 step 37 loss: 0.32581081986427307\n",
      "Epoch 68 step 38 loss: 0.4119614064693451\n",
      "Epoch 68 loss: 0.4119614064693451\n",
      "Epoch 69 step 0 loss: 0.4019469618797302\n",
      "Epoch 69 step 1 loss: 0.45236310362815857\n",
      "Epoch 69 step 2 loss: 0.3649647533893585\n",
      "Epoch 69 step 3 loss: 0.3452555239200592\n",
      "Epoch 69 step 4 loss: 0.39343562722206116\n",
      "Epoch 69 step 5 loss: 0.3194802701473236\n",
      "Epoch 69 step 6 loss: 0.27515846490859985\n",
      "Epoch 69 step 7 loss: 0.5022090673446655\n",
      "Epoch 69 step 8 loss: 0.27562981843948364\n",
      "Epoch 69 step 9 loss: 0.43969014286994934\n",
      "Epoch 69 step 10 loss: 0.39844202995300293\n",
      "Epoch 69 step 11 loss: 0.4062970280647278\n",
      "Epoch 69 step 12 loss: 0.40020376443862915\n",
      "Epoch 69 step 13 loss: 0.37892213463783264\n",
      "Epoch 69 step 14 loss: 0.39594364166259766\n",
      "Epoch 69 step 15 loss: 0.30921193957328796\n",
      "Epoch 69 step 16 loss: 0.3380950093269348\n",
      "Epoch 69 step 17 loss: 0.3631788194179535\n",
      "Epoch 69 step 18 loss: 0.355654239654541\n",
      "Epoch 69 step 19 loss: 0.28934741020202637\n",
      "Epoch 69 step 20 loss: 0.3590325117111206\n",
      "Epoch 69 step 21 loss: 0.4216768741607666\n",
      "Epoch 69 step 22 loss: 0.34366822242736816\n",
      "Epoch 69 step 23 loss: 0.3700794279575348\n",
      "Epoch 69 step 24 loss: 0.4206011891365051\n",
      "Epoch 69 step 25 loss: 0.4163847267627716\n",
      "Epoch 69 step 26 loss: 0.45535627007484436\n",
      "Epoch 69 step 27 loss: 0.48128196597099304\n",
      "Epoch 69 step 28 loss: 0.37849491834640503\n",
      "Epoch 69 step 29 loss: 0.34671342372894287\n",
      "Epoch 69 step 30 loss: 0.37568336725234985\n",
      "Epoch 69 step 31 loss: 0.38087865710258484\n",
      "Epoch 69 step 32 loss: 0.3777649998664856\n",
      "Epoch 69 step 33 loss: 0.40126073360443115\n",
      "Epoch 69 step 34 loss: 0.30470535159111023\n",
      "Epoch 69 step 35 loss: 0.38583239912986755\n",
      "Epoch 69 step 36 loss: 0.49801498651504517\n",
      "Epoch 69 step 37 loss: 0.3721286356449127\n",
      "Epoch 69 step 38 loss: 0.3141917288303375\n",
      "Epoch 69 loss: 0.3141917288303375\n",
      "Epoch 70 step 0 loss: 0.43441349267959595\n",
      "Epoch 70 step 1 loss: 0.4274059534072876\n",
      "Epoch 70 step 2 loss: 0.3781319260597229\n",
      "Epoch 70 step 3 loss: 0.386008083820343\n",
      "Epoch 70 step 4 loss: 0.449344664812088\n",
      "Epoch 70 step 5 loss: 0.4785357415676117\n",
      "Epoch 70 step 6 loss: 0.40707796812057495\n",
      "Epoch 70 step 7 loss: 0.4280226230621338\n",
      "Epoch 70 step 8 loss: 0.3494766354560852\n",
      "Epoch 70 step 9 loss: 0.32108980417251587\n",
      "Epoch 70 step 10 loss: 0.31758609414100647\n",
      "Epoch 70 step 11 loss: 0.30798599123954773\n",
      "Epoch 70 step 12 loss: 0.317682147026062\n",
      "Epoch 70 step 13 loss: 0.5276540517807007\n",
      "Epoch 70 step 14 loss: 0.3884356617927551\n",
      "Epoch 70 step 15 loss: 0.31686460971832275\n",
      "Epoch 70 step 16 loss: 0.3682207763195038\n",
      "Epoch 70 step 17 loss: 0.3543129563331604\n",
      "Epoch 70 step 18 loss: 0.33375710248947144\n",
      "Epoch 70 step 19 loss: 0.34645068645477295\n",
      "Epoch 70 step 20 loss: 0.34974464774131775\n",
      "Epoch 70 step 21 loss: 0.4148474633693695\n",
      "Epoch 70 step 22 loss: 0.3050978481769562\n",
      "Epoch 70 step 23 loss: 0.22655938565731049\n",
      "Epoch 70 step 24 loss: 0.3848460018634796\n",
      "Epoch 70 step 25 loss: 0.4544523358345032\n",
      "Epoch 70 step 26 loss: 0.4741012156009674\n",
      "Epoch 70 step 27 loss: 0.38491708040237427\n",
      "Epoch 70 step 28 loss: 0.37688666582107544\n",
      "Epoch 70 step 29 loss: 0.44968923926353455\n",
      "Epoch 70 step 30 loss: 0.3755011558532715\n",
      "Epoch 70 step 31 loss: 0.44277510046958923\n",
      "Epoch 70 step 32 loss: 0.3570463955402374\n",
      "Epoch 70 step 33 loss: 0.24463188648223877\n",
      "Epoch 70 step 34 loss: 0.3688599467277527\n",
      "Epoch 70 step 35 loss: 0.3901991546154022\n",
      "Epoch 70 step 36 loss: 0.47704413533210754\n",
      "Epoch 70 step 37 loss: 0.40775740146636963\n",
      "Epoch 70 step 38 loss: 0.38503751158714294\n",
      "Epoch 70 loss: 0.38503751158714294\n",
      "Epoch 71 step 0 loss: 0.41591307520866394\n",
      "Epoch 71 step 1 loss: 0.4194805324077606\n",
      "Epoch 71 step 2 loss: 0.39346808195114136\n",
      "Epoch 71 step 3 loss: 0.40746018290519714\n",
      "Epoch 71 step 4 loss: 0.2600543797016144\n",
      "Epoch 71 step 5 loss: 0.38187485933303833\n",
      "Epoch 71 step 6 loss: 0.3172379732131958\n",
      "Epoch 71 step 7 loss: 0.4097388982772827\n",
      "Epoch 71 step 8 loss: 0.5022463202476501\n",
      "Epoch 71 step 9 loss: 0.326244056224823\n",
      "Epoch 71 step 10 loss: 0.4078773260116577\n",
      "Epoch 71 step 11 loss: 0.41915300488471985\n",
      "Epoch 71 step 12 loss: 0.29955998063087463\n",
      "Epoch 71 step 13 loss: 0.36204957962036133\n",
      "Epoch 71 step 14 loss: 0.39855074882507324\n",
      "Epoch 71 step 15 loss: 0.4065168499946594\n",
      "Epoch 71 step 16 loss: 0.4500958025455475\n",
      "Epoch 71 step 17 loss: 0.41239994764328003\n",
      "Epoch 71 step 18 loss: 0.39246922731399536\n",
      "Epoch 71 step 19 loss: 0.3039463758468628\n",
      "Epoch 71 step 20 loss: 0.3798466920852661\n",
      "Epoch 71 step 21 loss: 0.33903247117996216\n",
      "Epoch 71 step 22 loss: 0.2958979606628418\n",
      "Epoch 71 step 23 loss: 0.3107704818248749\n",
      "Epoch 71 step 24 loss: 0.2643648087978363\n",
      "Epoch 71 step 25 loss: 0.45111069083213806\n",
      "Epoch 71 step 26 loss: 0.4498783051967621\n",
      "Epoch 71 step 27 loss: 0.4217403829097748\n",
      "Epoch 71 step 28 loss: 0.3009878993034363\n",
      "Epoch 71 step 29 loss: 0.43414056301116943\n",
      "Epoch 71 step 30 loss: 0.39072367548942566\n",
      "Epoch 71 step 31 loss: 0.37197184562683105\n",
      "Epoch 71 step 32 loss: 0.4450371563434601\n",
      "Epoch 71 step 33 loss: 0.44457530975341797\n",
      "Epoch 71 step 34 loss: 0.29672881960868835\n",
      "Epoch 71 step 35 loss: 0.36704590916633606\n",
      "Epoch 71 step 36 loss: 0.34526607394218445\n",
      "Epoch 71 step 37 loss: 0.4699929356575012\n",
      "Epoch 71 step 38 loss: 0.4167531132698059\n",
      "Epoch 71 loss: 0.4167531132698059\n",
      "Epoch 72 step 0 loss: 0.5571131706237793\n",
      "Epoch 72 step 1 loss: 0.5604298710823059\n",
      "Epoch 72 step 2 loss: 0.5011011362075806\n",
      "Epoch 72 step 3 loss: 0.4939022362232208\n",
      "Epoch 72 step 4 loss: 0.439618319272995\n",
      "Epoch 72 step 5 loss: 0.468837171792984\n",
      "Epoch 72 step 6 loss: 0.42553094029426575\n",
      "Epoch 72 step 7 loss: 0.48393145203590393\n",
      "Epoch 72 step 8 loss: 0.46500563621520996\n",
      "Epoch 72 step 9 loss: 0.37210968136787415\n",
      "Epoch 72 step 10 loss: 0.5040660500526428\n",
      "Epoch 72 step 11 loss: 0.3455393612384796\n",
      "Epoch 72 step 12 loss: 0.5590679049491882\n",
      "Epoch 72 step 13 loss: 0.2986827492713928\n",
      "Epoch 72 step 14 loss: 0.47799623012542725\n",
      "Epoch 72 step 15 loss: 0.43056538701057434\n",
      "Epoch 72 step 16 loss: 0.3404177725315094\n",
      "Epoch 72 step 17 loss: 0.42984315752983093\n",
      "Epoch 72 step 18 loss: 0.3601516783237457\n",
      "Epoch 72 step 19 loss: 0.40928614139556885\n",
      "Epoch 72 step 20 loss: 0.4828110635280609\n",
      "Epoch 72 step 21 loss: 0.5808285474777222\n",
      "Epoch 72 step 22 loss: 0.476833313703537\n",
      "Epoch 72 step 23 loss: 0.4059065878391266\n",
      "Epoch 72 step 24 loss: 0.49784523248672485\n",
      "Epoch 72 step 25 loss: 0.4426612854003906\n",
      "Epoch 72 step 26 loss: 0.49411246180534363\n",
      "Epoch 72 step 27 loss: 0.40659815073013306\n",
      "Epoch 72 step 28 loss: 0.5225418210029602\n",
      "Epoch 72 step 29 loss: 0.31821703910827637\n",
      "Epoch 72 step 30 loss: 0.3334311544895172\n",
      "Epoch 72 step 31 loss: 0.40038585662841797\n",
      "Epoch 72 step 32 loss: 0.3608551025390625\n",
      "Epoch 72 step 33 loss: 0.4881093502044678\n",
      "Epoch 72 step 34 loss: 0.30533087253570557\n",
      "Epoch 72 step 35 loss: 0.31142374873161316\n",
      "Epoch 72 step 36 loss: 0.3357259929180145\n",
      "Epoch 72 step 37 loss: 0.381357342004776\n",
      "Epoch 72 step 38 loss: 0.27216947078704834\n",
      "Epoch 72 loss: 0.27216947078704834\n",
      "Epoch 73 step 0 loss: 0.42961403727531433\n",
      "Epoch 73 step 1 loss: 0.40301188826560974\n",
      "Epoch 73 step 2 loss: 0.4878734052181244\n",
      "Epoch 73 step 3 loss: 0.2833748161792755\n",
      "Epoch 73 step 4 loss: 0.409840852022171\n",
      "Epoch 73 step 5 loss: 0.3452231287956238\n",
      "Epoch 73 step 6 loss: 0.4529067277908325\n",
      "Epoch 73 step 7 loss: 0.43281903862953186\n",
      "Epoch 73 step 8 loss: 0.4596829414367676\n",
      "Epoch 73 step 9 loss: 0.326946884393692\n",
      "Epoch 73 step 10 loss: 0.34465688467025757\n",
      "Epoch 73 step 11 loss: 0.3638576567173004\n",
      "Epoch 73 step 12 loss: 0.35442328453063965\n",
      "Epoch 73 step 13 loss: 0.36037155985832214\n",
      "Epoch 73 step 14 loss: 0.41592949628829956\n",
      "Epoch 73 step 15 loss: 0.45427677035331726\n",
      "Epoch 73 step 16 loss: 0.36132195591926575\n",
      "Epoch 73 step 17 loss: 0.3503521680831909\n",
      "Epoch 73 step 18 loss: 0.32839763164520264\n",
      "Epoch 73 step 19 loss: 0.3711826503276825\n",
      "Epoch 73 step 20 loss: 0.4291400611400604\n",
      "Epoch 73 step 21 loss: 0.4096754789352417\n",
      "Epoch 73 step 22 loss: 0.3595099449157715\n",
      "Epoch 73 step 23 loss: 0.3449368476867676\n",
      "Epoch 73 step 24 loss: 0.3259439468383789\n",
      "Epoch 73 step 25 loss: 0.3506394028663635\n",
      "Epoch 73 step 26 loss: 0.3590346872806549\n",
      "Epoch 73 step 27 loss: 0.5597658157348633\n",
      "Epoch 73 step 28 loss: 0.3550204038619995\n",
      "Epoch 73 step 29 loss: 0.32858625054359436\n",
      "Epoch 73 step 30 loss: 0.41064727306365967\n",
      "Epoch 73 step 31 loss: 0.2928880751132965\n",
      "Epoch 73 step 32 loss: 0.37289541959762573\n",
      "Epoch 73 step 33 loss: 0.467955619096756\n",
      "Epoch 73 step 34 loss: 0.4065486788749695\n",
      "Epoch 73 step 35 loss: 0.35069048404693604\n",
      "Epoch 73 step 36 loss: 0.5041579008102417\n",
      "Epoch 73 step 37 loss: 0.38511741161346436\n",
      "Epoch 73 step 38 loss: 0.36151936650276184\n",
      "Epoch 73 loss: 0.36151936650276184\n",
      "Epoch 74 step 0 loss: 0.5467478036880493\n",
      "Epoch 74 step 1 loss: 0.4435512125492096\n",
      "Epoch 74 step 2 loss: 0.46282345056533813\n",
      "Epoch 74 step 3 loss: 0.3990868031978607\n",
      "Epoch 74 step 4 loss: 0.48578229546546936\n",
      "Epoch 74 step 5 loss: 0.38357076048851013\n",
      "Epoch 74 step 6 loss: 0.3868791460990906\n",
      "Epoch 74 step 7 loss: 0.4892057180404663\n",
      "Epoch 74 step 8 loss: 0.41438397765159607\n",
      "Epoch 74 step 9 loss: 0.5159972310066223\n",
      "Epoch 74 step 10 loss: 0.3725977838039398\n",
      "Epoch 74 step 11 loss: 0.3590910732746124\n",
      "Epoch 74 step 12 loss: 0.45528537034988403\n",
      "Epoch 74 step 13 loss: 0.3497747778892517\n",
      "Epoch 74 step 14 loss: 0.3817669451236725\n",
      "Epoch 74 step 15 loss: 0.41314250230789185\n",
      "Epoch 74 step 16 loss: 0.36550137400627136\n",
      "Epoch 74 step 17 loss: 0.4934872090816498\n",
      "Epoch 74 step 18 loss: 0.42196574807167053\n",
      "Epoch 74 step 19 loss: 0.2938336431980133\n",
      "Epoch 74 step 20 loss: 0.4294677674770355\n",
      "Epoch 74 step 21 loss: 0.4578188359737396\n",
      "Epoch 74 step 22 loss: 0.3548525273799896\n",
      "Epoch 74 step 23 loss: 0.3037315011024475\n",
      "Epoch 74 step 24 loss: 0.4774853587150574\n",
      "Epoch 74 step 25 loss: 0.46662628650665283\n",
      "Epoch 74 step 26 loss: 0.3811224102973938\n",
      "Epoch 74 step 27 loss: 0.3702682554721832\n",
      "Epoch 74 step 28 loss: 0.4249166250228882\n",
      "Epoch 74 step 29 loss: 0.413829505443573\n",
      "Epoch 74 step 30 loss: 0.4420981705188751\n",
      "Epoch 74 step 31 loss: 0.5095483064651489\n",
      "Epoch 74 step 32 loss: 0.41291841864585876\n",
      "Epoch 74 step 33 loss: 0.5343605279922485\n",
      "Epoch 74 step 34 loss: 0.34011098742485046\n",
      "Epoch 74 step 35 loss: 0.37898966670036316\n",
      "Epoch 74 step 36 loss: 0.3328268229961395\n",
      "Epoch 74 step 37 loss: 0.37912067770957947\n",
      "Epoch 74 step 38 loss: 0.34434232115745544\n",
      "Epoch 74 loss: 0.34434232115745544\n",
      "Epoch 75 step 0 loss: 0.4371914863586426\n",
      "Epoch 75 step 1 loss: 0.45665043592453003\n",
      "Epoch 75 step 2 loss: 0.4777708649635315\n",
      "Epoch 75 step 3 loss: 0.4048822820186615\n",
      "Epoch 75 step 4 loss: 0.3194538354873657\n",
      "Epoch 75 step 5 loss: 0.42304882407188416\n",
      "Epoch 75 step 6 loss: 0.3060201406478882\n",
      "Epoch 75 step 7 loss: 0.3676215410232544\n",
      "Epoch 75 step 8 loss: 0.25551891326904297\n",
      "Epoch 75 step 9 loss: 0.4364364445209503\n",
      "Epoch 75 step 10 loss: 0.34624600410461426\n",
      "Epoch 75 step 11 loss: 0.4477037787437439\n",
      "Epoch 75 step 12 loss: 0.295454204082489\n",
      "Epoch 75 step 13 loss: 0.4081955552101135\n",
      "Epoch 75 step 14 loss: 0.3711288869380951\n",
      "Epoch 75 step 15 loss: 0.34288474917411804\n",
      "Epoch 75 step 16 loss: 0.5091407895088196\n",
      "Epoch 75 step 17 loss: 0.35705262422561646\n",
      "Epoch 75 step 18 loss: 0.3227333128452301\n",
      "Epoch 75 step 19 loss: 0.33438873291015625\n",
      "Epoch 75 step 20 loss: 0.4416389465332031\n",
      "Epoch 75 step 21 loss: 0.4169832170009613\n",
      "Epoch 75 step 22 loss: 0.33438557386398315\n",
      "Epoch 75 step 23 loss: 0.428561806678772\n",
      "Epoch 75 step 24 loss: 0.4527311325073242\n",
      "Epoch 75 step 25 loss: 0.36662057042121887\n",
      "Epoch 75 step 26 loss: 0.40118342638015747\n",
      "Epoch 75 step 27 loss: 0.34539875388145447\n",
      "Epoch 75 step 28 loss: 0.38456156849861145\n",
      "Epoch 75 step 29 loss: 0.5314603447914124\n",
      "Epoch 75 step 30 loss: 0.39377641677856445\n",
      "Epoch 75 step 31 loss: 0.34321099519729614\n",
      "Epoch 75 step 32 loss: 0.38655537366867065\n",
      "Epoch 75 step 33 loss: 0.42116105556488037\n",
      "Epoch 75 step 34 loss: 0.35422709584236145\n",
      "Epoch 75 step 35 loss: 0.3148495554924011\n",
      "Epoch 75 step 36 loss: 0.39305567741394043\n",
      "Epoch 75 step 37 loss: 0.45026150345802307\n",
      "Epoch 75 step 38 loss: 0.4531385004520416\n",
      "Epoch 75 loss: 0.4531385004520416\n",
      "Epoch 76 step 0 loss: 0.32605603337287903\n",
      "Epoch 76 step 1 loss: 0.3921468257904053\n",
      "Epoch 76 step 2 loss: 0.3513335883617401\n",
      "Epoch 76 step 3 loss: 0.34470927715301514\n",
      "Epoch 76 step 4 loss: 0.35164061188697815\n",
      "Epoch 76 step 5 loss: 0.4829712510108948\n",
      "Epoch 76 step 6 loss: 0.4394601583480835\n",
      "Epoch 76 step 7 loss: 0.3905099630355835\n",
      "Epoch 76 step 8 loss: 0.45691004395484924\n",
      "Epoch 76 step 9 loss: 0.3830586075782776\n",
      "Epoch 76 step 10 loss: 0.5417302250862122\n",
      "Epoch 76 step 11 loss: 0.3961898386478424\n",
      "Epoch 76 step 12 loss: 0.4932674467563629\n",
      "Epoch 76 step 13 loss: 0.4772047996520996\n",
      "Epoch 76 step 14 loss: 0.48545464873313904\n",
      "Epoch 76 step 15 loss: 0.5299185514450073\n",
      "Epoch 76 step 16 loss: 0.341728538274765\n",
      "Epoch 76 step 17 loss: 0.3840048313140869\n",
      "Epoch 76 step 18 loss: 0.40287405252456665\n",
      "Epoch 76 step 19 loss: 0.5573813319206238\n",
      "Epoch 76 step 20 loss: 0.4269026815891266\n",
      "Epoch 76 step 21 loss: 0.3445737063884735\n",
      "Epoch 76 step 22 loss: 0.375166654586792\n",
      "Epoch 76 step 23 loss: 0.42273226380348206\n",
      "Epoch 76 step 24 loss: 0.30538511276245117\n",
      "Epoch 76 step 25 loss: 0.7317007780075073\n",
      "Epoch 76 step 26 loss: 0.39183634519577026\n",
      "Epoch 76 step 27 loss: 0.3568187952041626\n",
      "Epoch 76 step 28 loss: 0.43387994170188904\n",
      "Epoch 76 step 29 loss: 0.33171623945236206\n",
      "Epoch 76 step 30 loss: 0.40694674849510193\n",
      "Epoch 76 step 31 loss: 0.3161061108112335\n",
      "Epoch 76 step 32 loss: 0.40843936800956726\n",
      "Epoch 76 step 33 loss: 0.3180745542049408\n",
      "Epoch 76 step 34 loss: 0.4404812753200531\n",
      "Epoch 76 step 35 loss: 0.3698303997516632\n",
      "Epoch 76 step 36 loss: 0.33396080136299133\n",
      "Epoch 76 step 37 loss: 0.4687890112400055\n",
      "Epoch 76 step 38 loss: 0.3137556314468384\n",
      "Epoch 76 loss: 0.3137556314468384\n",
      "Epoch 77 step 0 loss: 0.3420466482639313\n",
      "Epoch 77 step 1 loss: 0.3421036899089813\n",
      "Epoch 77 step 2 loss: 0.3630933463573456\n",
      "Epoch 77 step 3 loss: 0.2993231415748596\n",
      "Epoch 77 step 4 loss: 0.38647472858428955\n",
      "Epoch 77 step 5 loss: 0.41531217098236084\n",
      "Epoch 77 step 6 loss: 0.40706104040145874\n",
      "Epoch 77 step 7 loss: 0.42166540026664734\n",
      "Epoch 77 step 8 loss: 0.5671223998069763\n",
      "Epoch 77 step 9 loss: 0.3809623122215271\n",
      "Epoch 77 step 10 loss: 0.3316699266433716\n",
      "Epoch 77 step 11 loss: 0.45650196075439453\n",
      "Epoch 77 step 12 loss: 0.2722392976284027\n",
      "Epoch 77 step 13 loss: 0.5345413684844971\n",
      "Epoch 77 step 14 loss: 0.42050424218177795\n",
      "Epoch 77 step 15 loss: 0.2822016775608063\n",
      "Epoch 77 step 16 loss: 0.5266593098640442\n",
      "Epoch 77 step 17 loss: 0.3091552257537842\n",
      "Epoch 77 step 18 loss: 0.4725308120250702\n",
      "Epoch 77 step 19 loss: 0.4319777190685272\n",
      "Epoch 77 step 20 loss: 0.44692763686180115\n",
      "Epoch 77 step 21 loss: 0.4426502287387848\n",
      "Epoch 77 step 22 loss: 0.2769474685192108\n",
      "Epoch 77 step 23 loss: 0.3698427975177765\n",
      "Epoch 77 step 24 loss: 0.4043169915676117\n",
      "Epoch 77 step 25 loss: 0.38938620686531067\n",
      "Epoch 77 step 26 loss: 0.4239853024482727\n",
      "Epoch 77 step 27 loss: 0.4039696455001831\n",
      "Epoch 77 step 28 loss: 0.37633681297302246\n",
      "Epoch 77 step 29 loss: 0.6467979550361633\n",
      "Epoch 77 step 30 loss: 0.3880974352359772\n",
      "Epoch 77 step 31 loss: 0.2914290726184845\n",
      "Epoch 77 step 32 loss: 0.43040817975997925\n",
      "Epoch 77 step 33 loss: 0.4260574281215668\n",
      "Epoch 77 step 34 loss: 0.3016137182712555\n",
      "Epoch 77 step 35 loss: 0.34407901763916016\n",
      "Epoch 77 step 36 loss: 0.43680381774902344\n",
      "Epoch 77 step 37 loss: 0.4435550570487976\n",
      "Epoch 77 step 38 loss: 0.5226455926895142\n",
      "Epoch 77 loss: 0.5226455926895142\n",
      "Epoch 78 step 0 loss: 0.34027284383773804\n",
      "Epoch 78 step 1 loss: 0.4355836510658264\n",
      "Epoch 78 step 2 loss: 0.48972585797309875\n",
      "Epoch 78 step 3 loss: 0.6068329811096191\n",
      "Epoch 78 step 4 loss: 0.48397859930992126\n",
      "Epoch 78 step 5 loss: 0.5553800463676453\n",
      "Epoch 78 step 6 loss: 0.43193137645721436\n",
      "Epoch 78 step 7 loss: 0.35949721932411194\n",
      "Epoch 78 step 8 loss: 0.43077531456947327\n",
      "Epoch 78 step 9 loss: 0.4684092700481415\n",
      "Epoch 78 step 10 loss: 0.5043145418167114\n",
      "Epoch 78 step 11 loss: 0.4288029670715332\n",
      "Epoch 78 step 12 loss: 0.39201444387435913\n",
      "Epoch 78 step 13 loss: 0.45972874760627747\n",
      "Epoch 78 step 14 loss: 0.43082714080810547\n",
      "Epoch 78 step 15 loss: 0.5582546591758728\n",
      "Epoch 78 step 16 loss: 0.472019761800766\n",
      "Epoch 78 step 17 loss: 0.48177167773246765\n",
      "Epoch 78 step 18 loss: 0.28621718287467957\n",
      "Epoch 78 step 19 loss: 0.32532238960266113\n",
      "Epoch 78 step 20 loss: 0.347406804561615\n",
      "Epoch 78 step 21 loss: 0.35647842288017273\n",
      "Epoch 78 step 22 loss: 0.31698793172836304\n",
      "Epoch 78 step 23 loss: 0.3237898647785187\n",
      "Epoch 78 step 24 loss: 0.320451557636261\n",
      "Epoch 78 step 25 loss: 0.3347369432449341\n",
      "Epoch 78 step 26 loss: 0.30886363983154297\n",
      "Epoch 78 step 27 loss: 0.39563533663749695\n",
      "Epoch 78 step 28 loss: 0.3459548056125641\n",
      "Epoch 78 step 29 loss: 0.5522326231002808\n",
      "Epoch 78 step 30 loss: 0.4415627717971802\n",
      "Epoch 78 step 31 loss: 0.5437269806861877\n",
      "Epoch 78 step 32 loss: 0.3848686218261719\n",
      "Epoch 78 step 33 loss: 0.2579505741596222\n",
      "Epoch 78 step 34 loss: 0.3830755352973938\n",
      "Epoch 78 step 35 loss: 0.30293014645576477\n",
      "Epoch 78 step 36 loss: 0.45255789160728455\n",
      "Epoch 78 step 37 loss: 0.36719974875450134\n",
      "Epoch 78 step 38 loss: 0.30437061190605164\n",
      "Epoch 78 loss: 0.30437061190605164\n",
      "Epoch 79 step 0 loss: 0.3540254235267639\n",
      "Epoch 79 step 1 loss: 0.30376291275024414\n",
      "Epoch 79 step 2 loss: 0.3872275948524475\n",
      "Epoch 79 step 3 loss: 0.28633299469947815\n",
      "Epoch 79 step 4 loss: 0.34391286969184875\n",
      "Epoch 79 step 5 loss: 0.35634851455688477\n",
      "Epoch 79 step 6 loss: 0.3190446197986603\n",
      "Epoch 79 step 7 loss: 0.3702597916126251\n",
      "Epoch 79 step 8 loss: 0.40313613414764404\n",
      "Epoch 79 step 9 loss: 0.4496009051799774\n",
      "Epoch 79 step 10 loss: 0.3443005383014679\n",
      "Epoch 79 step 11 loss: 0.41610777378082275\n",
      "Epoch 79 step 12 loss: 0.3208073675632477\n",
      "Epoch 79 step 13 loss: 0.47083359956741333\n",
      "Epoch 79 step 14 loss: 0.4457390010356903\n",
      "Epoch 79 step 15 loss: 0.4460872411727905\n",
      "Epoch 79 step 16 loss: 0.3122791349887848\n",
      "Epoch 79 step 17 loss: 0.37749186158180237\n",
      "Epoch 79 step 18 loss: 0.3717297315597534\n",
      "Epoch 79 step 19 loss: 0.4803035855293274\n",
      "Epoch 79 step 20 loss: 0.36352604627609253\n",
      "Epoch 79 step 21 loss: 0.5005092024803162\n",
      "Epoch 79 step 22 loss: 0.3614391088485718\n",
      "Epoch 79 step 23 loss: 0.634544312953949\n",
      "Epoch 79 step 24 loss: 0.5726532936096191\n",
      "Epoch 79 step 25 loss: 0.4528641104698181\n",
      "Epoch 79 step 26 loss: 0.4428097605705261\n",
      "Epoch 79 step 27 loss: 0.41500404477119446\n",
      "Epoch 79 step 28 loss: 0.6022118926048279\n",
      "Epoch 79 step 29 loss: 0.43808069825172424\n",
      "Epoch 79 step 30 loss: 0.4977116286754608\n",
      "Epoch 79 step 31 loss: 0.4871829152107239\n",
      "Epoch 79 step 32 loss: 0.3684801757335663\n",
      "Epoch 79 step 33 loss: 0.46422743797302246\n",
      "Epoch 79 step 34 loss: 0.3817428946495056\n",
      "Epoch 79 step 35 loss: 0.3478334844112396\n",
      "Epoch 79 step 36 loss: 0.5838322043418884\n",
      "Epoch 79 step 37 loss: 0.4721924364566803\n",
      "Epoch 79 step 38 loss: 0.5513215661048889\n",
      "Epoch 79 loss: 0.5513215661048889\n",
      "Epoch 80 step 0 loss: 0.5736126899719238\n",
      "Epoch 80 step 1 loss: 0.4174099266529083\n",
      "Epoch 80 step 2 loss: 0.5101212859153748\n",
      "Epoch 80 step 3 loss: 0.4340989589691162\n",
      "Epoch 80 step 4 loss: 0.5167420506477356\n",
      "Epoch 80 step 5 loss: 0.4029495120048523\n",
      "Epoch 80 step 6 loss: 0.49447596073150635\n",
      "Epoch 80 step 7 loss: 0.41973018646240234\n",
      "Epoch 80 step 8 loss: 0.40261727571487427\n",
      "Epoch 80 step 9 loss: 0.3534073531627655\n",
      "Epoch 80 step 10 loss: 0.5475330948829651\n",
      "Epoch 80 step 11 loss: 0.45684367418289185\n",
      "Epoch 80 step 12 loss: 0.4182319939136505\n",
      "Epoch 80 step 13 loss: 0.38700374960899353\n",
      "Epoch 80 step 14 loss: 0.361919641494751\n",
      "Epoch 80 step 15 loss: 0.42325523495674133\n",
      "Epoch 80 step 16 loss: 0.39912617206573486\n",
      "Epoch 80 step 17 loss: 0.515264093875885\n",
      "Epoch 80 step 18 loss: 0.4219766855239868\n",
      "Epoch 80 step 19 loss: 0.4324354827404022\n",
      "Epoch 80 step 20 loss: 0.4397895932197571\n",
      "Epoch 80 step 21 loss: 0.43187153339385986\n",
      "Epoch 80 step 22 loss: 0.43496647477149963\n",
      "Epoch 80 step 23 loss: 0.3669247031211853\n",
      "Epoch 80 step 24 loss: 0.3914477229118347\n",
      "Epoch 80 step 25 loss: 0.3224810063838959\n",
      "Epoch 80 step 26 loss: 0.33072879910469055\n",
      "Epoch 80 step 27 loss: 0.34524720907211304\n",
      "Epoch 80 step 28 loss: 0.5971701145172119\n",
      "Epoch 80 step 29 loss: 0.39927247166633606\n",
      "Epoch 80 step 30 loss: 0.37034520506858826\n",
      "Epoch 80 step 31 loss: 0.350046843290329\n",
      "Epoch 80 step 32 loss: 0.3386884033679962\n",
      "Epoch 80 step 33 loss: 0.4711416959762573\n",
      "Epoch 80 step 34 loss: 0.33956387639045715\n",
      "Epoch 80 step 35 loss: 0.29426389932632446\n",
      "Epoch 80 step 36 loss: 0.49316561222076416\n",
      "Epoch 80 step 37 loss: 0.44304537773132324\n",
      "Epoch 80 step 38 loss: 0.4791274964809418\n",
      "Epoch 80 loss: 0.4791274964809418\n",
      "Epoch 81 step 0 loss: 0.3823166787624359\n",
      "Epoch 81 step 1 loss: 0.36998552083969116\n",
      "Epoch 81 step 2 loss: 0.41832655668258667\n",
      "Epoch 81 step 3 loss: 0.3090658485889435\n",
      "Epoch 81 step 4 loss: 0.5269761681556702\n",
      "Epoch 81 step 5 loss: 0.4839431345462799\n",
      "Epoch 81 step 6 loss: 0.4916240870952606\n",
      "Epoch 81 step 7 loss: 0.49280846118927\n",
      "Epoch 81 step 8 loss: 0.541297972202301\n",
      "Epoch 81 step 9 loss: 0.3491121530532837\n",
      "Epoch 81 step 10 loss: 0.42265722155570984\n",
      "Epoch 81 step 11 loss: 0.42062613368034363\n",
      "Epoch 81 step 12 loss: 0.425248920917511\n",
      "Epoch 81 step 13 loss: 0.4096537232398987\n",
      "Epoch 81 step 14 loss: 0.4328033924102783\n",
      "Epoch 81 step 15 loss: 0.44856128096580505\n",
      "Epoch 81 step 16 loss: 0.4210391044616699\n",
      "Epoch 81 step 17 loss: 0.35963982343673706\n",
      "Epoch 81 step 18 loss: 0.35070374608039856\n",
      "Epoch 81 step 19 loss: 0.3865801990032196\n",
      "Epoch 81 step 20 loss: 0.3509924113750458\n",
      "Epoch 81 step 21 loss: 0.42906802892684937\n",
      "Epoch 81 step 22 loss: 0.3930901288986206\n",
      "Epoch 81 step 23 loss: 0.38951966166496277\n",
      "Epoch 81 step 24 loss: 0.3260888457298279\n",
      "Epoch 81 step 25 loss: 0.33635213971138\n",
      "Epoch 81 step 26 loss: 0.43597379326820374\n",
      "Epoch 81 step 27 loss: 0.626075804233551\n",
      "Epoch 81 step 28 loss: 0.3739456832408905\n",
      "Epoch 81 step 29 loss: 0.3760794997215271\n",
      "Epoch 81 step 30 loss: 0.3733319342136383\n",
      "Epoch 81 step 31 loss: 0.5703349709510803\n",
      "Epoch 81 step 32 loss: 0.3593687415122986\n",
      "Epoch 81 step 33 loss: 0.40430212020874023\n",
      "Epoch 81 step 34 loss: 0.3866378366947174\n",
      "Epoch 81 step 35 loss: 0.487729012966156\n",
      "Epoch 81 step 36 loss: 0.4717853367328644\n",
      "Epoch 81 step 37 loss: 0.3498888611793518\n",
      "Epoch 81 step 38 loss: 0.253937304019928\n",
      "Epoch 81 loss: 0.253937304019928\n",
      "Epoch 82 step 0 loss: 0.4840549826622009\n",
      "Epoch 82 step 1 loss: 0.4084620475769043\n",
      "Epoch 82 step 2 loss: 0.3946688175201416\n",
      "Epoch 82 step 3 loss: 0.3924522399902344\n",
      "Epoch 82 step 4 loss: 0.33738887310028076\n",
      "Epoch 82 step 5 loss: 0.4174872636795044\n",
      "Epoch 82 step 6 loss: 0.4143184721469879\n",
      "Epoch 82 step 7 loss: 0.3380124270915985\n",
      "Epoch 82 step 8 loss: 0.35623452067375183\n",
      "Epoch 82 step 9 loss: 0.40953415632247925\n",
      "Epoch 82 step 10 loss: 0.40230804681777954\n",
      "Epoch 82 step 11 loss: 0.33530300855636597\n",
      "Epoch 82 step 12 loss: 0.4307388365268707\n",
      "Epoch 82 step 13 loss: 0.5186959505081177\n",
      "Epoch 82 step 14 loss: 0.30409061908721924\n",
      "Epoch 82 step 15 loss: 0.46993544697761536\n",
      "Epoch 82 step 16 loss: 0.34275758266448975\n",
      "Epoch 82 step 17 loss: 0.4566129744052887\n",
      "Epoch 82 step 18 loss: 0.36066246032714844\n",
      "Epoch 82 step 19 loss: 0.32494860887527466\n",
      "Epoch 82 step 20 loss: 0.4076680839061737\n",
      "Epoch 82 step 21 loss: 0.3490578532218933\n",
      "Epoch 82 step 22 loss: 0.520618200302124\n",
      "Epoch 82 step 23 loss: 0.3523128926753998\n",
      "Epoch 82 step 24 loss: 0.46046823263168335\n",
      "Epoch 82 step 25 loss: 0.3070105016231537\n",
      "Epoch 82 step 26 loss: 0.33633753657341003\n",
      "Epoch 82 step 27 loss: 0.5034588575363159\n",
      "Epoch 82 step 28 loss: 0.44055065512657166\n",
      "Epoch 82 step 29 loss: 0.2483832836151123\n",
      "Epoch 82 step 30 loss: 0.3479940891265869\n",
      "Epoch 82 step 31 loss: 0.33378010988235474\n",
      "Epoch 82 step 32 loss: 0.3264148235321045\n",
      "Epoch 82 step 33 loss: 0.31504181027412415\n",
      "Epoch 82 step 34 loss: 0.5306187868118286\n",
      "Epoch 82 step 35 loss: 0.3685213327407837\n",
      "Epoch 82 step 36 loss: 0.42749273777008057\n",
      "Epoch 82 step 37 loss: 0.41841569542884827\n",
      "Epoch 82 step 38 loss: 0.4671734869480133\n",
      "Epoch 82 loss: 0.4671734869480133\n",
      "Epoch 83 step 0 loss: 0.520345151424408\n",
      "Epoch 83 step 1 loss: 0.3316347002983093\n",
      "Epoch 83 step 2 loss: 0.35696643590927124\n",
      "Epoch 83 step 3 loss: 0.4773399233818054\n",
      "Epoch 83 step 4 loss: 0.5729354023933411\n",
      "Epoch 83 step 5 loss: 0.626055121421814\n",
      "Epoch 83 step 6 loss: 0.47081729769706726\n",
      "Epoch 83 step 7 loss: 0.49287351965904236\n",
      "Epoch 83 step 8 loss: 0.430771142244339\n",
      "Epoch 83 step 9 loss: 0.4638455808162689\n",
      "Epoch 83 step 10 loss: 0.36587780714035034\n",
      "Epoch 83 step 11 loss: 0.4288230538368225\n",
      "Epoch 83 step 12 loss: 0.43308529257774353\n",
      "Epoch 83 step 13 loss: 0.4119383692741394\n",
      "Epoch 83 step 14 loss: 0.4395545721054077\n",
      "Epoch 83 step 15 loss: 0.43385207653045654\n",
      "Epoch 83 step 16 loss: 0.6021342873573303\n",
      "Epoch 83 step 17 loss: 0.42430832982063293\n",
      "Epoch 83 step 18 loss: 0.5040163993835449\n",
      "Epoch 83 step 19 loss: 0.381392240524292\n",
      "Epoch 83 step 20 loss: 0.49938347935676575\n",
      "Epoch 83 step 21 loss: 0.4421529769897461\n",
      "Epoch 83 step 22 loss: 0.3387887477874756\n",
      "Epoch 83 step 23 loss: 0.5515620708465576\n",
      "Epoch 83 step 24 loss: 0.5019376873970032\n",
      "Epoch 83 step 25 loss: 0.616305410861969\n",
      "Epoch 83 step 26 loss: 0.4193848967552185\n",
      "Epoch 83 step 27 loss: 0.4411747455596924\n",
      "Epoch 83 step 28 loss: 0.4788413345813751\n",
      "Epoch 83 step 29 loss: 0.5214724540710449\n",
      "Epoch 83 step 30 loss: 0.548307478427887\n",
      "Epoch 83 step 31 loss: 0.5497729182243347\n",
      "Epoch 83 step 32 loss: 0.5477425456047058\n",
      "Epoch 83 step 33 loss: 0.4308486580848694\n",
      "Epoch 83 step 34 loss: 0.4510290026664734\n",
      "Epoch 83 step 35 loss: 0.415568470954895\n",
      "Epoch 83 step 36 loss: 0.4772649109363556\n",
      "Epoch 83 step 37 loss: 0.48793110251426697\n",
      "Epoch 83 step 38 loss: 0.378831148147583\n",
      "Epoch 83 loss: 0.378831148147583\n",
      "Epoch 84 step 0 loss: 0.4121168851852417\n",
      "Epoch 84 step 1 loss: 0.5087709426879883\n",
      "Epoch 84 step 2 loss: 0.4984529912471771\n",
      "Epoch 84 step 3 loss: 0.4754764139652252\n",
      "Epoch 84 step 4 loss: 0.40593022108078003\n",
      "Epoch 84 step 5 loss: 0.5384472608566284\n",
      "Epoch 84 step 6 loss: 0.37099528312683105\n",
      "Epoch 84 step 7 loss: 0.3952963352203369\n",
      "Epoch 84 step 8 loss: 0.42053651809692383\n",
      "Epoch 84 step 9 loss: 0.49902909994125366\n",
      "Epoch 84 step 10 loss: 0.46486896276474\n",
      "Epoch 84 step 11 loss: 0.4825051426887512\n",
      "Epoch 84 step 12 loss: 0.3664356470108032\n",
      "Epoch 84 step 13 loss: 0.4272052049636841\n",
      "Epoch 84 step 14 loss: 0.4696386754512787\n",
      "Epoch 84 step 15 loss: 0.4043312072753906\n",
      "Epoch 84 step 16 loss: 0.4893774688243866\n",
      "Epoch 84 step 17 loss: 0.37429535388946533\n",
      "Epoch 84 step 18 loss: 0.39935994148254395\n",
      "Epoch 84 step 19 loss: 0.4170141816139221\n",
      "Epoch 84 step 20 loss: 0.3089418411254883\n",
      "Epoch 84 step 21 loss: 0.3460853099822998\n",
      "Epoch 84 step 22 loss: 0.4338180720806122\n",
      "Epoch 84 step 23 loss: 0.5281104445457458\n",
      "Epoch 84 step 24 loss: 0.3999788165092468\n",
      "Epoch 84 step 25 loss: 0.40919893980026245\n",
      "Epoch 84 step 26 loss: 0.38034114241600037\n",
      "Epoch 84 step 27 loss: 0.4941396713256836\n",
      "Epoch 84 step 28 loss: 0.4239707589149475\n",
      "Epoch 84 step 29 loss: 0.4222298264503479\n",
      "Epoch 84 step 30 loss: 0.3536992371082306\n",
      "Epoch 84 step 31 loss: 0.4879988133907318\n",
      "Epoch 84 step 32 loss: 0.4503784775733948\n",
      "Epoch 84 step 33 loss: 0.40785548090934753\n",
      "Epoch 84 step 34 loss: 0.549689531326294\n",
      "Epoch 84 step 35 loss: 0.42344769835472107\n",
      "Epoch 84 step 36 loss: 0.3771434426307678\n",
      "Epoch 84 step 37 loss: 0.5262191295623779\n",
      "Epoch 84 step 38 loss: 0.4853340983390808\n",
      "Epoch 84 loss: 0.4853340983390808\n",
      "Epoch 85 step 0 loss: 0.31982672214508057\n",
      "Epoch 85 step 1 loss: 0.6202412247657776\n",
      "Epoch 85 step 2 loss: 0.42638063430786133\n",
      "Epoch 85 step 3 loss: 0.5366138815879822\n",
      "Epoch 85 step 4 loss: 0.36526137590408325\n",
      "Epoch 85 step 5 loss: 0.4713451564311981\n",
      "Epoch 85 step 6 loss: 0.5205437541007996\n",
      "Epoch 85 step 7 loss: 0.4970424771308899\n",
      "Epoch 85 step 8 loss: 0.3788479268550873\n",
      "Epoch 85 step 9 loss: 0.5464441180229187\n",
      "Epoch 85 step 10 loss: 0.31656739115715027\n",
      "Epoch 85 step 11 loss: 0.43726375699043274\n",
      "Epoch 85 step 12 loss: 0.32082894444465637\n",
      "Epoch 85 step 13 loss: 0.6232540011405945\n",
      "Epoch 85 step 14 loss: 0.4450046420097351\n",
      "Epoch 85 step 15 loss: 0.4991152286529541\n",
      "Epoch 85 step 16 loss: 0.4575742185115814\n",
      "Epoch 85 step 17 loss: 0.4614129364490509\n",
      "Epoch 85 step 18 loss: 0.48374447226524353\n",
      "Epoch 85 step 19 loss: 0.5140018463134766\n",
      "Epoch 85 step 20 loss: 0.5144425630569458\n",
      "Epoch 85 step 21 loss: 0.4319670796394348\n",
      "Epoch 85 step 22 loss: 0.4142535328865051\n",
      "Epoch 85 step 23 loss: 0.4504564702510834\n",
      "Epoch 85 step 24 loss: 0.5423703789710999\n",
      "Epoch 85 step 25 loss: 0.4256551265716553\n",
      "Epoch 85 step 26 loss: 0.3904561400413513\n",
      "Epoch 85 step 27 loss: 0.4186978042125702\n",
      "Epoch 85 step 28 loss: 0.5178146958351135\n",
      "Epoch 85 step 29 loss: 0.48112115263938904\n",
      "Epoch 85 step 30 loss: 0.41427865624427795\n",
      "Epoch 85 step 31 loss: 0.486300528049469\n",
      "Epoch 85 step 32 loss: 0.43337175250053406\n",
      "Epoch 85 step 33 loss: 0.4652341902256012\n",
      "Epoch 85 step 34 loss: 0.5087229609489441\n",
      "Epoch 85 step 35 loss: 0.3070026636123657\n",
      "Epoch 85 step 36 loss: 0.4241708219051361\n",
      "Epoch 85 step 37 loss: 0.4657904803752899\n",
      "Epoch 85 step 38 loss: 0.4990690350532532\n",
      "Epoch 85 loss: 0.4990690350532532\n",
      "Epoch 86 step 0 loss: 0.46241286396980286\n",
      "Epoch 86 step 1 loss: 0.3403981626033783\n",
      "Epoch 86 step 2 loss: 0.331204891204834\n",
      "Epoch 86 step 3 loss: 0.4292532503604889\n",
      "Epoch 86 step 4 loss: 0.3313829302787781\n",
      "Epoch 86 step 5 loss: 0.3564816415309906\n",
      "Epoch 86 step 6 loss: 0.47148236632347107\n",
      "Epoch 86 step 7 loss: 0.29913315176963806\n",
      "Epoch 86 step 8 loss: 0.34190499782562256\n",
      "Epoch 86 step 9 loss: 0.45776164531707764\n",
      "Epoch 86 step 10 loss: 0.3671082556247711\n",
      "Epoch 86 step 11 loss: 0.4506063163280487\n",
      "Epoch 86 step 12 loss: 0.5037972331047058\n",
      "Epoch 86 step 13 loss: 0.40189871191978455\n",
      "Epoch 86 step 14 loss: 0.3335491716861725\n",
      "Epoch 86 step 15 loss: 0.3669237494468689\n",
      "Epoch 86 step 16 loss: 0.3261245787143707\n",
      "Epoch 86 step 17 loss: 0.36430585384368896\n",
      "Epoch 86 step 18 loss: 0.6025394797325134\n",
      "Epoch 86 step 19 loss: 0.40392279624938965\n",
      "Epoch 86 step 20 loss: 0.4914751648902893\n",
      "Epoch 86 step 21 loss: 0.36443501710891724\n",
      "Epoch 86 step 22 loss: 0.4234488606452942\n",
      "Epoch 86 step 23 loss: 0.3954169452190399\n",
      "Epoch 86 step 24 loss: 0.4581962823867798\n",
      "Epoch 86 step 25 loss: 0.4960709512233734\n",
      "Epoch 86 step 26 loss: 0.44627925753593445\n",
      "Epoch 86 step 27 loss: 0.33891478180885315\n",
      "Epoch 86 step 28 loss: 0.4451097846031189\n",
      "Epoch 86 step 29 loss: 0.5150538086891174\n",
      "Epoch 86 step 30 loss: 0.45383667945861816\n",
      "Epoch 86 step 31 loss: 0.31565532088279724\n",
      "Epoch 86 step 32 loss: 0.3911387324333191\n",
      "Epoch 86 step 33 loss: 0.3533859848976135\n",
      "Epoch 86 step 34 loss: 0.45960208773612976\n",
      "Epoch 86 step 35 loss: 0.30096057057380676\n",
      "Epoch 86 step 36 loss: 0.447926789522171\n",
      "Epoch 86 step 37 loss: 0.5750730633735657\n",
      "Epoch 86 step 38 loss: 0.49885037541389465\n",
      "Epoch 86 loss: 0.49885037541389465\n",
      "Epoch 87 step 0 loss: 0.5875913500785828\n",
      "Epoch 87 step 1 loss: 0.494451105594635\n",
      "Epoch 87 step 2 loss: 0.40017300844192505\n",
      "Epoch 87 step 3 loss: 0.36787357926368713\n",
      "Epoch 87 step 4 loss: 0.5398749709129333\n",
      "Epoch 87 step 5 loss: 0.42111000418663025\n",
      "Epoch 87 step 6 loss: 0.4583711624145508\n",
      "Epoch 87 step 7 loss: 0.33072182536125183\n",
      "Epoch 87 step 8 loss: 0.46730881929397583\n",
      "Epoch 87 step 9 loss: 0.5558621883392334\n",
      "Epoch 87 step 10 loss: 0.39962637424468994\n",
      "Epoch 87 step 11 loss: 0.52028489112854\n",
      "Epoch 87 step 12 loss: 0.4001110792160034\n",
      "Epoch 87 step 13 loss: 0.3484158515930176\n",
      "Epoch 87 step 14 loss: 0.4899563491344452\n",
      "Epoch 87 step 15 loss: 0.4055113196372986\n",
      "Epoch 87 step 16 loss: 0.36238789558410645\n",
      "Epoch 87 step 17 loss: 0.39844444394111633\n",
      "Epoch 87 step 18 loss: 0.5103790760040283\n",
      "Epoch 87 step 19 loss: 0.45185744762420654\n",
      "Epoch 87 step 20 loss: 0.3432311713695526\n",
      "Epoch 87 step 21 loss: 0.400047242641449\n",
      "Epoch 87 step 22 loss: 0.41856953501701355\n",
      "Epoch 87 step 23 loss: 0.47545599937438965\n",
      "Epoch 87 step 24 loss: 0.5314297676086426\n",
      "Epoch 87 step 25 loss: 0.5245512127876282\n",
      "Epoch 87 step 26 loss: 0.4865427315235138\n",
      "Epoch 87 step 27 loss: 0.4276528060436249\n",
      "Epoch 87 step 28 loss: 0.48289862275123596\n",
      "Epoch 87 step 29 loss: 0.4991951882839203\n",
      "Epoch 87 step 30 loss: 0.47791680693626404\n",
      "Epoch 87 step 31 loss: 0.5205164551734924\n",
      "Epoch 87 step 32 loss: 0.3714553415775299\n",
      "Epoch 87 step 33 loss: 0.5867958068847656\n",
      "Epoch 87 step 34 loss: 0.37192460894584656\n",
      "Epoch 87 step 35 loss: 0.7854193449020386\n",
      "Epoch 87 step 36 loss: 0.590132474899292\n",
      "Epoch 87 step 37 loss: 0.7441683411598206\n",
      "Epoch 87 step 38 loss: 0.6748837828636169\n",
      "Epoch 87 loss: 0.6748837828636169\n",
      "Epoch 88 step 0 loss: 0.49421143531799316\n",
      "Epoch 88 step 1 loss: 0.5790988802909851\n",
      "Epoch 88 step 2 loss: 0.6740334033966064\n",
      "Epoch 88 step 3 loss: 0.4960777461528778\n",
      "Epoch 88 step 4 loss: 0.5431181192398071\n",
      "Epoch 88 step 5 loss: 0.47862672805786133\n",
      "Epoch 88 step 6 loss: 0.47053617238998413\n",
      "Epoch 88 step 7 loss: 0.49387386441230774\n",
      "Epoch 88 step 8 loss: 0.45234745740890503\n",
      "Epoch 88 step 9 loss: 0.4694002866744995\n",
      "Epoch 88 step 10 loss: 0.40722551941871643\n",
      "Epoch 88 step 11 loss: 0.4380062222480774\n",
      "Epoch 88 step 12 loss: 0.3092157542705536\n",
      "Epoch 88 step 13 loss: 0.4007847309112549\n",
      "Epoch 88 step 14 loss: 0.5607519149780273\n",
      "Epoch 88 step 15 loss: 0.42892035841941833\n",
      "Epoch 88 step 16 loss: 0.4229925870895386\n",
      "Epoch 88 step 17 loss: 0.5307649970054626\n",
      "Epoch 88 step 18 loss: 0.42897194623947144\n",
      "Epoch 88 step 19 loss: 0.4473889172077179\n",
      "Epoch 88 step 20 loss: 0.4665251076221466\n",
      "Epoch 88 step 21 loss: 0.36397767066955566\n",
      "Epoch 88 step 22 loss: 0.4440520405769348\n",
      "Epoch 88 step 23 loss: 0.4655914902687073\n",
      "Epoch 88 step 24 loss: 0.6087676882743835\n",
      "Epoch 88 step 25 loss: 0.3287056088447571\n",
      "Epoch 88 step 26 loss: 0.39871880412101746\n",
      "Epoch 88 step 27 loss: 0.46032923460006714\n",
      "Epoch 88 step 28 loss: 0.5636304020881653\n",
      "Epoch 88 step 29 loss: 0.39975419640541077\n",
      "Epoch 88 step 30 loss: 0.3822661340236664\n",
      "Epoch 88 step 31 loss: 0.4193597137928009\n",
      "Epoch 88 step 32 loss: 0.40787312388420105\n",
      "Epoch 88 step 33 loss: 0.4358856976032257\n",
      "Epoch 88 step 34 loss: 0.4061908423900604\n",
      "Epoch 88 step 35 loss: 0.5313125848770142\n",
      "Epoch 88 step 36 loss: 0.5990478992462158\n",
      "Epoch 88 step 37 loss: 0.5328621864318848\n",
      "Epoch 88 step 38 loss: 0.5283970832824707\n",
      "Epoch 88 loss: 0.5283970832824707\n",
      "Epoch 89 step 0 loss: 0.599597156047821\n",
      "Epoch 89 step 1 loss: 0.4794589877128601\n",
      "Epoch 89 step 2 loss: 0.3585098087787628\n",
      "Epoch 89 step 3 loss: 0.46405476331710815\n",
      "Epoch 89 step 4 loss: 0.482128769159317\n",
      "Epoch 89 step 5 loss: 0.6704155206680298\n",
      "Epoch 89 step 6 loss: 0.31318214535713196\n",
      "Epoch 89 step 7 loss: 0.3933638632297516\n",
      "Epoch 89 step 8 loss: 0.4293811023235321\n",
      "Epoch 89 step 9 loss: 0.3919455409049988\n",
      "Epoch 89 step 10 loss: 0.344617635011673\n",
      "Epoch 89 step 11 loss: 0.3681141138076782\n",
      "Epoch 89 step 12 loss: 0.5872287750244141\n",
      "Epoch 89 step 13 loss: 0.36201211810112\n",
      "Epoch 89 step 14 loss: 0.5159910321235657\n",
      "Epoch 89 step 15 loss: 0.35697227716445923\n",
      "Epoch 89 step 16 loss: 0.42890188097953796\n",
      "Epoch 89 step 17 loss: 0.4603966474533081\n",
      "Epoch 89 step 18 loss: 0.4624921679496765\n",
      "Epoch 89 step 19 loss: 0.45218902826309204\n",
      "Epoch 89 step 20 loss: 0.3434821367263794\n",
      "Epoch 89 step 21 loss: 0.42698416113853455\n",
      "Epoch 89 step 22 loss: 0.3662768602371216\n",
      "Epoch 89 step 23 loss: 0.45000895857810974\n",
      "Epoch 89 step 24 loss: 0.3693021237850189\n",
      "Epoch 89 step 25 loss: 0.44913822412490845\n",
      "Epoch 89 step 26 loss: 0.344757080078125\n",
      "Epoch 89 step 27 loss: 0.48485714197158813\n",
      "Epoch 89 step 28 loss: 0.3653201162815094\n",
      "Epoch 89 step 29 loss: 0.4204803705215454\n",
      "Epoch 89 step 30 loss: 0.31036505103111267\n",
      "Epoch 89 step 31 loss: 0.3278646171092987\n",
      "Epoch 89 step 32 loss: 0.3733363747596741\n",
      "Epoch 89 step 33 loss: 0.43193313479423523\n",
      "Epoch 89 step 34 loss: 0.5868155360221863\n",
      "Epoch 89 step 35 loss: 0.3729434311389923\n",
      "Epoch 89 step 36 loss: 0.35389745235443115\n",
      "Epoch 89 step 37 loss: 0.3862222135066986\n",
      "Epoch 89 step 38 loss: 0.3179798126220703\n",
      "Epoch 89 loss: 0.3179798126220703\n",
      "Epoch 90 step 0 loss: 0.3423536419868469\n",
      "Epoch 90 step 1 loss: 0.37890735268592834\n",
      "Epoch 90 step 2 loss: 0.35513097047805786\n",
      "Epoch 90 step 3 loss: 0.4330123960971832\n",
      "Epoch 90 step 4 loss: 0.40682312846183777\n",
      "Epoch 90 step 5 loss: 0.4470895230770111\n",
      "Epoch 90 step 6 loss: 0.48720118403434753\n",
      "Epoch 90 step 7 loss: 0.5060686469078064\n",
      "Epoch 90 step 8 loss: 0.4584237039089203\n",
      "Epoch 90 step 9 loss: 0.6562108397483826\n",
      "Epoch 90 step 10 loss: 0.46977698802948\n",
      "Epoch 90 step 11 loss: 0.6568944454193115\n",
      "Epoch 90 step 12 loss: 0.36924123764038086\n",
      "Epoch 90 step 13 loss: 0.46921825408935547\n",
      "Epoch 90 step 14 loss: 0.3886971175670624\n",
      "Epoch 90 step 15 loss: 0.44700294733047485\n",
      "Epoch 90 step 16 loss: 0.45557186007499695\n",
      "Epoch 90 step 17 loss: 0.34366458654403687\n",
      "Epoch 90 step 18 loss: 0.5316826105117798\n",
      "Epoch 90 step 19 loss: 0.40878865122795105\n",
      "Epoch 90 step 20 loss: 0.4887326657772064\n",
      "Epoch 90 step 21 loss: 0.5546014308929443\n",
      "Epoch 90 step 22 loss: 0.4032474160194397\n",
      "Epoch 90 step 23 loss: 0.4742654263973236\n",
      "Epoch 90 step 24 loss: 0.44349220395088196\n",
      "Epoch 90 step 25 loss: 0.4939059019088745\n",
      "Epoch 90 step 26 loss: 0.6203103065490723\n",
      "Epoch 90 step 27 loss: 0.46162155270576477\n",
      "Epoch 90 step 28 loss: 0.40552425384521484\n",
      "Epoch 90 step 29 loss: 0.3857145309448242\n",
      "Epoch 90 step 30 loss: 0.4484749138355255\n",
      "Epoch 90 step 31 loss: 0.48826783895492554\n",
      "Epoch 90 step 32 loss: 0.5294428467750549\n",
      "Epoch 90 step 33 loss: 0.4679126441478729\n",
      "Epoch 90 step 34 loss: 0.34932413697242737\n",
      "Epoch 90 step 35 loss: 0.41330990195274353\n",
      "Epoch 90 step 36 loss: 0.5607478618621826\n",
      "Epoch 90 step 37 loss: 0.3966486155986786\n",
      "Epoch 90 step 38 loss: 0.46144166588783264\n",
      "Epoch 90 loss: 0.46144166588783264\n",
      "Epoch 91 step 0 loss: 0.3410264253616333\n",
      "Epoch 91 step 1 loss: 0.4491892457008362\n",
      "Epoch 91 step 2 loss: 0.5386345386505127\n",
      "Epoch 91 step 3 loss: 0.5383461117744446\n",
      "Epoch 91 step 4 loss: 0.4158194959163666\n",
      "Epoch 91 step 5 loss: 0.42214903235435486\n",
      "Epoch 91 step 6 loss: 0.38509538769721985\n",
      "Epoch 91 step 7 loss: 0.32442182302474976\n",
      "Epoch 91 step 8 loss: 0.46721646189689636\n",
      "Epoch 91 step 9 loss: 0.4978586733341217\n",
      "Epoch 91 step 10 loss: 0.4496189057826996\n",
      "Epoch 91 step 11 loss: 0.5586773157119751\n",
      "Epoch 91 step 12 loss: 0.3452654778957367\n",
      "Epoch 91 step 13 loss: 0.31224989891052246\n",
      "Epoch 91 step 14 loss: 0.4027772843837738\n",
      "Epoch 91 step 15 loss: 0.4468683898448944\n",
      "Epoch 91 step 16 loss: 0.4631999731063843\n",
      "Epoch 91 step 17 loss: 0.3164512813091278\n",
      "Epoch 91 step 18 loss: 0.4212748110294342\n",
      "Epoch 91 step 19 loss: 0.4752199053764343\n",
      "Epoch 91 step 20 loss: 0.5188356041908264\n",
      "Epoch 91 step 21 loss: 0.30442264676094055\n",
      "Epoch 91 step 22 loss: 0.5594504475593567\n",
      "Epoch 91 step 23 loss: 0.3211113512516022\n",
      "Epoch 91 step 24 loss: 0.4832686185836792\n",
      "Epoch 91 step 25 loss: 0.3203722834587097\n",
      "Epoch 91 step 26 loss: 0.5270789861679077\n",
      "Epoch 91 step 27 loss: 0.47437867522239685\n",
      "Epoch 91 step 28 loss: 0.4266625642776489\n",
      "Epoch 91 step 29 loss: 0.38840678334236145\n",
      "Epoch 91 step 30 loss: 0.4226536452770233\n",
      "Epoch 91 step 31 loss: 0.3358597159385681\n",
      "Epoch 91 step 32 loss: 0.5337892174720764\n",
      "Epoch 91 step 33 loss: 0.3925006091594696\n",
      "Epoch 91 step 34 loss: 0.42326053977012634\n",
      "Epoch 91 step 35 loss: 0.3704645037651062\n",
      "Epoch 91 step 36 loss: 0.35467442870140076\n",
      "Epoch 91 step 37 loss: 0.42688634991645813\n",
      "Epoch 91 step 38 loss: 0.434725284576416\n",
      "Epoch 91 loss: 0.434725284576416\n",
      "Epoch 92 step 0 loss: 0.36770498752593994\n",
      "Epoch 92 step 1 loss: 0.40538397431373596\n",
      "Epoch 92 step 2 loss: 0.44951313734054565\n",
      "Epoch 92 step 3 loss: 0.28674519062042236\n",
      "Epoch 92 step 4 loss: 0.47757217288017273\n",
      "Epoch 92 step 5 loss: 0.4324200749397278\n",
      "Epoch 92 step 6 loss: 0.42451971769332886\n",
      "Epoch 92 step 7 loss: 0.5202391743659973\n",
      "Epoch 92 step 8 loss: 0.42355871200561523\n",
      "Epoch 92 step 9 loss: 0.3219352066516876\n",
      "Epoch 92 step 10 loss: 0.37790870666503906\n",
      "Epoch 92 step 11 loss: 0.43671298027038574\n",
      "Epoch 92 step 12 loss: 0.40952980518341064\n",
      "Epoch 92 step 13 loss: 0.40286457538604736\n",
      "Epoch 92 step 14 loss: 0.39599692821502686\n",
      "Epoch 92 step 15 loss: 0.44070619344711304\n",
      "Epoch 92 step 16 loss: 0.5650095343589783\n",
      "Epoch 92 step 17 loss: 0.3916323184967041\n",
      "Epoch 92 step 18 loss: 0.46833401918411255\n",
      "Epoch 92 step 19 loss: 0.3245334029197693\n",
      "Epoch 92 step 20 loss: 0.4828580319881439\n",
      "Epoch 92 step 21 loss: 0.4610860049724579\n",
      "Epoch 92 step 22 loss: 0.6226491928100586\n",
      "Epoch 92 step 23 loss: 0.42071762681007385\n",
      "Epoch 92 step 24 loss: 0.4693921208381653\n",
      "Epoch 92 step 25 loss: 0.6665693521499634\n",
      "Epoch 92 step 26 loss: 0.5220605134963989\n",
      "Epoch 92 step 27 loss: 0.3722691535949707\n",
      "Epoch 92 step 28 loss: 0.43274781107902527\n",
      "Epoch 92 step 29 loss: 0.47716954350471497\n",
      "Epoch 92 step 30 loss: 0.42099592089653015\n",
      "Epoch 92 step 31 loss: 0.3189367949962616\n",
      "Epoch 92 step 32 loss: 0.46162310242652893\n",
      "Epoch 92 step 33 loss: 0.3629955053329468\n",
      "Epoch 92 step 34 loss: 0.5151462554931641\n",
      "Epoch 92 step 35 loss: 0.4792744815349579\n",
      "Epoch 92 step 36 loss: 0.4258786141872406\n",
      "Epoch 92 step 37 loss: 0.37724190950393677\n",
      "Epoch 92 step 38 loss: 0.5107660293579102\n",
      "Epoch 92 loss: 0.5107660293579102\n",
      "Epoch 93 step 0 loss: 0.36842113733291626\n",
      "Epoch 93 step 1 loss: 0.6980229616165161\n",
      "Epoch 93 step 2 loss: 0.4985949397087097\n",
      "Epoch 93 step 3 loss: 0.41917169094085693\n",
      "Epoch 93 step 4 loss: 0.5085963010787964\n",
      "Epoch 93 step 5 loss: 0.3657485544681549\n",
      "Epoch 93 step 6 loss: 0.46796292066574097\n",
      "Epoch 93 step 7 loss: 0.525962769985199\n",
      "Epoch 93 step 8 loss: 0.5232398509979248\n",
      "Epoch 93 step 9 loss: 0.3340972661972046\n",
      "Epoch 93 step 10 loss: 0.5722121000289917\n",
      "Epoch 93 step 11 loss: 0.45001789927482605\n",
      "Epoch 93 step 12 loss: 0.3449459671974182\n",
      "Epoch 93 step 13 loss: 0.4638523459434509\n",
      "Epoch 93 step 14 loss: 0.48868945240974426\n",
      "Epoch 93 step 15 loss: 0.353210985660553\n",
      "Epoch 93 step 16 loss: 0.5704980492591858\n",
      "Epoch 93 step 17 loss: 0.37965282797813416\n",
      "Epoch 93 step 18 loss: 0.362639456987381\n",
      "Epoch 93 step 19 loss: 0.4573621153831482\n",
      "Epoch 93 step 20 loss: 0.4190758764743805\n",
      "Epoch 93 step 21 loss: 0.5616351366043091\n",
      "Epoch 93 step 22 loss: 0.4476063549518585\n",
      "Epoch 93 step 23 loss: 0.3419164717197418\n",
      "Epoch 93 step 24 loss: 0.39941519498825073\n",
      "Epoch 93 step 25 loss: 0.4331614375114441\n",
      "Epoch 93 step 26 loss: 0.3639688193798065\n",
      "Epoch 93 step 27 loss: 0.4802503287792206\n",
      "Epoch 93 step 28 loss: 0.39595773816108704\n",
      "Epoch 93 step 29 loss: 0.3576197624206543\n",
      "Epoch 93 step 30 loss: 0.48209527134895325\n",
      "Epoch 93 step 31 loss: 0.4697507619857788\n",
      "Epoch 93 step 32 loss: 0.4238508939743042\n",
      "Epoch 93 step 33 loss: 0.4620581567287445\n",
      "Epoch 93 step 34 loss: 0.33565354347229004\n",
      "Epoch 93 step 35 loss: 0.5814412236213684\n",
      "Epoch 93 step 36 loss: 0.26131558418273926\n",
      "Epoch 93 step 37 loss: 0.5131951570510864\n",
      "Epoch 93 step 38 loss: 0.34384462237358093\n",
      "Epoch 93 loss: 0.34384462237358093\n",
      "Epoch 94 step 0 loss: 0.437237024307251\n",
      "Epoch 94 step 1 loss: 0.39241912961006165\n",
      "Epoch 94 step 2 loss: 0.5603403449058533\n",
      "Epoch 94 step 3 loss: 0.45025667548179626\n",
      "Epoch 94 step 4 loss: 0.5448322296142578\n",
      "Epoch 94 step 5 loss: 0.5024524331092834\n",
      "Epoch 94 step 6 loss: 0.5733076930046082\n",
      "Epoch 94 step 7 loss: 0.43949195742607117\n",
      "Epoch 94 step 8 loss: 0.43530699610710144\n",
      "Epoch 94 step 9 loss: 0.3612852990627289\n",
      "Epoch 94 step 10 loss: 0.532444179058075\n",
      "Epoch 94 step 11 loss: 0.5122854709625244\n",
      "Epoch 94 step 12 loss: 0.4137532711029053\n",
      "Epoch 94 step 13 loss: 0.36537572741508484\n",
      "Epoch 94 step 14 loss: 0.46250540018081665\n",
      "Epoch 94 step 15 loss: 0.4850345551967621\n",
      "Epoch 94 step 16 loss: 0.47678154706954956\n",
      "Epoch 94 step 17 loss: 0.33524391055107117\n",
      "Epoch 94 step 18 loss: 0.42935910820961\n",
      "Epoch 94 step 19 loss: 0.491943895816803\n",
      "Epoch 94 step 20 loss: 0.38107991218566895\n",
      "Epoch 94 step 21 loss: 0.46478596329689026\n",
      "Epoch 94 step 22 loss: 0.45030683279037476\n",
      "Epoch 94 step 23 loss: 0.4625513553619385\n",
      "Epoch 94 step 24 loss: 0.571969747543335\n",
      "Epoch 94 step 25 loss: 0.37134402990341187\n",
      "Epoch 94 step 26 loss: 0.38105231523513794\n",
      "Epoch 94 step 27 loss: 0.430819034576416\n",
      "Epoch 94 step 28 loss: 0.41760143637657166\n",
      "Epoch 94 step 29 loss: 0.4908539056777954\n",
      "Epoch 94 step 30 loss: 0.49580350518226624\n",
      "Epoch 94 step 31 loss: 0.4456143379211426\n",
      "Epoch 94 step 32 loss: 0.39135128259658813\n",
      "Epoch 94 step 33 loss: 0.5629095435142517\n",
      "Epoch 94 step 34 loss: 0.545395016670227\n",
      "Epoch 94 step 35 loss: 0.4997160732746124\n",
      "Epoch 94 step 36 loss: 0.34340137243270874\n",
      "Epoch 94 step 37 loss: 0.4903438687324524\n",
      "Epoch 94 step 38 loss: 0.5259754061698914\n",
      "Epoch 94 loss: 0.5259754061698914\n",
      "Epoch 95 step 0 loss: 0.5124320387840271\n",
      "Epoch 95 step 1 loss: 0.5588241219520569\n",
      "Epoch 95 step 2 loss: 0.6186232566833496\n",
      "Epoch 95 step 3 loss: 0.3559732139110565\n",
      "Epoch 95 step 4 loss: 0.5408409833908081\n",
      "Epoch 95 step 5 loss: 0.3634219169616699\n",
      "Epoch 95 step 6 loss: 0.5799342393875122\n",
      "Epoch 95 step 7 loss: 0.5088900923728943\n",
      "Epoch 95 step 8 loss: 0.45045241713523865\n",
      "Epoch 95 step 9 loss: 0.4406949579715729\n",
      "Epoch 95 step 10 loss: 0.548404335975647\n",
      "Epoch 95 step 11 loss: 0.6155988574028015\n",
      "Epoch 95 step 12 loss: 0.4251704514026642\n",
      "Epoch 95 step 13 loss: 0.47048017382621765\n",
      "Epoch 95 step 14 loss: 0.5086712837219238\n",
      "Epoch 95 step 15 loss: 0.5031065344810486\n",
      "Epoch 95 step 16 loss: 0.41977792978286743\n",
      "Epoch 95 step 17 loss: 0.4361879527568817\n",
      "Epoch 95 step 18 loss: 0.46886304020881653\n",
      "Epoch 95 step 19 loss: 0.5928331017494202\n",
      "Epoch 95 step 20 loss: 0.48802798986434937\n",
      "Epoch 95 step 21 loss: 0.5167689323425293\n",
      "Epoch 95 step 22 loss: 0.37392038106918335\n",
      "Epoch 95 step 23 loss: 0.44871628284454346\n",
      "Epoch 95 step 24 loss: 0.4685717225074768\n",
      "Epoch 95 step 25 loss: 0.4165448844432831\n",
      "Epoch 95 step 26 loss: 0.4533400535583496\n",
      "Epoch 95 step 27 loss: 0.3708930015563965\n",
      "Epoch 95 step 28 loss: 0.3074464499950409\n",
      "Epoch 95 step 29 loss: 0.4026486575603485\n",
      "Epoch 95 step 30 loss: 0.37128910422325134\n",
      "Epoch 95 step 31 loss: 0.5733437538146973\n",
      "Epoch 95 step 32 loss: 0.30139902234077454\n",
      "Epoch 95 step 33 loss: 0.5015060305595398\n",
      "Epoch 95 step 34 loss: 0.3275725543498993\n",
      "Epoch 95 step 35 loss: 0.38485196232795715\n",
      "Epoch 95 step 36 loss: 0.4805956184864044\n",
      "Epoch 95 step 37 loss: 0.28901350498199463\n",
      "Epoch 95 step 38 loss: 0.30313727259635925\n",
      "Epoch 95 loss: 0.30313727259635925\n",
      "Epoch 96 step 0 loss: 0.4220602810382843\n",
      "Epoch 96 step 1 loss: 0.38937827944755554\n",
      "Epoch 96 step 2 loss: 0.3459928035736084\n",
      "Epoch 96 step 3 loss: 0.31051498651504517\n",
      "Epoch 96 step 4 loss: 0.31275713443756104\n",
      "Epoch 96 step 5 loss: 0.37789982557296753\n",
      "Epoch 96 step 6 loss: 0.42712292075157166\n",
      "Epoch 96 step 7 loss: 0.4636530876159668\n",
      "Epoch 96 step 8 loss: 0.4161683917045593\n",
      "Epoch 96 step 9 loss: 0.4244108498096466\n",
      "Epoch 96 step 10 loss: 0.565193235874176\n",
      "Epoch 96 step 11 loss: 0.692100465297699\n",
      "Epoch 96 step 12 loss: 0.28026628494262695\n",
      "Epoch 96 step 13 loss: 0.450504332780838\n",
      "Epoch 96 step 14 loss: 0.42146459221839905\n",
      "Epoch 96 step 15 loss: 0.5272484421730042\n",
      "Epoch 96 step 16 loss: 0.34056761860847473\n",
      "Epoch 96 step 17 loss: 0.5063542723655701\n",
      "Epoch 96 step 18 loss: 0.3059893250465393\n",
      "Epoch 96 step 19 loss: 0.3226662278175354\n",
      "Epoch 96 step 20 loss: 0.3647104501724243\n",
      "Epoch 96 step 21 loss: 0.5421539545059204\n",
      "Epoch 96 step 22 loss: 0.47577306628227234\n",
      "Epoch 96 step 23 loss: 0.45610669255256653\n",
      "Epoch 96 step 24 loss: 0.4005056321620941\n",
      "Epoch 96 step 25 loss: 0.372740238904953\n",
      "Epoch 96 step 26 loss: 0.5415616035461426\n",
      "Epoch 96 step 27 loss: 0.38707679510116577\n",
      "Epoch 96 step 28 loss: 0.4202135503292084\n",
      "Epoch 96 step 29 loss: 0.4563366770744324\n",
      "Epoch 96 step 30 loss: 0.4517304003238678\n",
      "Epoch 96 step 31 loss: 0.41376814246177673\n",
      "Epoch 96 step 32 loss: 0.36680373549461365\n",
      "Epoch 96 step 33 loss: 0.3543493449687958\n",
      "Epoch 96 step 34 loss: 0.6639416217803955\n",
      "Epoch 96 step 35 loss: 0.5047348141670227\n",
      "Epoch 96 step 36 loss: 0.45073142647743225\n",
      "Epoch 96 step 37 loss: 0.5142543315887451\n",
      "Epoch 96 step 38 loss: 0.4045059084892273\n",
      "Epoch 96 loss: 0.4045059084892273\n",
      "Epoch 97 step 0 loss: 0.3283550441265106\n",
      "Epoch 97 step 1 loss: 0.42249423265457153\n",
      "Epoch 97 step 2 loss: 0.347851037979126\n",
      "Epoch 97 step 3 loss: 0.4090491533279419\n",
      "Epoch 97 step 4 loss: 0.40035369992256165\n",
      "Epoch 97 step 5 loss: 0.4956038296222687\n",
      "Epoch 97 step 6 loss: 0.44205647706985474\n",
      "Epoch 97 step 7 loss: 0.7025810480117798\n",
      "Epoch 97 step 8 loss: 0.3800921142101288\n",
      "Epoch 97 step 9 loss: 0.5839358568191528\n",
      "Epoch 97 step 10 loss: 0.3645872473716736\n",
      "Epoch 97 step 11 loss: 0.5016123056411743\n",
      "Epoch 97 step 12 loss: 0.7083249092102051\n",
      "Epoch 97 step 13 loss: 0.4037471413612366\n",
      "Epoch 97 step 14 loss: 0.5459321141242981\n",
      "Epoch 97 step 15 loss: 0.35974735021591187\n",
      "Epoch 97 step 16 loss: 0.38934892416000366\n",
      "Epoch 97 step 17 loss: 0.34320998191833496\n",
      "Epoch 97 step 18 loss: 0.5155596733093262\n",
      "Epoch 97 step 19 loss: 0.46534332633018494\n",
      "Epoch 97 step 20 loss: 0.4827418327331543\n",
      "Epoch 97 step 21 loss: 0.42136090993881226\n",
      "Epoch 97 step 22 loss: 0.3920902907848358\n",
      "Epoch 97 step 23 loss: 0.48346206545829773\n",
      "Epoch 97 step 24 loss: 0.4169856011867523\n",
      "Epoch 97 step 25 loss: 0.31828001141548157\n",
      "Epoch 97 step 26 loss: 0.39893120527267456\n",
      "Epoch 97 step 27 loss: 0.5196167230606079\n",
      "Epoch 97 step 28 loss: 0.6456607580184937\n",
      "Epoch 97 step 29 loss: 0.5105100870132446\n",
      "Epoch 97 step 30 loss: 0.6412789821624756\n",
      "Epoch 97 step 31 loss: 0.3971995413303375\n",
      "Epoch 97 step 32 loss: 0.44675740599632263\n",
      "Epoch 97 step 33 loss: 0.4935052990913391\n",
      "Epoch 97 step 34 loss: 0.35476064682006836\n",
      "Epoch 97 step 35 loss: 0.4379497766494751\n",
      "Epoch 97 step 36 loss: 0.34602463245391846\n",
      "Epoch 97 step 37 loss: 0.5647644400596619\n",
      "Epoch 97 step 38 loss: 0.534942090511322\n",
      "Epoch 97 loss: 0.534942090511322\n",
      "Epoch 98 step 0 loss: 0.38810572028160095\n",
      "Epoch 98 step 1 loss: 0.38267019391059875\n",
      "Epoch 98 step 2 loss: 0.42045143246650696\n",
      "Epoch 98 step 3 loss: 0.4985099732875824\n",
      "Epoch 98 step 4 loss: 0.48913970589637756\n",
      "Epoch 98 step 5 loss: 0.5029180645942688\n",
      "Epoch 98 step 6 loss: 0.6667059659957886\n",
      "Epoch 98 step 7 loss: 0.36145085096359253\n",
      "Epoch 98 step 8 loss: 0.36325883865356445\n",
      "Epoch 98 step 9 loss: 0.42313554883003235\n",
      "Epoch 98 step 10 loss: 0.43001699447631836\n",
      "Epoch 98 step 11 loss: 0.45178669691085815\n",
      "Epoch 98 step 12 loss: 0.49135109782218933\n",
      "Epoch 98 step 13 loss: 0.40517860651016235\n",
      "Epoch 98 step 14 loss: 0.36078983545303345\n",
      "Epoch 98 step 15 loss: 0.346796452999115\n",
      "Epoch 98 step 16 loss: 0.3984989523887634\n",
      "Epoch 98 step 17 loss: 0.36166465282440186\n",
      "Epoch 98 step 18 loss: 0.4117041826248169\n",
      "Epoch 98 step 19 loss: 0.4982088804244995\n",
      "Epoch 98 step 20 loss: 0.3883534073829651\n",
      "Epoch 98 step 21 loss: 0.4381638765335083\n",
      "Epoch 98 step 22 loss: 0.5520685911178589\n",
      "Epoch 98 step 23 loss: 0.4573977291584015\n",
      "Epoch 98 step 24 loss: 0.4350471496582031\n",
      "Epoch 98 step 25 loss: 0.46625953912734985\n",
      "Epoch 98 step 26 loss: 0.45990610122680664\n",
      "Epoch 98 step 27 loss: 0.43592560291290283\n",
      "Epoch 98 step 28 loss: 0.4453113377094269\n",
      "Epoch 98 step 29 loss: 0.5185538530349731\n",
      "Epoch 98 step 30 loss: 0.4187334179878235\n",
      "Epoch 98 step 31 loss: 0.3671802878379822\n",
      "Epoch 98 step 32 loss: 0.49287477135658264\n",
      "Epoch 98 step 33 loss: 0.5014436841011047\n",
      "Epoch 98 step 34 loss: 0.3878009617328644\n",
      "Epoch 98 step 35 loss: 0.33035221695899963\n",
      "Epoch 98 step 36 loss: 0.4718050956726074\n",
      "Epoch 98 step 37 loss: 0.46941304206848145\n",
      "Epoch 98 step 38 loss: 0.720916211605072\n",
      "Epoch 98 loss: 0.720916211605072\n",
      "Epoch 99 step 0 loss: 0.4424254894256592\n",
      "Epoch 99 step 1 loss: 0.46260565519332886\n",
      "Epoch 99 step 2 loss: 0.5212147235870361\n",
      "Epoch 99 step 3 loss: 0.365386426448822\n",
      "Epoch 99 step 4 loss: 0.5281506180763245\n",
      "Epoch 99 step 5 loss: 0.5867101550102234\n",
      "Epoch 99 step 6 loss: 0.44339555501937866\n",
      "Epoch 99 step 7 loss: 0.5719804763793945\n",
      "Epoch 99 step 8 loss: 0.31837326288223267\n",
      "Epoch 99 step 9 loss: 0.5866518020629883\n",
      "Epoch 99 step 10 loss: 0.4058496356010437\n",
      "Epoch 99 step 11 loss: 0.43353137373924255\n",
      "Epoch 99 step 12 loss: 0.3495924770832062\n",
      "Epoch 99 step 13 loss: 0.3922538757324219\n",
      "Epoch 99 step 14 loss: 0.45750951766967773\n",
      "Epoch 99 step 15 loss: 0.45719969272613525\n",
      "Epoch 99 step 16 loss: 0.40929335355758667\n",
      "Epoch 99 step 17 loss: 0.4800441861152649\n",
      "Epoch 99 step 18 loss: 0.3278455436229706\n",
      "Epoch 99 step 19 loss: 0.4133037328720093\n",
      "Epoch 99 step 20 loss: 0.47846904397010803\n",
      "Epoch 99 step 21 loss: 0.3400225341320038\n",
      "Epoch 99 step 22 loss: 0.46439486742019653\n",
      "Epoch 99 step 23 loss: 0.3624822199344635\n",
      "Epoch 99 step 24 loss: 0.4189963638782501\n",
      "Epoch 99 step 25 loss: 0.3629600405693054\n",
      "Epoch 99 step 26 loss: 0.4706077575683594\n",
      "Epoch 99 step 27 loss: 0.5313177704811096\n",
      "Epoch 99 step 28 loss: 0.3954387307167053\n",
      "Epoch 99 step 29 loss: 0.5203816294670105\n",
      "Epoch 99 step 30 loss: 0.32990846037864685\n",
      "Epoch 99 step 31 loss: 0.44717174768447876\n",
      "Epoch 99 step 32 loss: 0.4199554920196533\n",
      "Epoch 99 step 33 loss: 0.6031802296638489\n",
      "Epoch 99 step 34 loss: 0.38745781779289246\n",
      "Epoch 99 step 35 loss: 0.4161020815372467\n",
      "Epoch 99 step 36 loss: 0.5074111223220825\n",
      "Epoch 99 step 37 loss: 0.4562548100948334\n",
      "Epoch 99 step 38 loss: 0.4025481939315796\n",
      "Epoch 99 loss: 0.4025481939315796\n"
     ]
    }
   ],
   "source": [
    "def get_model_name(epoch):\n",
    "    return f\"fasterrcnn_{epoch}.pth\"\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "# 训练模式\n",
    "model.train()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (images, targets) in enumerate(dataloader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        # print(\"images:\\n\", images)\n",
    "        # print(\"targets:\\n\", targets)\n",
    "\n",
    "        # 计算损失\n",
    "        loss_dict = model(images, targets)\n",
    "        # print(\"loss_dict:\\n\", loss_dict)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch} step {step} loss: {losses.item()}\")\n",
    "    print(f\"Epoch {epoch} loss: {losses.item()}\")\n",
    "    model_path = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/Faster_R_CNN/'\n",
    "    model_name = model_path + get_model_name(epoch)\n",
    "    torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 2.3430882661770553\n",
      "Epoch 1 loss: 1.406146147312262\n",
      "Epoch 2 loss: 0.9555601278940836\n",
      "Epoch 3 loss: 0.6870545928294842\n",
      "Epoch 4 loss: 0.5317501242344196\n",
      "Epoch 5 loss: 0.452578862508138\n",
      "Epoch 6 loss: 0.4057989701246604\n",
      "Epoch 7 loss: 0.37325896819432575\n",
      "Epoch 8 loss: 0.36268837329668874\n",
      "Epoch 9 loss: 0.3585699506295033\n",
      "Epoch 10 loss: 0.363021303445865\n",
      "Epoch 11 loss: 0.3797678259702829\n",
      "Epoch 12 loss: 0.3872361435340001\n",
      "Epoch 13 loss: 0.3661219760393485\n",
      "Epoch 14 loss: 0.35631023538418305\n",
      "Epoch 15 loss: 0.4260805241572551\n",
      "Epoch 16 loss: 0.40225165623884934\n",
      "Epoch 17 loss: 0.38193164345545644\n",
      "Epoch 18 loss: 0.38375144050671506\n",
      "Epoch 19 loss: 0.3820652785973671\n",
      "Epoch 20 loss: 0.42931783428558934\n",
      "Epoch 21 loss: 0.372503474736825\n",
      "Epoch 22 loss: 0.3730482145761832\n",
      "Epoch 23 loss: 0.33291935538634276\n",
      "Epoch 24 loss: 0.3118127867197379\n",
      "Epoch 25 loss: 0.35739472355598056\n",
      "Epoch 26 loss: 0.3428008212493016\n",
      "Epoch 27 loss: 0.316279404438459\n",
      "Epoch 28 loss: 0.32012932804914623\n",
      "Epoch 29 loss: 0.2940267355014116\n",
      "Epoch 30 loss: 0.308426905136842\n",
      "Epoch 31 loss: 0.40785086689851224\n",
      "Epoch 32 loss: 0.3005229563285143\n",
      "Epoch 33 loss: 0.27752275421069217\n",
      "Epoch 34 loss: 0.31399721671373415\n",
      "Epoch 35 loss: 0.40541575046686024\n",
      "Epoch 36 loss: 0.32171540153332245\n",
      "Epoch 37 loss: 0.31794369373566067\n",
      "Epoch 38 loss: 0.27751890474405044\n",
      "Epoch 39 loss: 0.378474011635169\n",
      "Epoch 40 loss: 0.3072039462052859\n",
      "Epoch 41 loss: 0.31361996745451903\n",
      "Epoch 42 loss: 0.3265396792155046\n",
      "Epoch 43 loss: 0.3085252833672059\n",
      "Epoch 44 loss: 0.3343726320144458\n",
      "Epoch 45 loss: 0.3349639486808043\n",
      "Epoch 46 loss: 0.33222994743249357\n",
      "Epoch 47 loss: 0.35073984815524173\n",
      "Epoch 48 loss: 0.3423762397888379\n",
      "Epoch 49 loss: 0.31688426167537004\n",
      "Epoch 50 loss: 0.3238485914010268\n",
      "Epoch 51 loss: 0.3740124503771464\n",
      "Epoch 52 loss: 0.3920567356623136\n",
      "Epoch 53 loss: 0.3139949097083165\n",
      "Epoch 54 loss: 0.33816491334866255\n",
      "Epoch 55 loss: 0.35370278587708104\n",
      "Epoch 56 loss: 0.32991616351482195\n",
      "Epoch 57 loss: 0.3923562039167453\n",
      "Epoch 58 loss: 0.35646982452808285\n",
      "Epoch 59 loss: 0.41168882296635556\n",
      "Epoch 60 loss: 0.36504383652638167\n",
      "Epoch 61 loss: 0.35633331613662916\n",
      "Epoch 62 loss: 0.4470792672572992\n",
      "Epoch 63 loss: 0.3939793232159737\n",
      "Epoch 64 loss: 0.3640251106176621\n",
      "Epoch 65 loss: 0.3741349058273511\n",
      "Epoch 66 loss: 0.3416727085908254\n",
      "Epoch 67 loss: 0.3893239230681688\n",
      "Epoch 68 loss: 0.3349180397314903\n",
      "Epoch 69 loss: 0.3932713927366795\n",
      "Epoch 70 loss: 0.3785834136681679\n",
      "Epoch 71 loss: 0.5075194675188798\n",
      "Epoch 72 loss: 0.34971027076244354\n",
      "Epoch 73 loss: 0.4596759585233835\n",
      "Epoch 74 loss: 0.372132088129337\n",
      "Epoch 75 loss: 0.385751057893802\n",
      "Epoch 76 loss: 0.3837655790341206\n",
      "Epoch 77 loss: 0.46304130936280274\n",
      "Epoch 78 loss: 0.364112043992067\n",
      "Epoch 79 loss: 0.42990782933357435\n",
      "Epoch 80 loss: 0.40669854558431184\n",
      "Epoch 81 loss: 0.3952132891385983\n",
      "Epoch 82 loss: 0.3742471803457309\n",
      "Epoch 83 loss: 0.4547602549577371\n",
      "Epoch 84 loss: 0.390862097342809\n",
      "Epoch 85 loss: 0.4294516757512704\n",
      "Epoch 86 loss: 0.43331558505694073\n",
      "Epoch 87 loss: 0.44992374991759276\n",
      "Epoch 88 loss: 0.4389742788596031\n",
      "Epoch 89 loss: 0.4110387250398978\n",
      "Epoch 90 loss: 0.4273327268086947\n",
      "Epoch 91 loss: 0.47569336952307284\n",
      "Epoch 92 loss: 0.40213697613813937\n",
      "Epoch 93 loss: 0.4638736653022277\n",
      "Epoch 94 loss: 0.5404935570863577\n",
      "Epoch 95 loss: 0.40664869394057834\n",
      "Epoch 96 loss: 0.444544860185721\n",
      "Epoch 97 loss: 0.4236191190206088\n",
      "Epoch 98 loss: 0.41920869549115497\n",
      "Epoch 99 loss: 0.4558564821879069\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *\n",
    "\n",
    "def get_model_name(epoch):\n",
    "    return f\"fasterrcnn_{epoch}.pth\"\n",
    "\n",
    "def load_model(model, epoch):\n",
    "    model_path = '/root/autodl-tmp/APS360_Project/Machine_Learning_Output/Faster_R_CNN/'\n",
    "    model_name = model_path + get_model_name(epoch)\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loss_crv = []\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)\n",
    "model.to(device)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    images = default_collate(images)\n",
    "    return images, targets\n",
    "\n",
    "dataset = ModifiedDataset(SegDataset('IAM', 'train'))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model = load_model(model, epoch)\n",
    "    # model.eval()\n",
    "    total_loss = 0\n",
    "    total_step = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (images, targets) in enumerate(dataloader):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # 计算损失\n",
    "            loss_dict = model(images, targets)\n",
    "            # print(loss_dict)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            total_loss += losses.item()\n",
    "            total_step += 1\n",
    "\n",
    "            # print(f\"Epoch {epoch} step {step} loss: {losses.item()}\")\n",
    "    losses = total_loss / total_step\n",
    "    loss_crv.append(losses)\n",
    "    print(f\"Epoch {epoch} loss: {losses}\")\n",
    "\n",
    "plt.plot(np.arange(len(loss_crv)), loss_crv)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve of Current Faster R-CNN Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save loss crv\n",
    "import pickle\n",
    "with open('train_crv.pkl', 'wb') as f:\n",
    "    pickle.dump(loss_crv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 2.3937403678894045\n",
      "Epoch 1 loss: 1.4132689952850341\n",
      "Epoch 2 loss: 0.9501038670539856\n",
      "Epoch 3 loss: 0.6789250016212464\n",
      "Epoch 4 loss: 0.528100597858429\n",
      "Epoch 5 loss: 0.4638660132884979\n",
      "Epoch 6 loss: 0.4135788559913635\n",
      "Epoch 7 loss: 0.3777868807315826\n",
      "Epoch 8 loss: 0.36378070116043093\n",
      "Epoch 9 loss: 0.3573130011558533\n",
      "Epoch 10 loss: 0.3569773077964783\n",
      "Epoch 11 loss: 0.38963437676429746\n",
      "Epoch 12 loss: 0.390592485666275\n",
      "Epoch 13 loss: 0.36112846732139586\n",
      "Epoch 14 loss: 0.3532510221004486\n",
      "Epoch 15 loss: 0.4232593238353729\n",
      "Epoch 16 loss: 0.40438262224197385\n",
      "Epoch 17 loss: 0.372318035364151\n",
      "Epoch 18 loss: 0.3623042583465576\n",
      "Epoch 19 loss: 0.3534569501876831\n",
      "Epoch 20 loss: 0.4087063312530518\n",
      "Epoch 21 loss: 0.33974774479866027\n",
      "Epoch 22 loss: 0.3365471661090851\n",
      "Epoch 23 loss: 0.3191616714000702\n",
      "Epoch 24 loss: 0.29890450835227966\n",
      "Epoch 25 loss: 0.3506736636161804\n",
      "Epoch 26 loss: 0.3467234969139099\n",
      "Epoch 27 loss: 0.317995685338974\n",
      "Epoch 28 loss: 0.3178845465183258\n",
      "Epoch 29 loss: 0.29660236835479736\n",
      "Epoch 30 loss: 0.3254444420337677\n",
      "Epoch 31 loss: 0.3986286997795105\n",
      "Epoch 32 loss: 0.30245853066444395\n",
      "Epoch 33 loss: 0.28588227927684784\n",
      "Epoch 34 loss: 0.3314702928066254\n",
      "Epoch 35 loss: 0.43108431696891786\n",
      "Epoch 36 loss: 0.3300756812095642\n",
      "Epoch 37 loss: 0.3343911826610565\n",
      "Epoch 38 loss: 0.2926682114601135\n",
      "Epoch 39 loss: 0.39249311089515687\n",
      "Epoch 40 loss: 0.33175297975540163\n",
      "Epoch 41 loss: 0.32589096426963804\n",
      "Epoch 42 loss: 0.3487608551979065\n",
      "Epoch 43 loss: 0.3269377529621124\n",
      "Epoch 44 loss: 0.3619072675704956\n",
      "Epoch 45 loss: 0.3542791724205017\n",
      "Epoch 46 loss: 0.3518116056919098\n",
      "Epoch 47 loss: 0.3780890226364136\n",
      "Epoch 48 loss: 0.35391283631324766\n",
      "Epoch 49 loss: 0.3460298299789429\n",
      "Epoch 50 loss: 0.3525032699108124\n",
      "Epoch 51 loss: 0.42144421935081483\n",
      "Epoch 52 loss: 0.4231848955154419\n",
      "Epoch 53 loss: 0.35042551159858704\n",
      "Epoch 54 loss: 0.3667317986488342\n",
      "Epoch 55 loss: 0.39513776898384095\n",
      "Epoch 56 loss: 0.37250648736953734\n",
      "Epoch 57 loss: 0.4165038764476776\n",
      "Epoch 58 loss: 0.38584624528884887\n",
      "Epoch 59 loss: 0.4350834429264069\n",
      "Epoch 60 loss: 0.3996675908565521\n",
      "Epoch 61 loss: 0.4031430959701538\n",
      "Epoch 62 loss: 0.4891513824462891\n",
      "Epoch 63 loss: 0.4300051271915436\n",
      "Epoch 64 loss: 0.41618417501449584\n",
      "Epoch 65 loss: 0.4314471185207367\n",
      "Epoch 66 loss: 0.38994516134262086\n",
      "Epoch 67 loss: 0.43741575479507444\n",
      "Epoch 68 loss: 0.37819170355796816\n",
      "Epoch 69 loss: 0.43985897302627563\n",
      "Epoch 70 loss: 0.42714120745658873\n",
      "Epoch 71 loss: 0.5388075590133667\n",
      "Epoch 72 loss: 0.40728360414505005\n",
      "Epoch 73 loss: 0.4974247753620148\n",
      "Epoch 74 loss: 0.4325538814067841\n",
      "Epoch 75 loss: 0.4286285102367401\n",
      "Epoch 76 loss: 0.43352845311164856\n",
      "Epoch 77 loss: 0.5041579067707062\n",
      "Epoch 78 loss: 0.43618383407592776\n",
      "Epoch 79 loss: 0.46565365195274355\n",
      "Epoch 80 loss: 0.45592126846313474\n",
      "Epoch 81 loss: 0.44806390404701235\n",
      "Epoch 82 loss: 0.4354166805744171\n",
      "Epoch 83 loss: 0.5024714231491089\n",
      "Epoch 84 loss: 0.46823217272758483\n",
      "Epoch 85 loss: 0.4890959084033966\n",
      "Epoch 86 loss: 0.49815213680267334\n",
      "Epoch 87 loss: 0.5156235277652741\n",
      "Epoch 88 loss: 0.4989587128162384\n",
      "Epoch 89 loss: 0.4974174499511719\n",
      "Epoch 90 loss: 0.4928646385669708\n",
      "Epoch 91 loss: 0.5848118126392364\n",
      "Epoch 92 loss: 0.49932810068130495\n",
      "Epoch 93 loss: 0.5318194687366485\n",
      "Epoch 94 loss: 0.6467710733413696\n",
      "Epoch 95 loss: 0.5068363904953003\n",
      "Epoch 96 loss: 0.5489901423454284\n",
      "Epoch 97 loss: 0.525320315361023\n",
      "Epoch 98 loss: 0.5060726225376129\n",
      "Epoch 99 loss: 0.5451704800128937\n"
     ]
    }
   ],
   "source": [
    "# validation crv\n",
    "\n",
    "dataset = ModifiedDataset(SegDataset('IAM', 'val'))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "val_crv = []\n",
    "for epoch in range(100):\n",
    "    model = load_model(model, epoch)\n",
    "    # model.eval()\n",
    "    total_loss = 0\n",
    "    total_step = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (images, targets) in enumerate(dataloader):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # 计算损失\n",
    "            loss_dict = model(images, targets)\n",
    "            # print(loss_dict)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            total_loss += losses.item()\n",
    "            total_step += 1\n",
    "\n",
    "            # print(f\"Epoch {epoch} step {step} loss: {losses.item()}\")\n",
    "    losses = total_loss / total_step\n",
    "    val_crv.append(losses)\n",
    "    print(f\"Epoch {epoch} loss: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot both crv\n",
    "plt.plot(np.arange(len(loss_crv)), loss_crv, label='Train')\n",
    "plt.plot(np.arange(len(val_crv)), val_crv, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve of Current Faster R-CNN Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
